{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMysCbDQkGaE4DTx6nL1Jwt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rabnawaz172/ET/blob/main/ET_taif.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "INdeG4mC9TVS",
        "outputId": "1e7030cf-e1e4-4b35-ef31-538beffbc9b3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-03c71018-4876-473d-914f-644fa9da50e2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-03c71018-4876-473d-914f-644fa9da50e2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ET_Riaz_5.csv to ET_Riaz_5.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Use the following command to upload a file from your computer\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn import preprocessing\n",
        "import numpy\n",
        "from sklearn.tree import DecisionTreeRegressor\n"
      ],
      "metadata": {
        "id": "aFByq9uJASxM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you uploaded a CSV file named 'my_dataset.csv'\n",
        "file_name = 'ET_Riaz_5.csv'\n",
        "\n",
        "# Read the uploaded CSV file into a DataFrame\n",
        "df = pd.read_csv(file_name)\n",
        "\n",
        "# Now, you can work with the DataFrame 'df' as you would with any other pandas DataFrame.\n",
        "\n",
        "sns.set_theme(style=\"white\", font_scale=1.5)\n",
        "# Load the example planets dataset\n",
        "df1=df.drop(['Day','Month','Year'],axis=1)\n",
        "column_order = ['Tx', 'Tn', 'RH', 'u(x)', 'Rs', 'e(a)', 'e(s)', 'u2', 'Ra', 'n', 'N', 'Rnl', 'Rn', 'ETo']\n",
        "df1 = df1[column_order]\n",
        "df1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5D8rsY-kAbuo",
        "outputId": "b8dab70d-c37d-46e3-e3dc-5188cde92a5b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Tx    Tn    RH  u(x)     Rs   e(a)   e(s)    u2     Ra      n      N  \\\n",
              "0     22.5   3.3  22.6  1.79  17.38  0.336  1.750  1.79  22.98  10.48  10.48   \n",
              "1     22.1   5.2  33.9  2.51  17.67  0.530  1.772  2.51  23.03  10.49  10.49   \n",
              "2     22.6   5.4  44.6  4.12  16.51  0.713  1.820  4.12  23.08   9.76  10.49   \n",
              "3     20.5   6.3  51.7  1.36  16.48  0.795  1.683  1.36  23.14   9.71  10.50   \n",
              "4     20.6   5.2  41.1  2.48  15.71  0.612  1.656  2.48  23.20   8.98  10.51   \n",
              "...    ...   ...   ...   ...    ...    ...    ...   ...    ...    ...    ...   \n",
              "8120  27.5  14.0  61.7  1.76  23.64  1.511  2.635  1.76  35.08  10.29  12.13   \n",
              "8121  27.0  11.5  51.1  2.09  24.36  1.141  2.461  2.09  35.22  10.74  12.16   \n",
              "8122  27.6  10.9  40.5  1.85  24.81  0.904  2.498  1.85  35.37  11.00  12.18   \n",
              "8123  29.8  12.5  42.8  2.95  22.98  1.074  2.822  2.95  35.51   9.69  12.21   \n",
              "8124  29.7  14.4  49.5  4.76  24.05  1.313  2.906  4.76  35.66  10.38  12.23   \n",
              "\n",
              "       Rnl     Rn  ETo  \n",
              "0     8.47   4.92  3.5  \n",
              "1     7.94   5.57  3.9  \n",
              "2     6.82   5.90  4.5  \n",
              "3     6.51   6.18  2.6  \n",
              "4     6.46   5.64  3.5  \n",
              "...    ...    ...  ...  \n",
              "8120  5.20  13.00  4.7  \n",
              "8121  6.00  12.76  5.1  \n",
              "8122  6.65  12.45  5.3  \n",
              "8123  5.74  11.96  6.2  \n",
              "8124  5.67  12.84  7.1  \n",
              "\n",
              "[8125 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3640b6e2-9407-4682-ad4e-ed7a109d8ebf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tx</th>\n",
              "      <th>Tn</th>\n",
              "      <th>RH</th>\n",
              "      <th>u(x)</th>\n",
              "      <th>Rs</th>\n",
              "      <th>e(a)</th>\n",
              "      <th>e(s)</th>\n",
              "      <th>u2</th>\n",
              "      <th>Ra</th>\n",
              "      <th>n</th>\n",
              "      <th>N</th>\n",
              "      <th>Rnl</th>\n",
              "      <th>Rn</th>\n",
              "      <th>ETo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>22.6</td>\n",
              "      <td>1.79</td>\n",
              "      <td>17.38</td>\n",
              "      <td>0.336</td>\n",
              "      <td>1.750</td>\n",
              "      <td>1.79</td>\n",
              "      <td>22.98</td>\n",
              "      <td>10.48</td>\n",
              "      <td>10.48</td>\n",
              "      <td>8.47</td>\n",
              "      <td>4.92</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22.1</td>\n",
              "      <td>5.2</td>\n",
              "      <td>33.9</td>\n",
              "      <td>2.51</td>\n",
              "      <td>17.67</td>\n",
              "      <td>0.530</td>\n",
              "      <td>1.772</td>\n",
              "      <td>2.51</td>\n",
              "      <td>23.03</td>\n",
              "      <td>10.49</td>\n",
              "      <td>10.49</td>\n",
              "      <td>7.94</td>\n",
              "      <td>5.57</td>\n",
              "      <td>3.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22.6</td>\n",
              "      <td>5.4</td>\n",
              "      <td>44.6</td>\n",
              "      <td>4.12</td>\n",
              "      <td>16.51</td>\n",
              "      <td>0.713</td>\n",
              "      <td>1.820</td>\n",
              "      <td>4.12</td>\n",
              "      <td>23.08</td>\n",
              "      <td>9.76</td>\n",
              "      <td>10.49</td>\n",
              "      <td>6.82</td>\n",
              "      <td>5.90</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20.5</td>\n",
              "      <td>6.3</td>\n",
              "      <td>51.7</td>\n",
              "      <td>1.36</td>\n",
              "      <td>16.48</td>\n",
              "      <td>0.795</td>\n",
              "      <td>1.683</td>\n",
              "      <td>1.36</td>\n",
              "      <td>23.14</td>\n",
              "      <td>9.71</td>\n",
              "      <td>10.50</td>\n",
              "      <td>6.51</td>\n",
              "      <td>6.18</td>\n",
              "      <td>2.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.6</td>\n",
              "      <td>5.2</td>\n",
              "      <td>41.1</td>\n",
              "      <td>2.48</td>\n",
              "      <td>15.71</td>\n",
              "      <td>0.612</td>\n",
              "      <td>1.656</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.20</td>\n",
              "      <td>8.98</td>\n",
              "      <td>10.51</td>\n",
              "      <td>6.46</td>\n",
              "      <td>5.64</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8120</th>\n",
              "      <td>27.5</td>\n",
              "      <td>14.0</td>\n",
              "      <td>61.7</td>\n",
              "      <td>1.76</td>\n",
              "      <td>23.64</td>\n",
              "      <td>1.511</td>\n",
              "      <td>2.635</td>\n",
              "      <td>1.76</td>\n",
              "      <td>35.08</td>\n",
              "      <td>10.29</td>\n",
              "      <td>12.13</td>\n",
              "      <td>5.20</td>\n",
              "      <td>13.00</td>\n",
              "      <td>4.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8121</th>\n",
              "      <td>27.0</td>\n",
              "      <td>11.5</td>\n",
              "      <td>51.1</td>\n",
              "      <td>2.09</td>\n",
              "      <td>24.36</td>\n",
              "      <td>1.141</td>\n",
              "      <td>2.461</td>\n",
              "      <td>2.09</td>\n",
              "      <td>35.22</td>\n",
              "      <td>10.74</td>\n",
              "      <td>12.16</td>\n",
              "      <td>6.00</td>\n",
              "      <td>12.76</td>\n",
              "      <td>5.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8122</th>\n",
              "      <td>27.6</td>\n",
              "      <td>10.9</td>\n",
              "      <td>40.5</td>\n",
              "      <td>1.85</td>\n",
              "      <td>24.81</td>\n",
              "      <td>0.904</td>\n",
              "      <td>2.498</td>\n",
              "      <td>1.85</td>\n",
              "      <td>35.37</td>\n",
              "      <td>11.00</td>\n",
              "      <td>12.18</td>\n",
              "      <td>6.65</td>\n",
              "      <td>12.45</td>\n",
              "      <td>5.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8123</th>\n",
              "      <td>29.8</td>\n",
              "      <td>12.5</td>\n",
              "      <td>42.8</td>\n",
              "      <td>2.95</td>\n",
              "      <td>22.98</td>\n",
              "      <td>1.074</td>\n",
              "      <td>2.822</td>\n",
              "      <td>2.95</td>\n",
              "      <td>35.51</td>\n",
              "      <td>9.69</td>\n",
              "      <td>12.21</td>\n",
              "      <td>5.74</td>\n",
              "      <td>11.96</td>\n",
              "      <td>6.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8124</th>\n",
              "      <td>29.7</td>\n",
              "      <td>14.4</td>\n",
              "      <td>49.5</td>\n",
              "      <td>4.76</td>\n",
              "      <td>24.05</td>\n",
              "      <td>1.313</td>\n",
              "      <td>2.906</td>\n",
              "      <td>4.76</td>\n",
              "      <td>35.66</td>\n",
              "      <td>10.38</td>\n",
              "      <td>12.23</td>\n",
              "      <td>5.67</td>\n",
              "      <td>12.84</td>\n",
              "      <td>7.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8125 rows Ã— 14 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3640b6e2-9407-4682-ad4e-ed7a109d8ebf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3640b6e2-9407-4682-ad4e-ed7a109d8ebf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3640b6e2-9407-4682-ad4e-ed7a109d8ebf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-18999128-179b-4ecf-bcd7-b8a8fd93f2a0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-18999128-179b-4ecf-bcd7-b8a8fd93f2a0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-18999128-179b-4ecf-bcd7-b8a8fd93f2a0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df1",
              "summary": "{\n  \"name\": \"df1\",\n  \"rows\": 8125,\n  \"fields\": [\n    {\n      \"column\": \"Tx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.296722791242718,\n        \"min\": 7.5,\n        \"max\": 46.4,\n        \"samples\": [\n          43.4,\n          41.9,\n          39.6\n        ],\n        \"num_unique_values\": 343,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tn\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.59178392231562,\n        \"min\": -3.6,\n        \"max\": 32.0,\n        \"samples\": [\n          0.8,\n          -1.5,\n          17.4\n        ],\n        \"num_unique_values\": 333,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.914419794694322,\n        \"min\": 5.7,\n        \"max\": 89.7,\n        \"samples\": [\n          26.9,\n          9.3,\n          53.8\n        ],\n        \"num_unique_values\": 669,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"u(x)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.942528950635093,\n        \"min\": 0.78,\n        \"max\": 7.2,\n        \"samples\": [\n          1.8,\n          2.27,\n          4.46\n        ],\n        \"num_unique_values\": 492,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.422939349309958,\n        \"min\": -999.0,\n        \"max\": 31.79,\n        \"samples\": [\n          16.6,\n          27.22,\n          27.03\n        ],\n        \"num_unique_values\": 1937,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"e(a)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.26098317712779595,\n        \"min\": 0.149,\n        \"max\": 2.467,\n        \"samples\": [\n          1.252,\n          0.283,\n          1.342\n        ],\n        \"num_unique_values\": 1263,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"e(s)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6416352754395964,\n        \"min\": 0.866,\n        \"max\": 7.498,\n        \"samples\": [\n          2.038,\n          2.088,\n          3.972\n        ],\n        \"num_unique_values\": 3907,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"u2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.942528950635093,\n        \"min\": 0.78,\n        \"max\": 7.2,\n        \"samples\": [\n          1.8,\n          2.27,\n          4.46\n        ],\n        \"num_unique_values\": 492,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ra\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.3715531800873375,\n        \"min\": 22.7,\n        \"max\": 40.47,\n        \"samples\": [\n          34.06,\n          38.14,\n          31.62\n        ],\n        \"num_unique_values\": 326,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.114966151878025,\n        \"min\": 0.0,\n        \"max\": 13.55,\n        \"samples\": [\n          8.9,\n          3.57,\n          4.12\n        ],\n        \"num_unique_values\": 1001,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.078859861661569,\n        \"min\": 10.45,\n        \"max\": 13.55,\n        \"samples\": [\n          13.27,\n          12.89,\n          13.2\n        ],\n        \"num_unique_values\": 164,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rnl\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7809895503158573,\n        \"min\": 0.0,\n        \"max\": 11.49,\n        \"samples\": [\n          3.75,\n          8.23,\n          7.8\n        ],\n        \"num_unique_values\": 903,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rn\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.7581068546068668,\n        \"min\": 1.81,\n        \"max\": 15.53,\n        \"samples\": [\n          11.36,\n          12.09,\n          6.63\n        ],\n        \"num_unique_values\": 1025,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ETo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.7879749678967265,\n        \"min\": 1.1,\n        \"max\": 16.3,\n        \"samples\": [\n          10.5,\n          9.8,\n          3.4\n        ],\n        \"num_unique_values\": 141,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.inspection import permutation_importance\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
      ],
      "metadata": {
        "id": "LuVf0JdlAiTf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "df3=df1.drop(['Tx', 'Tn', 'RH', 'u(x)', 'Rs', 'e(a)', 'e(s)', 'u2', 'Ra', 'n', 'N', 'Rnl', 'Rn'],axis=1)\n",
        "y=df3\n",
        "y\n",
        "X=df1.drop(['ETo'],axis=1)\n",
        "X\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "csb_NUAUAnh3",
        "outputId": "52917766-1e2c-4f34-cfc0-30f0d3eb6ae1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Tx    Tn    RH  u(x)     Rs   e(a)   e(s)    u2     Ra      n      N  \\\n",
              "0     22.5   3.3  22.6  1.79  17.38  0.336  1.750  1.79  22.98  10.48  10.48   \n",
              "1     22.1   5.2  33.9  2.51  17.67  0.530  1.772  2.51  23.03  10.49  10.49   \n",
              "2     22.6   5.4  44.6  4.12  16.51  0.713  1.820  4.12  23.08   9.76  10.49   \n",
              "3     20.5   6.3  51.7  1.36  16.48  0.795  1.683  1.36  23.14   9.71  10.50   \n",
              "4     20.6   5.2  41.1  2.48  15.71  0.612  1.656  2.48  23.20   8.98  10.51   \n",
              "...    ...   ...   ...   ...    ...    ...    ...   ...    ...    ...    ...   \n",
              "8120  27.5  14.0  61.7  1.76  23.64  1.511  2.635  1.76  35.08  10.29  12.13   \n",
              "8121  27.0  11.5  51.1  2.09  24.36  1.141  2.461  2.09  35.22  10.74  12.16   \n",
              "8122  27.6  10.9  40.5  1.85  24.81  0.904  2.498  1.85  35.37  11.00  12.18   \n",
              "8123  29.8  12.5  42.8  2.95  22.98  1.074  2.822  2.95  35.51   9.69  12.21   \n",
              "8124  29.7  14.4  49.5  4.76  24.05  1.313  2.906  4.76  35.66  10.38  12.23   \n",
              "\n",
              "       Rnl     Rn  \n",
              "0     8.47   4.92  \n",
              "1     7.94   5.57  \n",
              "2     6.82   5.90  \n",
              "3     6.51   6.18  \n",
              "4     6.46   5.64  \n",
              "...    ...    ...  \n",
              "8120  5.20  13.00  \n",
              "8121  6.00  12.76  \n",
              "8122  6.65  12.45  \n",
              "8123  5.74  11.96  \n",
              "8124  5.67  12.84  \n",
              "\n",
              "[8125 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-807e561a-9b20-4018-a93e-82147e9a97f8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tx</th>\n",
              "      <th>Tn</th>\n",
              "      <th>RH</th>\n",
              "      <th>u(x)</th>\n",
              "      <th>Rs</th>\n",
              "      <th>e(a)</th>\n",
              "      <th>e(s)</th>\n",
              "      <th>u2</th>\n",
              "      <th>Ra</th>\n",
              "      <th>n</th>\n",
              "      <th>N</th>\n",
              "      <th>Rnl</th>\n",
              "      <th>Rn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>22.6</td>\n",
              "      <td>1.79</td>\n",
              "      <td>17.38</td>\n",
              "      <td>0.336</td>\n",
              "      <td>1.750</td>\n",
              "      <td>1.79</td>\n",
              "      <td>22.98</td>\n",
              "      <td>10.48</td>\n",
              "      <td>10.48</td>\n",
              "      <td>8.47</td>\n",
              "      <td>4.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22.1</td>\n",
              "      <td>5.2</td>\n",
              "      <td>33.9</td>\n",
              "      <td>2.51</td>\n",
              "      <td>17.67</td>\n",
              "      <td>0.530</td>\n",
              "      <td>1.772</td>\n",
              "      <td>2.51</td>\n",
              "      <td>23.03</td>\n",
              "      <td>10.49</td>\n",
              "      <td>10.49</td>\n",
              "      <td>7.94</td>\n",
              "      <td>5.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22.6</td>\n",
              "      <td>5.4</td>\n",
              "      <td>44.6</td>\n",
              "      <td>4.12</td>\n",
              "      <td>16.51</td>\n",
              "      <td>0.713</td>\n",
              "      <td>1.820</td>\n",
              "      <td>4.12</td>\n",
              "      <td>23.08</td>\n",
              "      <td>9.76</td>\n",
              "      <td>10.49</td>\n",
              "      <td>6.82</td>\n",
              "      <td>5.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20.5</td>\n",
              "      <td>6.3</td>\n",
              "      <td>51.7</td>\n",
              "      <td>1.36</td>\n",
              "      <td>16.48</td>\n",
              "      <td>0.795</td>\n",
              "      <td>1.683</td>\n",
              "      <td>1.36</td>\n",
              "      <td>23.14</td>\n",
              "      <td>9.71</td>\n",
              "      <td>10.50</td>\n",
              "      <td>6.51</td>\n",
              "      <td>6.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.6</td>\n",
              "      <td>5.2</td>\n",
              "      <td>41.1</td>\n",
              "      <td>2.48</td>\n",
              "      <td>15.71</td>\n",
              "      <td>0.612</td>\n",
              "      <td>1.656</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.20</td>\n",
              "      <td>8.98</td>\n",
              "      <td>10.51</td>\n",
              "      <td>6.46</td>\n",
              "      <td>5.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8120</th>\n",
              "      <td>27.5</td>\n",
              "      <td>14.0</td>\n",
              "      <td>61.7</td>\n",
              "      <td>1.76</td>\n",
              "      <td>23.64</td>\n",
              "      <td>1.511</td>\n",
              "      <td>2.635</td>\n",
              "      <td>1.76</td>\n",
              "      <td>35.08</td>\n",
              "      <td>10.29</td>\n",
              "      <td>12.13</td>\n",
              "      <td>5.20</td>\n",
              "      <td>13.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8121</th>\n",
              "      <td>27.0</td>\n",
              "      <td>11.5</td>\n",
              "      <td>51.1</td>\n",
              "      <td>2.09</td>\n",
              "      <td>24.36</td>\n",
              "      <td>1.141</td>\n",
              "      <td>2.461</td>\n",
              "      <td>2.09</td>\n",
              "      <td>35.22</td>\n",
              "      <td>10.74</td>\n",
              "      <td>12.16</td>\n",
              "      <td>6.00</td>\n",
              "      <td>12.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8122</th>\n",
              "      <td>27.6</td>\n",
              "      <td>10.9</td>\n",
              "      <td>40.5</td>\n",
              "      <td>1.85</td>\n",
              "      <td>24.81</td>\n",
              "      <td>0.904</td>\n",
              "      <td>2.498</td>\n",
              "      <td>1.85</td>\n",
              "      <td>35.37</td>\n",
              "      <td>11.00</td>\n",
              "      <td>12.18</td>\n",
              "      <td>6.65</td>\n",
              "      <td>12.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8123</th>\n",
              "      <td>29.8</td>\n",
              "      <td>12.5</td>\n",
              "      <td>42.8</td>\n",
              "      <td>2.95</td>\n",
              "      <td>22.98</td>\n",
              "      <td>1.074</td>\n",
              "      <td>2.822</td>\n",
              "      <td>2.95</td>\n",
              "      <td>35.51</td>\n",
              "      <td>9.69</td>\n",
              "      <td>12.21</td>\n",
              "      <td>5.74</td>\n",
              "      <td>11.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8124</th>\n",
              "      <td>29.7</td>\n",
              "      <td>14.4</td>\n",
              "      <td>49.5</td>\n",
              "      <td>4.76</td>\n",
              "      <td>24.05</td>\n",
              "      <td>1.313</td>\n",
              "      <td>2.906</td>\n",
              "      <td>4.76</td>\n",
              "      <td>35.66</td>\n",
              "      <td>10.38</td>\n",
              "      <td>12.23</td>\n",
              "      <td>5.67</td>\n",
              "      <td>12.84</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8125 rows Ã— 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-807e561a-9b20-4018-a93e-82147e9a97f8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-807e561a-9b20-4018-a93e-82147e9a97f8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-807e561a-9b20-4018-a93e-82147e9a97f8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3907e0be-c340-4606-a4bc-dca27354775c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3907e0be-c340-4606-a4bc-dca27354775c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3907e0be-c340-4606-a4bc-dca27354775c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X",
              "summary": "{\n  \"name\": \"X\",\n  \"rows\": 8125,\n  \"fields\": [\n    {\n      \"column\": \"Tx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.296722791242718,\n        \"min\": 7.5,\n        \"max\": 46.4,\n        \"samples\": [\n          43.4,\n          41.9,\n          39.6\n        ],\n        \"num_unique_values\": 343,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tn\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.59178392231562,\n        \"min\": -3.6,\n        \"max\": 32.0,\n        \"samples\": [\n          0.8,\n          -1.5,\n          17.4\n        ],\n        \"num_unique_values\": 333,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.914419794694322,\n        \"min\": 5.7,\n        \"max\": 89.7,\n        \"samples\": [\n          26.9,\n          9.3,\n          53.8\n        ],\n        \"num_unique_values\": 669,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"u(x)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.942528950635093,\n        \"min\": 0.78,\n        \"max\": 7.2,\n        \"samples\": [\n          1.8,\n          2.27,\n          4.46\n        ],\n        \"num_unique_values\": 492,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.422939349309958,\n        \"min\": -999.0,\n        \"max\": 31.79,\n        \"samples\": [\n          16.6,\n          27.22,\n          27.03\n        ],\n        \"num_unique_values\": 1937,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"e(a)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.26098317712779595,\n        \"min\": 0.149,\n        \"max\": 2.467,\n        \"samples\": [\n          1.252,\n          0.283,\n          1.342\n        ],\n        \"num_unique_values\": 1263,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"e(s)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6416352754395964,\n        \"min\": 0.866,\n        \"max\": 7.498,\n        \"samples\": [\n          2.038,\n          2.088,\n          3.972\n        ],\n        \"num_unique_values\": 3907,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"u2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.942528950635093,\n        \"min\": 0.78,\n        \"max\": 7.2,\n        \"samples\": [\n          1.8,\n          2.27,\n          4.46\n        ],\n        \"num_unique_values\": 492,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ra\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.3715531800873375,\n        \"min\": 22.7,\n        \"max\": 40.47,\n        \"samples\": [\n          34.06,\n          38.14,\n          31.62\n        ],\n        \"num_unique_values\": 326,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.114966151878025,\n        \"min\": 0.0,\n        \"max\": 13.55,\n        \"samples\": [\n          8.9,\n          3.57,\n          4.12\n        ],\n        \"num_unique_values\": 1001,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.078859861661569,\n        \"min\": 10.45,\n        \"max\": 13.55,\n        \"samples\": [\n          13.27,\n          12.89,\n          13.2\n        ],\n        \"num_unique_values\": 164,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rnl\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7809895503158573,\n        \"min\": 0.0,\n        \"max\": 11.49,\n        \"samples\": [\n          3.75,\n          8.23,\n          7.8\n        ],\n        \"num_unique_values\": 903,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rn\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.7581068546068668,\n        \"min\": 1.81,\n        \"max\": 15.53,\n        \"samples\": [\n          11.36,\n          12.09,\n          6.63\n        ],\n        \"num_unique_values\": 1025,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exploring Hyperparameter**"
      ],
      "metadata": {
        "id": "GUJW7Uj__R4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "# Assuming X_train_np and y_train are your training data\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Decision Tree\n",
        "dt_param_grid = {\n",
        "    'criterion': ['friedman_mse', 'absolute_error', 'poisson', 'squared_error'],\n",
        "    'max_depth': [None, 5, 10, 15],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "dt_model = DecisionTreeRegressor()\n",
        "dt_grid_search = GridSearchCV(dt_model, dt_param_grid, cv=kf, scoring='neg_mean_squared_error')\n",
        "dt_grid_search.fit(X_train_np, y_train)\n",
        "\n",
        "# Random Forest\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "rf_model = RandomForestRegressor()\n",
        "rf_grid_search = GridSearchCV(rf_model, rf_param_grid, cv=kf, scoring='neg_mean_squared_error')\n",
        "rf_grid_search.fit(X_train_np, y_train)\n",
        "\n",
        "# XGBoost\n",
        "xgb_param_grid = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'gamma': [0, 0.1, 0.2, 0.3]\n",
        "}\n",
        "\n",
        "xgb_model = XGBRegressor()\n",
        "xgb_grid_search = GridSearchCV(xgb_model, xgb_param_grid, cv=kf, scoring='neg_mean_squared_error')\n",
        "xgb_grid_search.fit(X_train_np, y_train)\n",
        "\n",
        "# LightGBM\n",
        "lgbm_param_grid = {\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'min_data_in_leaf': [1, 5, 10, 20],\n",
        "    'feature_fraction': [0.5, 0.7, 0.9]\n",
        "}\n",
        "\n",
        "lgbm_model = LGBMRegressor()\n",
        "lgbm_grid_search = GridSearchCV(lgbm_model, lgbm_param_grid, cv=kf, scoring='neg_mean_squared_error')\n",
        "lgbm_grid_search.fit(X_train_np, y_train)\n",
        "\n",
        "# Retrieve best hyperparameters\n",
        "dt_best_params = dt_grid_search.best_params_\n",
        "rf_best_params = rf_grid_search.best_params_\n",
        "xgb_best_params = xgb_grid_search.best_params_\n",
        "lgbm_best_params = lgbm_grid_search.best_params_\n",
        "\n",
        "print(\"Decision Tree Best Parameters:\", dt_best_params)\n",
        "print(\"Random Forest Best Parameters:\", rf_best_params)\n",
        "print(\"XGBoost Best Parameters:\", xgb_best_params)\n",
        "print(\"LightGBM Best Parameters:\", lgbm_best_params)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVOhjc35BPI3",
        "outputId": "14cfb2e3-7856-42a2-e93c-e55e30ef7d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000860 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000841 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000738 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000681 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000909 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001055 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000950 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000950 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001262 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000909 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001255 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000864 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000876 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000923 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000856 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001226 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000867 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000743 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001138 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000942 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001191 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001094 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001223 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001275 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001316 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001245 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000846 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000828 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000921 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000870 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001179 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000878 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000900 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000844 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000856 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000840 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000891 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000882 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000910 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001209 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000940 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000919 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000854 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000884 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000725 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000869 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000994 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000861 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001222 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000895 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001100 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001072 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001073 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001067 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001070 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000317 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001307 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001038 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001070 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001086 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001093 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000725 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001054 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000871 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001054 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001076 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001058 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001072 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000745 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000689 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001232 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000866 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000857 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000855 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000934 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000920 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000866 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000870 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000838 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000847 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000903 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000844 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001166 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000836 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000885 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000842 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001311 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001255 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001189 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001172 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001148 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001167 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001127 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001196 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001231 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001229 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001291 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000716 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000914 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001461 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001211 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000687 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000890 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000821 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000888 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000903 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000902 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000734 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000873 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000784 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000863 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001277 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001220 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000933 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000868 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=1, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000895 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001242 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001155 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000862 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000250 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001260 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000890 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000906 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000864 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000864 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=10, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001514 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.230538\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000891 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3193\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238442\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000859 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.249173\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000890 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3190\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.265327\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000848 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3194\n",
            "[LightGBM] [Info] Number of data points in the train set: 5200, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.239288\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000958 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 6500, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.244554\n",
            "Decision Tree Best Parameters: {'criterion': 'poisson', 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
            "Random Forest Best Parameters: {'max_depth': 30, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "XGBoost Best Parameters: {'gamma': 0, 'learning_rate': 0.1, 'max_depth': 7, 'min_child_weight': 5}\n",
            "LightGBM Best Parameters: {'feature_fraction': 0.5, 'learning_rate': 0.1, 'max_depth': 10, 'min_data_in_leaf': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4dq8Pt_fM-e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**All models training and evaluation using all weather parametrs**"
      ],
      "metadata": {
        "id": "ZcrwoDe1AA6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Split the data into training and testing sets (e.g., 80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Convert the y_train and y_test DataFrames to 1D arrays\n",
        "y_train = y_train.values.ravel()\n",
        "y_test = y_test.values.ravel()\n",
        "\n",
        "# Create models with default hyperparameters\n",
        "random_forest_model = RandomForestRegressor()\n",
        "xgb_model = XGBRegressor()\n",
        "lgbm_model = LGBMRegressor()\n",
        "decision_tree_model = DecisionTreeRegressor()\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "num_folds = 10\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=0)\n",
        "\n",
        "# Create a dictionary to store results and hyperparameters for each model\n",
        "results = {}\n",
        "\n",
        "# Convert X_train to a NumPy array to simplify indexing\n",
        "X_train_np = X_train.to_numpy()\n",
        "\n",
        "# Perform 10-fold cross-validation for each model\n",
        "for model_name, model in [('Random Forest', random_forest_model), ('XGBoost', xgb_model), ('LightGBM', lgbm_model), ('Decision Tree', decision_tree_model)]:\n",
        "    mse_scores = []\n",
        "    r2_scores = []\n",
        "    rmse_scores = []\n",
        "    mae_scores = []\n",
        "\n",
        "    for train_index, val_index in kf.split(X_train):\n",
        "        X_train_fold, X_val_fold = X_train_np[train_index], X_train_np[val_index]\n",
        "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "        model.fit(X_train_fold, y_train_fold)\n",
        "        y_val_pred = model.predict(X_val_fold)\n",
        "\n",
        "        mse = mean_squared_error(y_val_fold, y_val_pred)\n",
        "        r2 = r2_score(y_val_fold, y_val_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(y_val_fold, y_val_pred)\n",
        "\n",
        "        mse_scores.append(mse)\n",
        "        r2_scores.append(r2)\n",
        "        rmse_scores.append(rmse)\n",
        "        mae_scores.append(mae)\n",
        "\n",
        "    # Store results and hyperparameters for the current model\n",
        "    results[model_name] = {\n",
        "        'Hyperparameters': model.get_params(),\n",
        "        'MSE': mse_scores,\n",
        "        'R2': r2_scores,\n",
        "        'RMSE': rmse_scores,\n",
        "        'MAE': mae_scores\n",
        "    }\n",
        "\n",
        "# Print results\n",
        "for model_name, metrics in results.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"Hyperparameters: {metrics['Hyperparameters']}\")\n",
        "    print(f\"Mean MSE: {np.mean(metrics['MSE'])}\")\n",
        "    print(f\"Mean R2: {np.mean(metrics['R2'])}\")\n",
        "    print(f\"Mean RMSE: {np.mean(metrics['RMSE'])}\")\n",
        "    print(f\"Mean MAE: {np.mean(metrics['MAE'])}\")\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "Ax21GEUWNAb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f114b38e-4791-45c6-ccf0-529d078fd2fd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000779 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.240462\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000785 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3192\n",
            "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.235094\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000789 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3195\n",
            "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.241299\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000792 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.238393\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000808 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3191\n",
            "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.245744\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000796 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.227983\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000815 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.253128\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000763 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3191\n",
            "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.262667\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000757 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3191\n",
            "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.253983\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000273 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.246786\n",
            "Model: Random Forest\n",
            "Hyperparameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
            "Mean MSE: 0.02700270830769228\n",
            "Mean R2: 0.9964593717789361\n",
            "Mean RMSE: 0.16364423051209998\n",
            "Mean MAE: 0.10848153846153843\n",
            "\n",
            "\n",
            "Model: XGBoost\n",
            "Hyperparameters: {'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': None, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n",
            "Mean MSE: 0.0292514305120115\n",
            "Mean R2: 0.9961595889246093\n",
            "Mean RMSE: 0.1708381022961593\n",
            "Mean MAE: 0.12470681005257826\n",
            "\n",
            "\n",
            "Model: LightGBM\n",
            "Hyperparameters: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n",
            "Mean MSE: 0.016627664972612276\n",
            "Mean R2: 0.9978181776594589\n",
            "Mean RMSE: 0.128666796208074\n",
            "Mean MAE: 0.09350032791561326\n",
            "\n",
            "\n",
            "Model: Decision Tree\n",
            "Hyperparameters: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}\n",
            "Mean MSE: 0.10982153846153848\n",
            "Mean R2: 0.9855897404382793\n",
            "Mean RMSE: 0.33102971290344607\n",
            "Mean MAE: 0.24003076923076921\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Define model names for plotting\n",
        "model_names = {'Decision Tree': 'DTR', 'Random Forest': 'RFR', 'XGBoost': 'XGBR', 'LightGBM': 'LGBMR'}\n",
        "\n",
        "# Create a 2x2 grid of subplots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "plt.subplots_adjust(hspace=0.3, wspace=0.3)  # Adjust vertical and horizontal spacing\n",
        "\n",
        "# Loop through metrics and assign each subplot\n",
        "metrics_to_compare = ['MSE', 'R2', 'RMSE', 'MAE']\n",
        "for i, metric in enumerate(metrics_to_compare):\n",
        "    row, col = i // 2, i % 2  # Calculate the row and column index\n",
        "\n",
        "    # Create a DataFrame for the current metric\n",
        "    data = []\n",
        "    for model_name, scores in results.items():\n",
        "        model_label = model_names[model_name]\n",
        "        data.extend({'Model': model_label, 'Metric': metric, 'Score': score} for score in scores[metric])\n",
        "\n",
        "    metric_df = pd.DataFrame(data)\n",
        "\n",
        "    # Plot using Seaborn\n",
        "    sns.boxplot(x=\"Model\", y=\"Score\", data=metric_df, ax=axes[row, col], palette=\"Set2\", order=['DTR', 'RFR', 'XGBR', 'LGBMR'])\n",
        "    axes[row, col].set_title(f'{metric} Comparison', fontsize=18)\n",
        "    axes[row, col].set_xlabel('Model', fontsize=20)\n",
        "    axes[row, col].set_ylabel(metric, fontsize=20)\n",
        "\n",
        "    # Increase tick label font size\n",
        "    axes[row, col].tick_params(axis='both', which='major', labelsize=16)\n",
        "\n",
        "# Use LaTeX formatting for RÂ²\n",
        "axes[0, 1].set_title(r'$R^2$ Comparison', fontsize=18)\n",
        "axes[0, 1].set_ylabel(r'$R^2$', fontsize=18)\n",
        "\n",
        "# Save the plot as an image file with 400 DPI resolution\n",
        "plt.savefig(\"all_weather_model_comparison_plot.png\", dpi=400, bbox_inches=\"tight\")\n",
        "\n",
        "# Download the plot from Colab\n",
        "from google.colab import files\n",
        "files.download(\"all_weather_model_comparison_plot.png\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "prveXOL9Bz-X",
        "outputId": "02328640-e65a-4a4c-e1bc-5c5b99da0ef1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-b94f6c61a6b4>:26: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.boxplot(x=\"Model\", y=\"Score\", data=metric_df, ax=axes[row, col], palette=\"Set2\", order=['DTR', 'RFR', 'XGBR', 'LGBMR'])\n",
            "<ipython-input-18-b94f6c61a6b4>:26: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.boxplot(x=\"Model\", y=\"Score\", data=metric_df, ax=axes[row, col], palette=\"Set2\", order=['DTR', 'RFR', 'XGBR', 'LGBMR'])\n",
            "<ipython-input-18-b94f6c61a6b4>:26: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.boxplot(x=\"Model\", y=\"Score\", data=metric_df, ax=axes[row, col], palette=\"Set2\", order=['DTR', 'RFR', 'XGBR', 'LGBMR'])\n",
            "<ipython-input-18-b94f6c61a6b4>:26: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.boxplot(x=\"Model\", y=\"Score\", data=metric_df, ax=axes[row, col], palette=\"Set2\", order=['DTR', 'RFR', 'XGBR', 'LGBMR'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d47550ae-77a5-4597-8f1b-f6f1e0996ac2\", \"all_weather_model_comparison_plot.png\", 405233)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x1000 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABUwAAAN5CAYAAADTn3HqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeViVdf7/8RdHIDkIooJICpamkqgFkWtpi5mZW7bYSCbpaEYWps03bWzUzLFmlKKFzClTBBqzLM1cUUfHFUFUELGm1FARUURAMNbfH3rOzxOgiMDx6PNxXV7i/dne98Hs5n1/FruysrIyAQAAAAAAAABksHYAAAAAAAAAAHC9IGEKAAAAAAAAABeRMAUAAAAAAACAi0iYAgAAAAAAAMBFJEwBAAAAAAAA4CISpgAAAAAAAABwEQlTAAAAAAAAALiIhCkAAAAAAAAAXETCFAAAAAAAAAAusrd2AAAAAAAAoLz9+/dr+fLl2r59u44ePSpHR0e1bt1aL7zwgnr37m3t8ADghmVXVlZWZu0gAAAAAACApddee03btm3TI488og4dOuj8+fP68ccftW/fPoWEhCg0NNTaIQLADYmEKQAAAAAA16GEhAR16NBBt9xyi/laSUmJhg0bpuTkZG3dulVubm7WCxAAblDsYQoAAAAAwHXonnvusUiWSlK9evX0yCOPqLi4WIcPH7ZOYABwgyNhCgAAAACADTl58qQkqXHjxlaOBNU1adIktWvXTpMmTbJ2KAAqwKFPAAAAAADUggcffFDHjx8vd91oNKpFixZ68MEHNXLkyKtaVp+RkaGlS5fqrrvuko+PT7VjKykp0Zo1a/Sf//xHe/fu1enTp3X+/Hm5uLjotttuU2BgoAYMGKC2bdtWewwAsFXMMAUA2KThw4erXbt2+uijj6wdCgAAQDlZWVnmZGnDhg3l7u4ud3d3NWzYUPn5+frpp5/02Wef6YknnlBGRkaV+iwoKNDLL7+swsJCvf3229WObc+ePerXr59ee+01LVu2TIcPH9b58+fl7Oys7Oxs7d69W/PmzdOAAQP0yiuvqLCwsNpjoWIeHh66/fbb5eHhYe1QAFSAGaYAqu2jjz7Sxx9/bP5zWFiYHn/88cu2GTNmjDZt2mT+8/r169WiRYty9bKysrR48WJt3rxZv/76q/Ly8tSgQQO5u7vL29tbAQEBCgwMVEBAQLm27dq1q/I9jBs3Tq+88kqV6/9RamqqfvjhB+3cuVPHjx9XTk6ObrnlFnl6eqpjx4565JFH1KtXLzk4OFR7DAAAANielJQU89eLFi2yeEbNzs7Whx9+qOjoaB0/flxhYWF67733LttfYWGhxo0bp5SUFH3wwQfy9fWtVlwbNmxQaGioCgsL5ebmplGjRqlPnz667bbbJF2YeZqSkqK1a9cqJiZGa9eu1fnz5+Xo6Fit8VCxiRMnauLEidYOA0AlSJgCqDFLly69bMI0IyNDW7ZsuWI/27dv1/jx45WdnW2+ZjQaVVxcrP/973/63//+p40bN0qSDh48WGk/RqNRRqPxsmNdqbwyeXl5mjp1qn788UeVlZVJkuzs7OTi4qLz58/rl19+0S+//KLvv/9ePj4+mj17tu66665qjYWKeXl56fbbb1ejRo2sHQoAAEA5+/fvlyTVr19fd9xxh0WZm5ub3nrrLSUkJCg1NfWKz8hFRUUaP368tm7dqlmzZqlPnz7Viunw4cP6y1/+osLCQt1xxx364osv1KxZM4s69erVU8eOHdWxY0eNGjVKb775ZrXGAgBbRsIUwDVr1KiRfv/9d23btk0nTpwo99BlsmzZMpWUlKh58+Y6duxYhXWOHz+ukJAQ5efnq3nz5nr55Zf1yCOPyNXVVZKUm5urvXv3asOGDVqxYsVl4xo5cuQ1zR6tzNmzZxUUFKSff/5ZdnZ2evzxx/WnP/1Jd911l/nNe0ZGhjZv3qxFixbp4MGDSkxMJGFaw/7xj39YOwQAAIBKmRKmvr6+qlevXrlyOzs7+fr6KjU1VWfPnq20n5KSEk2cOFHr16/XtGnT9MQTT1Q7pg8++EB5eXm65ZZb9PHHH1f63G7i5uamiIgI8wSBP9q5c6eio6OVmJioM2fOyNnZWb6+vho4cKAGDx5c4X0PHz5ccXFxGjdunF566SVFRUXp+++/15EjR1S/fn35+/vr1VdfNc+gLSgo0JdffqmVK1fq6NGjuuWWW9StWzdNmDChwj1cL+3/xRdf1IIFC/TDDz8oLS1NDg4O6tChg4KDg9WrV68K7+ns2bNau3attmzZol9//VUZGRkqKCiQu7u7AgICNHz4cN19992VfmaXjj927FgtWrRIK1as0G+//abc3FxFRkaqS5cumjRpkr777js98cQTevfdd8v1s3LlSi1dulQpKSk6e/asnJyc1LhxY7Vq1Ur333+/nnrqKd1yyy01/j0ZN26clixZoiVLluiXX35RWVmZ2rZtq2HDhmnQoEGV3jdwoyFhCuCaGY1GPfDAA/ruu++0dOlShYSEVFjv22+/lSQNGTKk0n0nFy9erPz8fDk4OCgqKkq33nqrRbmLi4vuu+8+3Xffffq///u/mr2RKnr99df1888/y97eXrNnz9Zjjz1Wro6np6eefvppPfXUU/rqq69kZ2dnhUgBAABgLaaEqZ+fX6V10tPTJV1YOVOR0tJSvfHGG1qzZo0mT56sP/3pT9WO59SpU1qzZo0kacCAAbr99tur3LaiZ9lZs2ZpwYIF5nIXFxfl5uZqx44d2rFjh5YvX65PPvlEDRo0qLDP4uJi/fnPf9b27dvl4OAgBwcHZWVlaf369dq+fbsiIyPVokULjRw5UikpKbrllltkZ2en7OxsrVq1SnFxcfrmm2/K/bxgUlRUpBdeeEHx8fGyt7eX0WhUTk6Otm3bpm3btlW6NVdkZKR527F69eqZ4z9+/LiOHz+uH3/8UW+++aaef/75y35mv//+u4YPH67ExETZ29vL2dm5yj8TTJ48WUuXLjX/2bTa7siRIzpy5Ig2btyoXr16ldva7Fq/JyUlJXr55Ze1fv162dvbq379+jp37pz27NmjPXv26MiRI3r11VerdA+ArePQJwA1YsiQIZKk7777rsLy+Ph4HT58WN7e3goMDKy0nwMHDkiS7rzzzkoffkzq169fzWirb9OmTdq8ebMkKSQkpMJk6aXs7Ow0bNgwDR06tFxZSUmJvvnmGz3//PPq0qWLOnTooPvvv1+vvvqqdu7cWWmflx52VFxcrAULFmjw4MHy9/dXt27dFBISotTUVHP9goICRUREqH///rr77rvVpUsXjR8/Xr/99luF/S9dulTt2rXTQw89JEnaunWr/vznP6tr167q1KmTHn/8cUVEROj333+vsH1RUZHWr1+vt956S0OGDNF9992nDh06qFu3bho1apRWrFhx2VkK7dq1M+/xlZKSookTJ6pnz57y8/PT8OHDK/wc/qi4uFiLFy/W8OHD1aVLF/n5+alLly569NFHNX78eC1ZsqTSz3fnzp169dVXdf/996tDhw7q0qWLRowYoW+//VYlJSUVtvnoo4/Url07c3zbt2/XmDFj1LVrV3Xs2FGPPfaYPv7440o/MwAAcGM5e/asjh49Kknq0KFDhXXi4+O1a9cuSdKjjz5aYZ1//OMf+uGHH+Tv769GjRpp2bJlFr/S0tKqHNPOnTtVWloqSXrkkUeu5nbKiYqKMifmhg4dqv/+97/atWuX4uPjNXnyZNnb22vHjh166623Ku0jJiZGBw4cUHh4uBITE7V7924tWbJE3t7eys/P18yZM/XWW2/p7Nmz+uKLL7Rnzx4lJiZqwYIFaty4sU6fPq2wsLDL9r9v3z5Nnz5du3fv1q5du/Sf//zH/Fl//PHHWr9+fbl2TZs21bhx4/Ttt99qz549iouL0759+xQbG2tOkr777rsWe9RWJDo6WgcPHtSsWbOUkJCguLg4bd++/YrnLcTHx2vp0qUyGAx6/fXXtXPnTiUmJmrPnj3asWOHvvjiCz3xxBPlzkioqe9JXFyc3n33XSUkJCghIUGbNm3Sgw8+KEn69NNPdfjw4cvGD9womGEKoEbce++98vHx0W+//aZdu3bp3nvvtSg3vSF94oknqvRm9eTJkyorK7vuZmZGR0dLujDT9YUXXqhyO4PB8v1Ubm6uQkJCFBcXJ+nC22tnZ2dlZmZqzZo1WrNmjUaOHKk33nij0j5r+6286X5nzJihsrIyubq6qqSkRP/73/8UHh6udevWacGCBWrYsKFFm927d1vMMm7QoIEcHR2VlZWlLVu2aMuWLVq3bp3ef//9cp/LpdasWaOJEyeqqKhIDRo0qHD5UEVKSko0ZswYbd261XzNxcVF+fn5ys7O1uHDh7Vq1So9/fTT5dpe61t5Sfr88881e/Zs87hFRUX69ddf9dFHHykuLk5ffvllle8FAADYpkuTaX+cYXrq1Cl9++23mjt3rkpLS3Xbbbdp7NixFfZjmqWamJioxMTEcuWzZs2St7d3lWL6+eefzV/feeedVWpTkfPnz5tfWPfv319vv/22ucxoNCo4OFj16tXTO++8o5UrV2rUqFEVJo1zcnIUHR1tMZmiU6dOmjFjhoKDg5WYmKj69etr+fLlatmypblOt27dNHHiRP31r3/VunXrVFRUVOEBq7m5uZo5c6aeeuop8zUvLy998MEHev7557Vr1y69//77evjhhy3aVTTRwc7OTt7e3vrrX/+qkpISRUdHKzo6WjNnzqz0c8rPz9enn35qnoQgqUp775u+z927d9fo0aMtyho1amRebXepmvqenD17VgsXLlTXrl3N15o1a6YPP/xQDz/8sE6ePKlVq1bppZdeuuJ9ALaOGaYAaoSdnZ15PyXT0nuT/Px8rVq1SgaDwTwTtTKdOnWSJJ04cULvvfee8vPzayfgaiguLjbPAujevXu1D4ySpL/+9a+Ki4uTg4ODpkyZooSEBO3atUv//e9/9eSTT0qS5s+fr6+++qrSPmr7rXxWVpZmzZqlRx99VP/5z3+0a9cuJSQkaNq0aXJ0dFRKSor++te/lmvn5OSkoUOH6ssvvzS/md69e7d27typv/71r2rQoIFWr16tqKioy35GkyZNUvfu3bVy5UolJCRo3759mjFjxhU/2xUrVmjr1q265ZZb9M4772j37t2Kj4/Xvn37tG3bNn388ccVzuKoibfyqampmjNnjsaMGaNt27aZ27/88suSLszsqGwWNgAAuHGYEp2S9MILL6hHjx7q0aOHAgIC1KNHD4WFhSk/P189evRQZGRkpS9jTfvhV/brSs/Wl7r0QFU3N7fq3pq2bt1q7mvcuHEV1hk2bJg8PDwkqdJzB+65554KV5517tzZfC7Ao48+apEsNbn//vslXUgUHjlypML+vby8zM/VlzIYDOaE388//3zZQ2QrYtr7NCEh4bL12rRpY5EsrSrT2Q1ZWVmVrm76o5r6ngQEBFgkS00cHR3NSdqr/bwAW0XCFECNeeKJJ2QwGLRmzRqdO3fOfH3VqlXKz89Xt27dKt2fyWTYsGFq2rSpJOnLL79Ujx499Oc//1nh4eGKjY3V6dOnqxzP/PnzzQ+nlf0y7RtVFcePHzcncNu3b1/ldn+0d+9e8/5Rb731loYPHy4nJydJkoeHh/7+97+bE3rh4eGVLuPOycnRJ598or59+8rBwUF2dnbmt/LShbfT//3vf/Xll1/qvvvuk8FgkMFgML+Vl2R+K1+RgoIC+fv76/333zd/3+rXr68//elP+tvf/mZuv2/fPot2nTp10ttvv63u3btbPPy7ubnp+eefN7+JX7Ro0WU/pzvuuEOffvqpWrdubb522223XbaN6b4lafDgwXr66afl7Ows6UJSv0mTJnrkkUf04YcfWrSp6K286YHS9FZ+0qRJki5swJ+cnFzh2Dk5OQoJCdGECRPUuHFjSRdm2L766qvm02x//PHHK94DAACwbZfOMD19+rROnTqlU6dOmZ+RTcut58+fL09PT2uFWS2m5yAvL69K90GtV6+eOfFW2XOTaaJERW1NMzE7duxYYZ0mTZqYv67swKzOnTtXulotMDBQ9vb2lcaXlpam9957T0OGDFFgYKDuvPNO87ZRY8aMkXThkNfLCQgIuGx5Zbp166ZbbrlFKSkpCgoK0pIlS6649UJNfU8ud0it6We0yx1QBtxISJgCqDFeXl7q3r27eUapiWk5fkVveP+ocePGiomJUY8ePSRdmJ363//+VxEREXr55ZfVvXt3DRkyREuXLjXvwVSZ/Px888NpZb+q+tZWsnwr/8dl6Fdj5cqVki4sb6loWbgkhYaGSpLOnDljsbT8UrX9Vl6SXnrppQqXzT/55JPmU1VN91NVDzzwgCTpt99+U2ZmZqX1Ro0aVa2l66a38pfr+49q6q28o6OjRo4cWWGZabkXb+UBALjxmWaYPv/88+bZoElJSVq5cqX69++v0tJShYWFafv27XUW06WzSi99rr1apgkMV0r0mp4VK5vwYHqpXRFTMrOyOqZy6cIqsIpcLr5bbrnF/Hn8Mb5169apX79+mj9/vvbv36/c3FwZjUY1adJE7u7u5p8DrrQSzvTy/Gr5+PjonXfekdFoVGJioqZMmaLevXurW7duGj9+vGJjY8udB1CX35PKPm/gRkPCFECNMi0LMi3LP3LkiOLj49WwYUP17t27Sn14e3tr/vz5WrlypSZOnKiHH37YYp/N/fv3a/LkyRo9evRlD9EZN27cZZcwHTx4sNzJknXB9Ea3S5cule7h2bp1a/MDj7Xeytvb21d6QJfBYFDnzp0rjS8vL0+ff/65nnvuOXXr1k0dOnQwv5W/9M31iRMnKuxfqv5b+Z49e8rOzk4bNmzQn//8Z61YseKKMwBq6q18mzZtKn3Q5K08AAA3h7y8PPML6Uv3CnV0dFTr1q01e/Zs+fn5qbS0VBEREXUWV5s2bcxfmw5ahaUzZ85o0qRJKiwsVNeuXbVo0SLt3btXCQkJ2rZtm7Zu3arw8PAq9XUte9YPHDhQGzdu1PTp09WvXz95eXkpKytLq1at0ssvv6znnntOeXl51e4fwJVx6BOAGvXII4+oYcOG2r17tw4fPmzer/Hxxx/XLbfcclV9tW7d2mI5dmZmptavX6958+bp2LFj2rJliz744IPLHoxUky59K38tSa+reQOckZFhtbfyjRo1Ms9UrYgp/j/Gd+jQIQUHB1skQ52cnOTi4mJOEJ86dUrShWX/lbk0qXs1AgMD9frrr+uDDz7Qf//7X/33v/+VdOHz7N69uwYNGlRub6a6eCtvemjmrTwAADe2lJQU8wzAig5XsrOz0/PPP6833nhDcXFxSktLq/LBTdfC9LK+tLRU69atM6/6uVqmZ7TLvfi+tLy6z3TX6nIvzAsLC82zbC+Nb9OmTcrLy1PDhg01d+5c87ZZl7qaVUzXws3NTc8++6yeffZZSRdWZy1ZskT/+te/FB8fr48++kiTJ0+2uIfr/XsC2BJmmAKoUY6Ojnr88cclSUuWLNH3338vSVe1IX1lPDw89Oyzz+rrr782/0/+22+/veLS/Jpy6623mg96unRfKliaPHmyTpw4oebNmys8PFw7d+7Unj17tH37dm3dulWbN2821/3jcqJLXctb+T//+c9av369Jk+erN69e6tJkyY6ceKEli5dqhEjRujVV1+tdO9WAACAa2F6TnRwcLB4+X+p3r17m092N+1tX9vc3d3Ne6qvWLFChw4dqnLbS5/ZTKernzhxotI+SkpKtHPnTkmVr3iqbbt27ar0WTM+Pt78EvvS0+JNCcXbb7+9wmSppDrdRuFSPj4+mjhxovr37y9J2rZtm7nMVr4ngC0hYQqgxpmSowsXLtSJEyfUtm3bGv2fsru7u3k/yLNnzyorK6vG+r4ce3t73XvvvZIuPKBcad+iytjKG+AzZ86osLCw0nLTW/tL40tPTzcfuhQWFqa+ffuWO4XVNLu0tnl6eio4OFiffPKJtm3bpuXLl5v3jF2zZo2++uorc11b+Z4AAIDrn2nrntatW1e6WqdBgwbm7YdiY2PrLLbx48fLaDTq/PnzeuWVV664bdHZs2f1yiuvKDc313ytR48e5ue7jz/+uMJ2//73v3Xy5ElJMk+mqGvHjx83r3a7VGlpqebOnSvpwiGj7dq1M5e5uLhIkg4fPlzh1l8HDhzQDz/8UEsRX3C552/pwiGskiwOtLKV7wlgS0iYAqhxHTt2VNu2bc0z+Kpy2NPVMs30lHTZZeM1LSgoSJKUm5urL7/8ssrtLp0Fa3oDvHPnzkpnx/7yyy/mB1hrvQEuLi5WQkJChWVlZWXatWuXJMu38unp6eav27dvX2HbS9+G16V27drpnXfeMf9wwlt5AABQG0wzTCtajn8p05L4vXv31tky79tvv13//Oc/5eDgoJ9//lmDBg3SvHnzLA4BLSkpUUpKisLDw9W7d2+tXbvWoo/69evrlVdekXRhpurf/vY3i+2WIiMjNWvWLElSv379LJ4V65KLi4umTZumr7/+2pz8TE9P14QJE8zPdOPHj7do06NHDxkMBmVnZ+v11183P48XFhZq5cqVGjly5GW3YKoJb7/9tkJDQ7VmzRqLbaDOnTunr776yryC79ItFWzlewLYEvYwBVArXn/9de3YsUPShU3Lqyo+Pl5+fn6VLoGRLjwsrFu3TpLUokUL86nodaFXr1667777tGXLFkVERKh169bq27fvZdssXrxYZWVl5v2HHn/8cS1YsEAZGRlasmSJhg4dWq7Nhx9+KOnCPqLdu3ev+Rupok8//bTCw6m+++47c3K0X79+5uumt/KSlJqaWu5gqry8PH366ae1GPGFB9rLJdEv91Y+OztbH3/8sebMmVOuHW/lAQDAleTn55tfvvr6+l62bq9evfTee++ptLRU69evNz8r1rbevXtr4cKFmjx5so4cOaI5c+Zozpw5cnBwkLOzs3Jycswv9e3s7NS/f/9yz+bPPfec0tLStGDBAi1evFhff/21XF1dde7cOfNS9y5dumjGjBl1ck8VGTZsmOLj4/XWW2/p7bffltFotDiH4KWXXtIjjzxi0ea2227TqFGj9K9//Utr167V2rVr5eLiovPnz6uoqEgtWrTQ+PHj9frrr9da3MXFxVq9erVWr14t6cJEEXt7e+Xk5Jjr3HPPPRo7dqxFO1v4ngC2hIQpgFrRq1cv9erV66rbRUZGaufOnerfv78efvhhderUSQ0aNJB0Idm2efNmffrppzp27JgkaeTIkTUad1XMnj1bQUFB+uWXXzR+/Hg9/vjj+tOf/qS77rrLvBfVyZMntXXrVi1atEj79+83b8guXTjd/tFHH9WaNWs0Y8YMFRUV6cknn5STk5MyMzMVHh5ufkAKDQ296sOyaoqTk5N2796tiRMn6o033lCzZs30+++/6/vvv9fMmTMlyfw9MmndurVuvfVWHT9+XG+++abeffdd8xvsxMREzZgxo9ZPiQ8JCZGHh4f69u0rf39/c0I9OztbMTEx5n2nKnorP2PGDK1YsULOzs569dVX5e7uroKCAi1ZskT/+Mc/JPFWHgAAVO7AgQPmZOOVZpi2bt1a3t7eSktLU2xsbJ0lTKULCbdVq1Zp9erV2rhxo/bt26fTp0/r3LlzatiwoVq1aqV7771XgwYNUqtWrSrsY/LkyXrwwQcVExOj3bt3Kzs7W87OzvL19dWgQYM0ePDga9qT/lo5ODhowYIF+vLLL7VixQqlpaXJxcVFHTp00AsvvFDpzyqvv/667rjjDkVHR+unn35ScXGxfHx89Mgjj+jPf/5zrZ9lEBISIj8/P+3cuVO//PKLTp06pfz8fDVp0kS+vr56/PHHK/1sr/fvCWBLSJgCuK7Y29srOztbUVFRioqKknTh5PGysjKLPUMNBoNGjRplXiJfkfnz5+vf//73Zcfz9/evdJ+fyjRq1Ehff/21pkyZotWrV2vFihVasWKF7Ozs5OrqqvPnz1vsedS6dWsFBgZa9DFz5kydOXNGcXFxmjFjhmbNmmV+o2/anH7kyJH605/+dFWx1aTGjRtr1KhRmjFjhlauXKmGDRsqPz/fvNWCr6+vOXFqYjAY9Le//U3jxo3Tzz//bE4ESxeWAxmNRkVERCg4OLjW4v7999+1dOlSLV26VJIsEu4mjz76qHk/UxPeygMAgGt1zz336ODBg1WuX5f7l/5RvXr19Pjjj1/TypmuXbuqa9euV9Vm0aJFV6yzYcOGK9apyufs6OioF198US+++GKVYjMZPHiwBg8eXGFZly5dLjt2Ve5Pkt599129++675a77+Pho+PDhGj58eJX6+aPa+p688sor5mX/wM2AhCmA68o//vEPPfPMM9q2bZv27dunQ4cOKSsrS6WlpWrYsKF8fHx0zz336IknnrjiMqf8/PwrHsxU3dmODRo00AcffKDU1FQtW7ZMcXFxOn78uHJycnTLLbeoRYsW6tSpk/r27av777+/3JtcFxcXLViwQN99952WLVumgwcPKj8/X+7u7goICFBQUJC6dOlSrdhqUlBQkG677TZ9+eWXSkpKkp2dnVq1aqX+/ftr1KhR5uXtl3rwwQcVFRWluXPnavfu3SooKJCHh4cee+wxjR49utJZCjVlypQp2rx5s3bt2qUjR44oMzNThYWFatq0qTp06KAnnnjCfELsH/FWHgAAAABgV2aaygQAgKSlS5dq8uTJat68eZXe7gMAAADXi+HDhysuLk7jxo1jRiSAarP5GaarVq1STEyMUlNTVVRUJB8fHw0YMEDBwcHmvQSr4syZM9q4caP279+v/fv368CBAzp//ry6deumBQsWXFVMqampeuqpp8zxmA6nAQAAAAAAAHB9s+mE6cyZMxUZGSl7e3t17dpVRqNRO3bs0OzZs7Vx40bNnz+/wuWiFUlISLA4lKW6CgsL9X//93/m/e4AAAAAAAAA2A6bTZjGxsYqMjJSRqNRUVFR8vPzkyRlZWVpxIgRSkhIUHh4uN54440q9dekSRMNHTpUfn5+at++vfbv36+pU6dedVyffPKJDh48qOeee858YA0AAAAAAKh9VT10CQAux2DtAKpr7ty5kqQxY8aYk6XShVOdTYnOqKgo5ebmVqk/f39/vf322xo6dKg6duwoR0fHq45p3759+te//qW+fftWeqAIAAAAAAAAgOuXTSZMMzIylJSUJEnq379/ufLAwEB5eXmpsLBQmzZtqpOYfv/9d02aNEmurq7629/+VidjAkBtGDJkiA4ePMiBTwAAAACAm5JNLslPSUmRJLm5ucnb27vCOh06dFB6erpSUlIqTKrWtA8++EC//PKL5syZoyZNmuh///tfjfUdGBiowsJCeXh41FifAAAAl8rMzJSjo6Pi4+OtHQpuUjzzAgCA2nQ1z7s2mTA9evSoJMnLy6vSOs2aNbOoW5t2796tBQsW6OGHH66V5Ozvv/+ukpKSGu8XAADApLi4WGVlZdYOAzcxnnkBAEBtuprnXZtMmJ47d06S5OTkVGkdZ2dni7q1paCgQJMnT5aLi4umTZtWK2M0bdpUkrR+/fpa6R8AAODhhx+2dgi4yfHMCwAAatPVPO/aZML0ejJnzhwdPnxY7733nvkhDwAAAAAAAIBtsslDn0yzRwsKCiqtY5pZaqpbG3bu3KmoqCj16tVLgwcPrrVxAAAAAAAAANQNm5xh2rx5c0lSenp6pXVOnDhhUbc2xMbGqqysTOnp6Ro+fLhFWU5OjiQpIyPDXPbmm2/qzjvvrLV4AAAAAAAAAFwbm0yYtm/fXpKUnZ2ttLQ0eXt7l6uTnJwsSfLz86v1eH766adKy37//XfFxcVJ+v9JVAAAAAAAAADXJ5tckt+sWTN17NhRkrRixYpy5fHx8UpPT5ejo6N69epVa3H89a9/1cGDByv8FRkZKUny8fExX+vSpUutxQIAAAAAAADg2tlkwlSSxo4dK0maN2+e9u/fb75+5swZTZ8+XZL03HPPycXFxVy2bt069e3bVyNGjKjbYAEAAAAAAADYBJtcki9JvXv31vDhw7Vo0SINHTpUXbt2ldFo1Pbt25WTk6OAgACFhoZatMnNzdWhQ4dUWFhYYZ/PPPOM+eusrCxJUlJSksX1kJAQPfDAAzV/QwAAAAAAAACszmYTppI0ZcoUBQQEKCYmRomJiSouLpaPj49Gjx6t4OBgOTo6XlV/e/fuLXctLy/P4ropkQoAAAAAAADgxmPTCVNJ6tevn/r161elukOGDNGQIUMqLT948GBNhaUuXbrUaH+4oLS0VKmpqcrOzpabm5t8fX1lMNjszhIAAAAAAAC4zth8whQ3j7i4OEVHRyszM9N8zcPDQ0FBQercubMVIwMAAAAAAMCNgoQpbEJcXJzCw8Pl7++vcePGydvbW2lpaVq2bJnCw8MVGhpK0hQAAAAAAADXjLXMuO6VlpYqOjpa/v7+mjBhgtq0aaP69eurTZs2mjBhgvz9/RUdHa3S0lJrhwoAAAAAAAAbxwxTXPdSU1OVmZmpcePGlduv1GAwaODAgZo2bZpSU1PVvn17K0UJAAAAAABQNRkZGcrPz7d2GDXOaDTK09PT2mFcMxKmuO5lZ2dLkry9vSssN1031QMAAAAAALhe5eTkaMKECSorK7N2KDXOYDAoIiJCrq6u1g7lmpAwxXXPzc1NkpSWlqY2bdqUK09LS7OoBwAAAAAAcL1ydXVVWFhYncwwPXbsmCIiIhQSEqLmzZvX+nhGo9Hmk6USCVPYAF9fX3l4eGjZsmWaMGGCxbL80tJSLV++XB4eHvL19bVilAAAAAAAAFVT18vWmzdvrttvv71Ox7RlHPqE657BYFBQUJASExMVFhamn376SQUFBfrpp58UFhamxMREBQUFldvfFAAAAAAAALhazDCFTejcubNCQ0MVHR2tadOmma97eHgoNDRUnTt3tl5wAAAAAADA5p06dUq5ubnWDqNGHTt2zOL3G4mLi4vc3d1rpW8SprAZnTt3VmBgoFJTU5WdnS03Nzf5+voysxQAAAAAAFyTU6dO6fWJr6uwqNDaodSKiIgIa4dQ4xwdHDV7zuxaSZqSMIVNMRgMat++vbXDAAAAAAAAN5Dc3FwVFhXqyXYPycPoZu1wcAWZ+dn69uAG5ebm1krClKl5AAAAAAAAgCSpzNoBoEpq9/vEDFMAAAAAAABA0rcHN1o7BFwHSJgCAAAAAAAAkh5qea8a1W9g7TBwBWfO52nDkV211j8JUwAAAAAAANzUXFxc5OjgWKtJONQsRwdHubi41ErfJEwBAAAAAABwU3N3d9fsObOVm5tbJ+NlZWWpoKCg1sfJzMzUkiVL9PTTT8vDw6PWx3NyclLjxo1rfRzpQpK7Ng58kkiYAgAAAAAAAHJ3d6+1BNylcnJyNGXKFJWV1d0BU0uWLKmTcQwGgyIiIuTq6lon49UWEqYAAAAAAABAHXF1dVVYWJjy8/OtHUqNMxqNNp8slUiYAgAAAAAAAHXK09PT2iHgMgzWDgAAAAAAAAAArhfMMAUAAAAAALBRpaWlSk1NVXZ2ttzc3OTr6yuDgflxwLUgYQoAAAAAAGCD4uLiFB0drczMTPM1Dw8PBQUFqXPnzlaMDLBtJEwBAAAAAABsTFxcnMLDw+Xv769x48bJ29tbaWlpWrZsmcLDwxUaGkrS9CbH7OPqI2EKAAAAAABgQ0pLSxUdHS1/f39NmDDBnARr06aNJkyYoLCwMEVHRyswMJAE2U2K2cfXhv9qAAAAAAAAbEhqaqoyMzM1aNCgcglRg8GggQMHKjMzU6mpqVaKENZkmn3s7e2t6dOna/78+Zo+fbq8vb0VHh6uuLg4a4d43WOGKQAAAAAA1yAjI0P5+fnWDqPGGY1GeXp6WjsMVCA7O1uS5O3tXWG56bqpHm4ezD6uGSRMAQAAAACoppycHE2YMEFlZWXWDqXGGQwGRUREyNXV1dqh4A/c3NwkSWlpaWrTpk258rS0NIt6uHmYZh+PGzeu0tnH06ZNU2pqqtq3b2+lKK9/JEwBAAAAAKgmV1dXhYWF1ckM02PHjikiIkIhISFq3rx5rY9nNBpJll6nfH195eHhoWXLllnMIpQuzDBcvny5PDw85Ovra8UoYQ3MPq4ZJEwBAAAAALgGdb1svXnz5rr99tvrdExcXwwGg4KCghQeHq6wsDANHDhQ3t7eSktL0/Lly5WYmKjQ0FCWXN+EmH1cM0iYAgAAAABuSKdOnVJubq61w6gxx44ds/j9RuLi4iJ3d3drh2FTOnfurNDQUEVHR2vatGnm6x4eHgoNDeUk9JsUs49rBglTAAAAAMAN59SpU3p94kQVFhVZO5QaFxERYe0Qapyjg4Nmz5lD0vQqde7cWYGBgUpNTVV2drbc3Nzk6+vLzNKbGLOPawYJUwAAAADADSc3N1eFRUV6rKWrmtSvZ+1wcBmnz5do1ZEc5ebmkjCtBoPBwOE9sMDs42tHwhQAAAAAcMNadSTH2iEAQJ1j9vG1sfmE6apVqxQTE6PU1FQVFRXJx8dHAwYMUHBwsBwcHKrcz5kzZ7Rx40bt379f+/fv14EDB3T+/Hl169ZNCxYsqLTdr7/+qs2bN2vr1q1KTU3VmTNn5OjoqNtvv119+vTRc889J2dn5xq4UwAAAADA1XquXSN5Gqv+syHqXkZ+kaIOnrF2GMANh9nH1WfTCdOZM2cqMjJS9vb26tq1q4xGo3bs2KHZs2dr48aNmj9/vurXr1+lvhISEjR58uSrjiE4OFgZGRm65ZZb1KFDB9177706deqU9uzZo+TkZH3zzTdauHChbr311qvuGwAAAABwbTyNDvJu4GjtMHCTysjIUH5+vrXDqHFGo1Genp7WDgOoNTabMI2NjVVkZKSMRqOioqLk5+cnScrKytKIESOUkJCg8PBwvfHGG1Xqr0mTJho6dKj8/PzUvn177d+/X1OnTr1iu9tvv12vvvqqHnvsMYuZpEePHtXYsWP1888/a9KkSYqMjKzejQIAAAAAAJuTk5OjCRMmqKyszNqh1DiDwaCIiAi5urpaOxSgVthswnTu3LmSpDFjxpiTpZLUuHFjTZ06VUFBQYqKilJISIhcXFyu2J+/v7/8/f3Nf/7555+rFMfChQsrvN6iRQtNmzZNQUFB2rlzp06cOKFmzZpVqU8AAAAAAGDbXF1dFRYWViczTI8dO6aIiAiFhISoefPmtT6e0WgkWYobmk0mTDMyMpSUlCRJ6t+/f7nywMBAeXl5KT09XZs2baqwTl24dJ+I9PR0EqYAAAAAANxE6nrZevPmzXX77bfX6ZjAjcgmE6YpKSmSJDc3N3l7e1dYp0OHDkpPT1dKSorVEqZHjhwxf+3h4WGVGAAAAADgZpaRX2ztEHAFfI8AXG9sMmF69OhRSZKXl1eldUyzOU11rWHevHmSJD8/P7Vo0cJqcQAAAADAzcbFxUWODg6KOphl7VBQBY4ODlXaTg8A6oJNJkzPnTsnSXJycqq0jukAJlPdurZ06VKtXLlS9erV05tvvmmVGOoap/8BAAAAuF64u7tr9pw5ys3NrfWxsrKyVFBQUOvjZGZmasmSJXr66afrZBWjk5OTGjduXOvjSBcS3O7u7nUy1qlTp+rk70VdOnbsmMXvN5K6/LsBmNhkwvR6t337dv3tb3+TJP3lL39RYGCglSOqfZz+BwAAAOB64+7uXuuJlpycHE2ZMqVOfxZasmRJnYxzI/4sdOrUKU18/XUVFRZaO5RaERERYe0QapyDo6PmzJ5N0hR1yiYTpqbZo5d7g2eaWWqqW1fi4+MVEhKioqIijRs3Ti+88EKdjm8tnP4HAAAA4GZUlz8L1bUb8Weh3NxcFRUWqu1dvWVs0Mja4eAK8vPO6Ke9scrNzSVhijplkwlTU5IsPT290jonTpywqFsXdu/erTFjxig/P19jx47VK6+8UmdjXw84/Q8AAADAzYgtvADgxmKTCdP27dtLkrKzs5WWliZvb+9ydZKTkyVdOHCpLuzZs0d//vOfde7cOY0dO1avvfZanYwLAAAAAACuzk97Y60dAoDrmE0mTJs1a6aOHTsqKSlJK1as0EsvvWRRHh8fr/T0dDk6OqpXr161Hs++ffs0atQokqUAAAAAANgAluTbBtOSfKCuGawdQHWNHTtWkjRv3jzt37/ffP3MmTOaPn26JOm5556Ti4uLuWzdunXq27evRowYUWNxJCUlaeTIkcrLyyNZCgAAAAAAANg4m5xhKkm9e/fW8OHDtWjRIg0dOlRdu3aV0WjU9u3blZOTo4CAAIWGhlq0yc3N1aFDh1RYyWl4zzzzjPnrrKwsSRcSopdeDwkJ0QMPPGD+86hRo5SbmytXV1dlZGRo0qRJFfY9evRotW7durq3CwAAAAAArpGLi4scHB2ZtWhDHBwdLSbDAXXBZhOmkjRlyhQFBAQoJiZGiYmJKi4ulo+Pj0aPHq3g4GA5OjpeVX979+4tdy0vL8/iuimRanL27FlJUk5Ojr777rtK+37iiSdImAIAAAAAYEXu7u6aM3u2cnNza32sc+fOadasWSorK6v1seqawWDQpEmT5OzsXOtjubi4yN3dvdbHAS5l0wlTSerXr5/69etXpbpDhgzRkCFDKi0/ePDgVY9fnTYAAAAAAMA63N3d6ywBFxYWpvz8/DoZqy4ZjUZ5enpaOwyg1th8whQAAAAAAOB6RFIRsE02e+gTAAAAAAAAANQ0EqYAAAAAAAAAcBFL8gEAAAAAAGxUaWmpUlNTlZ2dLTc3N/n6+spgYH4ccC1ImAIAAAAAANiguLg4RUdHKzMz03zNw8NDQUFB6ty5sxUjA2wbCVMAAAAAAAAbExcXp/DwcPn7+2vcuHHy9vZWWlqali1bpvDwcIWGhpI0BaqJOdoAAAAAAAA2pLS0VNHR0fL399eECRPUpk0b1a9fX23atNGECRPk7++v6OholZaWWjtUwCYxwxQAAACoI6tWrVJMTIxSU1NVVFQkHx8fDRgwQMHBwXJwcLiqvgoKChQZGamVK1fqyJEjsrOzU6tWrTR48GANGzZM9erVq7BdcXGxFi9erGXLlul///ufSkpK5OPjo759+2rUqFGqX79+uTZHjx7Vww8/fNl4Ro8erddff/2q7gFA1RUXF2vt2rU6efKkmjZtqj59+sjenh/pb1apqanKzMzUuHHjyu1XajAYNHDgQE2bNk2pqalq3769laIEbBf/ugIAAAB1YObMmYqMjJS9vb26du0qo9GoHTt2aPbs2dq4caPmz59fYbKyItnZ2RoxYoRSU1Pl7OysgIAAGQwG7d27V++88442btyouXPnytHR0aJdYWGhXnzxRW3btk2Ojo66++675ezsrH379unDDz/U2rVrtWjRIrm6ulY4rtFo1KOPPlphmZ+f39V9IACqLCYmRitXrrSYLRgTE6N+/fpp2LBhVowM1pKdnS1J8vb2rrDcdN1UD8DVIWF6gzt16pRyc3OtHUaNOnbsmMXvNxIXFxe5u7tbOwwAAFDDYmNjFRkZKaPRqKioKHNyMSsrSyNGjFBCQoLCw8P1xhtvVKm/qVOnKjU1VW3bttW8efPk5eUl6cKz30svvaStW7fqk08+0WuvvWbR7oMPPtC2bdvk6empzz//XG3btpUk5eXlaeLEifrPf/6j6dOna86cORWO26hRI7377rvV/RgAVENMTIxWrFihhg0b6umnn1ZAQIB2796tJUuWaMWKFZJE0vQm5ObmJklKS0tTmzZtypWnpaVZ1ANwdUiY3sBOnTqlia+/rqLCQmuHUisiIiKsHUKNc3B01JzZs0maAgBwg5k7d64kacyYMRYzMRs3bqypU6cqKChIUVFRCgkJkYuLy2X7ysjI0Jo1ayRJU6ZMMSdLJcnd3V0zZszQoEGDtGDBAo0ePVoNGjSQJBUVFemrr76SJI0fP96cLJWkBg0a6J133lHv3r31448/6tVXX1XLli1r5uYBVFtxcbFWrlyphg0b6qOPPjIvwX/ooYfUs2dPvfLKK1q5cqWeeeYZluffZHx9feXh4aFly5ZpwoQJFsvyS0tLtXz5cnl4eMjX19eKUQK2i39Rb2C5ubkqKiyUW49Osm/obO1wcAXFZ88pe+s+5ebmkjAFAOAGkpGRoaSkJElS//79y5UHBgbKy8tL6enp2rRpU4V1LpWcnKyysjI5ODjo3nvvLVfu6+urxo0bKysrS5s3b1a/fv0kSb/88ovy8/MlSd27dy/XzsPDQ23atFFSUpLWrFmjMWPGXPW9AqhZa9euVWlpqZ5++ulyCVF7e3s99dRT+uKLL7R27Vrzf+u4ORgMBgUFBSk8PFxhYWEaOHCgvL29lZaWpuXLlysxMVGhoaHl9jcFUDUkTG8C9g2d5dCkobXDAAAAuCmlpKRIurAssrK95jp06KD09HSlpKRcMWFqSnq6urpW+oNwo0aNlJWVpeTkZHMSxdTOFEtl7SRp//79lY49b948HT16VA4ODvL29lbPnj3VqlWry8YMoHpOnjwpSQoICKiw3N/f36Iebi6dO3dWaGiooqOjNW3aNPN1Dw8PhYaGqnPnztYLDrBxJEwBAACAWnT06FFJslg6/0fNmjWzqHs5TZo0kSSdPn1a586dk7Oz5Uqi0tJSHT9+vFx/pnbSlfe8qyyOM2fOlNvf9N1339WAAQM0bdq0crEAuDZNmzaVJO3evVsPPfRQufLExESLerj5dO7cWYGBgUpNTVV2drbc3Nzk6+vLzFLgGvFfEAAAAFCLzp07J0lycnKqtI4p0WiqezmdOnUy97VkyZJy5d9//70KCgrK9deyZUvdeuutkqSvv/66XLudO3fq0KFDki4cAnUpR0dHPfPMM/riiy+0adMm7d27Vz/++KNCQ0Pl5OSk5cuX69VXX1VZWdkV4wdQdX369JHBYNCSJUtUXFxsUVZcXKxvvvlGBoNBffr0sVKEuB4YDAa1b99e3bt3V/v27UmWAjWA/4oAAAAAG9KgQQO98MILkqSwsDBFRkbq5MmTOn36tJYsWaIZM2bIwcFBkmRnZ2fR9uWXX5YkRUVFKTw8XMeOHdPZs2e1evVqvfbaa+Z2f/xhu2nTppoxY4buu+8+NWvWTPXr19cdd9yhkJAQLVy4UPXq1dOWLVu0fv362r594KZib2+vfv366ezZs3rllVe0fv16ZWVlaf369XrllVd09uxZ9evXjwOfAKCG8a8qAAAAUItMs0dNsz4rYpoJWtUl7ePGjVNWVpb+/e9/a+bMmZo5c6a57N5771WrVq20ePFiNWxouY/9U089pRMnTigiIsL8y6Rt27Z6+umnNXfu3HLtLqdTp0568MEHFRsbqw0bNqh3795VbgvgyoYNGyZJWrlypb744gvzdYPBoP79+5vLAQA1h4TpTaD4bN6VK8Hq+D4BAHBjat68uSQpPT290jonTpywqHsl9erV0/Tp0zVs2DBt2LBB6enpMhqN6ty5sx544AH95S9/kSS1a9euXNtx48Zp0KBBWrt2rX777Tc5ODjo7rvvVp8+ffTxxx9LupA8vRqtW7dWbGysMjIyrqodgKoZNmyYnnnmGa1du1YnT55U06ZN1adPH2aWAkAt4V/Xm0D21iRrhwAAAHDTat++vSQpOztbaWlp8vb2LlcnOTlZkuTn53dVfbdr165cUrSsrEy7d++WJHXv3r3Cdt7e3ho1alS56/Hx8ZKkHj16XFUc2dnZkqo+QxbA1TMtzwcA1D4SpjcBtx4dZd+wgbXDwBUUn80juQ0AwA2oWbNm6tixo5KSkrRixQq99NJLFuXx8fFKT0+Xo6OjevXqdc3jrVq1SsePH5e/v786dOhQ5XZ79uxRQkKCvLy89PDDD1e5XX5+vjZs2CBJ6tix41XHCwAAcL0hYXoTsG/YQA5Nqr4PFQAAAGrW2LFj9fLLL2vevHnq2bOneSbpmTNnNH36dEnSc889JxcXF3ObdevWac6cOfL09NTChQst+svIyFBpaam8vLwsrm/cuFFvvfWWHB0dNW3atHJxnD17VqdPn1arVq0sru/Zs0evvPKK7Ozs9Pbbb5db5rt48WL17Nmz3HhpaWl66623lJmZKVdXVz355JNX98EAAABch0iYAgAAALWsd+/eGj58uBYtWqShQ4eqa9euMhqN2r59u3JychQQEKDQ0FCLNrm5uTp06JAKCwvL9ZeUlKRx48bJ19dXLVq0kL29vQ4ePKhff/1VRqNRn3zyiXx9fcu1O378uAYPHqzWrVvLx8dHRqNRhw4dUkpKihwcHDRz5kz17NmzXLuYmBhNnTpVbdq00W233SYHBwcdPXpUBw4cUGFhodzc3PTxxx+rcePGNfehAQAAWAkJUwAAAKAOTJkyRQEBAYqJiVFiYqKKi4vl4+Oj0aNHKzg4WI6OjlXuq02bNho8eLASExO1detW82zT4OBgjRw5Up6enhW28/T01NChQ7V7927t2rVLhYWFatq0qZ555hm98MIL5WaemgwfPlxbtmzRwYMHFRcXp7y8PBmNRrVr1069evXSsGHD1KRJk2p9LgAAANcbEqYAAABAHenXr1+VD20ZMmSIhgwZUmFZy5Yt9e677171+I0bN9bbb7991e2eeuopPfXUU1fdDgAAwBYZrB0AAAAAAAAAAFwvSJgCAAAAAAAAwEUkTAEAAAAAAADgIhKmAAAAAAAAAHARCVMAAAAAAAAAuIiEKQAAAAAAAABcRMIUAAAAAAAAAC4iYQoAAAAAAAAAF5EwBQAAAAAAAICLSJgCAAAAAAAAwEX21g7gWq1atUoxMTFKTU1VUVGRfHx8NGDAAAUHB8vBwaHK/Zw5c0YbN27U/v37tX//fh04cEDnz59Xt27dtGDBgiu2P3LkiD799FNt27ZNWVlZaty4sbp3766XX35Z3t7e13CHAAAAAAAAAOqKTSdMZ86cqcjISNnb26tr164yGo3asWOHZs+erY0bN2r+/PmqX79+lfpKSEjQ5MmTqxVHQkKCRo0apYKCArVp00b33HOPfv75Z3333Xdas2aNvvzyS919993V6hsAAAAAAABA3bHZhGlsbKwiIyNlNBoVFRUlPz8/SVJWVpZGjBihhIQEhYeH64033qhSf02aNNHQoUPl5+en9u3ba//+/Zo6deoV2xUUFGj8+PEqKCjQiy++qAkTJpjLwsLC9Nlnn2n8+PFavXp1lZO3Na347DmrjIurw/cJAAAAAADA+mw2YTp37lxJ0pgxY8zJUklq3Lixpk6dqqCgIEVFRSkkJEQuLi5X7M/f31/+/v7mP//8889VimPp0qU6efKkbrvtNo0fP96ibPz48VqzZo0OHz6s77//Xs8++2yV+qwpLi4ucnB0VPbWfXU6LqrPwdGxSn9fAQAAAAAAUDtsMmGakZGhpKQkSVL//v3LlQcGBsrLy0vp6enatGlThXVqSmxsrCTp8ccfl8FgeYaWwWBQv379FBERoXXr1tV5wtTd3V1zZs9Wbm5unY5b244dO6aIiAiFhISoefPm1g6nRrm4uMjd3d3aYQAAAAAAANy0bDJhmpKSIklyc3Or9EClDh06KD09XSkpKbWaMDXF0qFDh0rjuLReXXN3d79hE3DNmzfX7bffbu0wAAAAAAAAcAMxXLnK9efo0aOSJC8vr0rrNGvWzKJubcjLy1N2drYk6dZbb62wjinGrKws5efn11osAAAAAAAAAK6dTSZMz527cDiOk5NTpXWcnZ0t6tZmHJeLxWg0mr/Oy8urtVgAAAAAAAAAXDubTJgCAAAAAAAAQG2wyYSpafZoQUFBpXVMsz9NdWszjsvFcuky/AYNGtRaLAAAAAAAAACunU0mTE0no6enp1da58SJExZ1a0ODBg3k5uYmSTp+/HiFdUwxNmrUyGJ5PgAAAAAAAIDrj00mTNu3by9Jys7OVlpaWoV1kpOTJUl+fn51EotpPGvFAQAAAAAAAODa2WTCtFmzZurYsaMkacWKFeXK4+PjlZ6eLkdHR/Xq1atWY+ndu7ck6ccff1RpaalFWWlpqVauXClJeuSRR2o1DgAAAAAAAADXzt7aAVTX2LFj9fLLL2vevHnq2bOneQbnmTNnNH36dEnSc889JxcXF3ObdevWac6cOfL09NTChQtrJI4hQ4Zo7ty5Onz4sMLDw/Xaa6+Zy8LDw3X48GE1a9ZMgwcPrpHxrmcZGRkWe7bWlmPHjln8XtuMRqM8PT3rZCwAAAAAAABYl80mTHv37q3hw4dr0aJFGjp0qLp27Sqj0ajt27crJydHAQEBCg0NtWiTm5urQ4cOqbCwsMI+n3nmGfPXWVlZkqSkpCSL6yEhIXrggQfMf3ZyctIHH3ygUaNGae7cudqwYYPatGmjn3/+WT/99JOMRqPCw8NVv379Grz7609OTo4mTJigsrKyOhszIiKiTsYxGAyKiIiQq6trnYwHAAAAAAAA67HZhKkkTZkyRQEBAYqJiVFiYqKKi4vl4+Oj0aNHKzg4WI6OjlfV3969e8tdy8vLs7huSqRe6p577tGyZcsUERGhbdu2ae3atWrUqJEGDx6sl19+WT4+Pld/czbG1dVVYWFhdTLDtK4ZjUaSpQAAAAAAADcJm06YSlK/fv3Ur1+/KtUdMmSIhgwZUmn5wYMHqx1Hy5Yt9d5771W7/Y2AZesAAAAAAACwdTZ56BMAAAAAAAAA1AYSpgAAAAAAAABwEQlTAAAAAAAAALiIhCkAAAAAAAAAXETCFAAAAAAAAAAuImEKAAAAAAAAABeRMAUAAAAAAACAi0iYAgAAAAAAAMBFJEwBAAAAAAAA4CISpgAAAAAAAABwEQlTAAAAAAAAALiIhCkAAAAAAAAAXETCFAAAAAAAAAAuImEKAAAAAAAAABeRMAUAAAAAAACAi0iYAgAAAAAAAMBFJEwBAAAAAAAA4CISpgAAAAAAAABwEQlTAAAAAAAAALiIhCkAAAAAAAAAXETCFAAAAAAAAAAuImEKAAAAAAAAABeRMAUAAAAAAACAi0iYAgAAAAAAAMBFJEwBAAAAAAAA4CISpgAAAAAAAABwEQlTAAAAAAAAALiIhCkAAAAAAAAAXETCFAAAAAAAAAAuImEKAAAAAAAAABeRMAUAAAAAAACAi0iYAgAAAAAAAMBF9tVplJqaKklq1aqVHB0dqz14dna2li9fLkl6/vnnq90PAAAAAAAAANSEaiVMBw8eLIPBoOXLl+uOO+4oV3706FG9+eabsrOz08KFCyvtJzMzU3//+99lMBiqnTBdtWqVYmJilJqaqqKiIvn4+GjAgAEKDg6Wg4PDVfeXnJysefPmKT4+Xrm5ufLw8NCDDz6okJAQNWnSpMI2ZWVl+uGHH7R06VIdOHBAeXl5cnJy0h133KF+/frp2WefvabEMgAAAAAAAIC6Ua2EqXQhSViZgoICxcXFyc7O7pr7upyZM2cqMjJS9vb26tq1q4xGo3bs2KHZs2dr48aNmj9/vurXr1/l/lavXq2JEyequLhYHTt2VIsWLZScnKyoqCitXr1aMTExatmyZbl2EyZM0MqVK2UwGOTv7y9PT0+dOnVKiYmJSkxM1I8//qiFCxdeVSwAAAAAAAAA6l61E6bWFhsbq8jISBmNRkVFRcnPz0+SlJWVpREjRighIUHh4eF64403qtRfRkaGJk2apOLiYr399tsaOnSoJKmkpESTJk3S8uXLNXHiRC1ZssQiEbxu3TqtXLlSLi4uioqKkq+vr7ksLS1NQUFB2rNnjyIjIzVmzJga/AQAAAAAAAAA1DSbPfRp7ty5kqQxY8aYk6WS1LhxY02dOlWSFBUVpdzc3Cr1t3DhQhUUFKh79+7mZKkk1atXT9OmTZOLi4uSkpK0ZcsWi3Y7duyQJA0YMMAiWSpJ3t7eGjZsmCQpMTHxKu8QAAAAAAAAQF2zyYRpRkaGkpKSJEn9+/cvVx4YGCgvLy8VFhZq06ZNVeozNja20v6cnZ310EMPSbowo/RSVd2btFGjRlWqBwAAAAAAAMB6bDJhmpKSIklyc3OTt7d3hXU6dOhgUfdy8vLydOTIEYt2Ve2vZ8+ekqQVK1YoNTXVoiwtLU1fffWV7Ozs9Mwzz1wxDgAAAAAAAADWZZN7mB49elSS5OXlVWmdZs2aWdS9nGPHjpm/vvXWWyusYxrrj/1169ZNY8eO1dy5c/XEE08oICDAfOjT7t271axZM0VEROjuu+++YhwAAAAAAAAArMsmE6bnzp2TJDk5OVVax9nZ2aJuVfq7XJ9Go1HShdmof/Taa6+pdevWmjp1quLj483X7e3t1b17d7Vp0+aKMQAAAAAAAACwPptckn89KSoq0uTJk/WXv/xFvXv31g8//KA9e/ZozZo1CgoK0tdff62nnnpKBw4csHaoAAAAAAAAAK7gmmaYZmZmmmdeXurkyZPmr9PT01VWVlZh+0vrXQ3T7NGCgoJK65hmjZrqVqU/U58uLi7l6uTn50uSGjRoYHH9888/19KlS9WrVy/985//NF+/7bbb9Oabb+r8+fNavHixZs6cqaioqCvGAgAAAAAAAMB6rilhOnLkyErL7OzsJMl8unxNat68uaQLydjKnDhxwqJuVfqTpOPHj6tdu3bl6pjG+mN/3333nSTp8ccfr7DvAQMGaPHixUpISFBhYaEcHR2vGA8AAACqLycnR4cPH1ajRo0qPSA0LS1NCQkJGjx4cN0GBwAAgOtetZfkl5WV1civ6mjfvr0kKTs7W2lpaRXWSU5OliT5+fldsb8GDRqoZcuWFu2q2t/x48fNfVTENFu1tLRUOTk5V4wFAAAA1ffRRx+pe/fuGjp0qPr06aNnn31WP//8c7l6iYmJmjx5shUiBAAAwPWuWjNMn3jiiZqO46o0a9ZMHTt2VFJSklasWKGXXnrJojw+Pl7p6elydHRUr169qtRn79699cUXX2jFihV68sknLcrOnTunjRs3SpIeeeQRizJPT08dPXpU+/bt08MPP1yu3z179ki6sOy/UaNGVb1FAAAAXKXY2Fh98sknuvvuu/XII48oIyND3333nZ5++mnNnj1bvXv3tnaIAAAAsAHVSpjOmjWrpuO4amPHjtXLL7+sefPmqWfPnuaZn2fOnNH06dMlSc8995zFfqTr1q3TnDlz5OnpqYULF1r0N2LECMXExGjbtm36+uuv9cwzz0iSSkpKNH36dOXk5Khjx4667777LNo9+uij+uKLL7RgwQJ1795dXbp0MZcdOHBA4eHhkqTHHntM9erVq/kPAgAAAJKkBQsW6K677tJXX31l3h5q1KhRevnllzV+/HjNnDlTgwYNsnKUAAAAuN5d0x6m1tS7d28NHz5cixYt0tChQ9W1a1cZjUZt375dOTk5CggIUGhoqEWb3NxcHTp0SIWFheX68/T01KxZszRx4kS99dZb+uabb9S8eXMlJSUpLS1N7u7umjNnjvnh2yQkJERxcXFKSkrS888/r44dO6pFixY6ceKE9u3bp5KSErVt21avv/56rX4eAAAAN7tffvlFL730ksXzmqenp6KiovTyyy9r8uTJ+v33380vxgEAAICK2GzCVJKmTJmigIAAxcTEKDExUcXFxfLx8dHo0aMVHBx81QcsPfbYY/L29tZnn32m+Ph4paSkqGnTpgoKClJISIjc3d3LtWnQoIFiYmL073//W6tXr9b//vc/paSkyMnJSR07dlSfPn0UFBSk+vXr19RtAwAAoAKFhYUVPnPVr19fc+fOVWhoqKZOnarff/9dDRs2tEKEAAAAsAV2ZdU9eakazpw5Izs7O7m5udXVkDcE096o69evt3IkAADgRnUjPG8MGjRId911l95+++0Ky4uLizVhwgStW7dOd999t/bs2aMDBw7UaYyrVq1STEyMUlNTVVRUJB8fHw0YMEDBwcFycHC4qr4KCgoUGRmplStX6siRI7Kzs1OrVq00ePBgDRs2rNLtoIqLi7V48WItW7ZM//vf/1RSUiIfHx/17dtXo0aNuuyL/lOnTikiIkL/+c9/dPLkSbm6uiowMFAvvvhilQ5bvZwb4e8gAAC4fl3Ns4ahtoM5deqU3nrrLXXp0kXdu3dXt27ddO+992rSpEnmE+YBAACAa9W1a1etXbu2wu2XJMne3l4ffPCBHn/8cSUmJtZxdNLMmTM1fvx47d69W506ddL999+v9PR0zZ49WyNGjND58+er3Fd2draeffZZhYWFKS0tTQEBAbrnnnv022+/6Z133tHo0aMr/BwKCws1evRovf322zpw4ID8/PzUrVs3nT59Wh9++KGGDh2qnJycCsc8dOiQBg4cqOjoaBkMBvXu3Vu33nqr1qxZo2eeeUbr1q2r9mcDAABwPanWkvwTJ07oqaeeknRhD89hw4ZVWC8tLU1BQUHKzMzUpRNZc3NztWzZMm3cuFELFizQnXfeWZ0wAAAAALNBgwYpMzNT+/fvl7+/f4V1DAaD/vnPf8rd3V379++vs9hiY2MVGRkpo9GoqKgo82zMrKwsjRgxQgkJCQoPD9cbb7xRpf6mTp2q1NRUtW3bVvPmzZOXl5ekC5MVXnrpJW3dulWffPKJXnvtNYt2H3zwgbZt2yZPT099/vnnatu2rSQpLy9PEydO1H/+8x9Nnz5dc+bMsWhXVlamCRMm6PTp0xo0aJBmzZplnsG6ePFi/e1vf9P//d//ae3atfLw8LimzwoAAMDaqjXD9L///a9OnTqls2fP6rHHHqu03muvvaaTJ0+ak6VeXl6666675OzsrLKyMp09e1YTJkxQcXFx9aIHAAAALmrfvr3CwsIqTZaa2NnZadKkSVq0aFEdRSbNnTtXkjRmzBiLpeuNGzfW1KlTJUlRUVHKzc29Yl8ZGRlas2aNpAt7+puSpZLk7u6uGTNmSJIWLFigvLw8c1lRUZG++uorSdL48ePNyVLpwr7877zzjurXr68ff/xRR44csRhz8+bNSklJkaurq6ZOnWqx3H/o0KHq1q2b8vPzFRkZWbUPBAAA4DpWrYSpaQlTly5d1KhRowrrbNy4UcnJybKzs1PDhg31+eefa+PGjVq8eLG2bt2qIUOGSJIOHz6stWvXVjN8AAAA4PqWkZGhpKQkSVL//v3LlQcGBsrLy0uFhYXatGnTFftLTk5WWVmZHBwcdO+995Yr9/X1VePGjXX+/Hlt3rzZfP2XX35Rfn6+JKl79+7l2nl4eKhNmzYqKyszJ2RNTMvtH3roITk7O5dra7ovnusBAMCNoFoJ059++kl2dnbq0aNHpXV++OEH89eTJk3SfffdZ/5z/fr1NXPmTPNbbTZ2BwAAwI0qJSVFkuTm5iZvb+8K63To0MGi7uWYkp6urq4yGCp+nDdNakhOTi7XzhTL5dr9cbsCU1ymOP/IdP3IkSMW4wAAANiiaiVMjx07JunC2+vKxMXFSZJcXFwqfJNuZ2enJ598UmVlZUpNTa1OGAAAAMB17+jRo5JksXT+j5o1a2ZR93KaNGkiSTp9+rTOnTtXrry0tNR8uOql/ZnaSRfOGqiI6fof4zA9/1d2D6brZWVl5roAAAC2qloJU9NeSJUtxz969KhOnTolOzs7BQYGysHBocJ67du3lySdPHmyOmEAAAAA1z1TUtPJyanSOqZl7hUlQP+oU6dO5r6WLFlSrvz7779XQUFBuf5atmypW2+9VZL09ddfl2u3c+dOHTp0SJIs9j69tB+j0VhhTJde/2NbAAAAW1OthKmdnZ0kqbCwsMLyffv2mb+ubNmOdGH2qSTzAx0AAABQ006ePKnJkyfrvvvuU6dOnfToo4/q/fffv2Jy8vTp0/r66681ZsyYOoq0aho0aKAXXnhBkhQWFqbIyEidPHlSp0+f1pIlSzRjxgzzhAXTc7vJyy+/LOnCAVPh4eE6duyYzp49q9WrV+u1114zt6tsqT8AAMDNwL46jdzc3JSZmanDhw+rU6dO5cpNh0JJUseOHSvtx/SQ6ujoWJ0wAAAAgMs6e/asnn32WaWnp6usrEzShX02582bp7Vr12rhwoVq2rSpuf6xY8e0Zs0arVu3Tvv27VNpaek1x2CaPXq5SQKm5+KKDlSqyLhx45SVlaV///vfmjlzpmbOnGkuu/fee9WqVSstXrxYDRs2tGj31FNP6cSJE4qIiDD/Mmnbtq2efvppzZ07t1w7Z2dnZWdnV7o/6aXXGzRoUKV7AAAAuF5VK2Hq6+urzMxMrV27VgMHDrQoKysr04YNGyRJ9erVU0BAQKX9mPZWcnd3r04YAAAAwGXNnz/f/Mzp6+srX19fpaena9euXTp8+LDefPNNff7559qxY4ciIiK0a9cuSTInVyVVelBTVTVv3lySlJ6eXmmdEydOWNS9knr16mn69OkaNmyYNmzYoPT0dBmNRnXu3FkPPPCA/vKXv0iS2rVrV67tuHHjNGjQIK1du1a//fabHBwcdPfdd6tPnz76+OOPJcl8OOul95CdnV3pPZiu29nZmZf9AwAA2KpqJUwfeughbd68WevXr9f333+vwYMHm8u++OILHTt2THZ2durevftl35Lv2bNHknT77bdXJwwAAADgsjZu3Cg7OzsFBQVpypQp5uvx8fEaM2aMtm7dqi+++EJhYWEqLS1VWVmZ7O3tdc899+iBBx5Qr1691KpVq2uKwbRvf3Z2ttLS0ipMwJpOs/fz87uqvtu1a1cuKVpWVqbdu3dLkrp3715hO29vb40aNarc9fj4eElSjx49yt3D/v37zXFWFn/Lli2rPEsWAADgelWtzYkGDRpkPglz8uTJevrppzVx4kQ98cQTmjNnjrmeaW+lipSVlSk2NlZ2dna66667qhMGAAAAcFmmU99fffVVi+uBgYF68cUXVVZWprCwMJWUlKh9+/Z67733tGPHDi1cuFAvvPDCNSdLJalZs2bmbapWrFhRrjw+Pl7p6elydHRUr169rnm8VatW6fjx4/L397/seQJ/tGfPHiUkJMjLy0sPP/ywRdkjjzwiSdqwYUOFy/JN99WnT59riBwAAOD6UK2EqZOTk8LCwmQ0GlVWVqbk5GStXLlSqamp5uVLTz75pLp161ZpH5s2bVJGRoakyt98AwAAANeioKBArq6ucnV1LVf21FNPSZJKS0s1YMAAffvttxo0aFCt7ME5duxYSdK8efO0f/9+8/UzZ85o+vTpkqTnnnvOfCiqJK1bt059+/bViBEjyvWXkZFR4fL4jRs36q233pKjo6OmTZtWrvzs2bP69ddfy13fs2ePXnnlFdnZ2entt9+Wvb3lQrSePXuqffv2ysnJ0fTp01VSUmIuW7x4sbZv3y6j0ajnn3/+Cp8EAADA9a9aS/Ilyd/fX99++63CwsK0efNmnT9/XpJ06623avjw4QoODr5se9MG8+7u7rr77rurGwYAAABwWaaT3/+oSZMmcnZ2Vn5+vl566aVajaF3794aPny4Fi1apKFDh6pr164yGo3avn27cnJyFBAQoNDQUIs2ubm5OnTokAoLC8v1l5SUpHHjxsnX11ctWrSQvb29Dh48qF9//VVGo1GffPKJfH19y7U7fvy4Bg8erNatW8vHx0dGo1GHDh1SSkqKHBwcNHPmTPXs2bNcOzs7O82ZM0dBQUH6/vvvlZCQoI4dO+ro0aPat2+f7O3t9Y9//EMeHh4196EBAABYSbUTppJ022236cMPP1RpaamysrLk4OBQ7kTNyixYsOBCAPbXFAIAAABQbU5OTsrPz5ePj0+tjzVlyhQFBAQoJiZGiYmJKi4ulo+Pj0aPHq3g4GA5OjpWua82bdpo8ODBSkxM1NatW1VaWiovLy8FBwdr5MiR8vT0rLCdp6enhg4dqt27d2vXrl0qLCxU06ZN9cwzz1xxC4JWrVpp+fLl+vTTT/Wf//xH69atk4uLi/r06aOxY8de9f6rAAAA1yu7skuPAMV1ybSH1Pr1660cCQAAuFHdqM8bvr6+atiwoaKjo9W6dWvZ2dlZlN933306ffq0Dhw4YKUIYXKj/h0EAADXh6t51mB6JwAAAG5oOTk5GjBggOrXr6927dqpQ4cO6tChg/z8/MTcAQAAAPxRtRKmu3btquk4dO+999Z4nwAAALi5eXl5mQ9HKigo0J49e7R3795y9WbNmqU777xTvr6+uuOOO9g2CgAA4CZWrSfB4cOHl1vOdC3s7OyUkpJSY/0BAAAA0oVT48+cOaOUlBTt37/f/Ovo0aMW9SIjI81f29vb64477pCvr6/uvPNO3XnnnbzcBwAAuIlc06tzljABAADgeteoUSP16NFDPXr0MF/LycnR/v37lZKSopSUFCUnJ+u3335TWVmZioqKdODAAaWmpur777/n5T4AAMBN5poSpvXr19fDDz+s7t27y2Aw1FRMAAAAQK1ydXVVt27d1K1bN/O1vLw8HThwwDwLNSUlRYcOHWKSAAAAwE2mWglTZ2dnnTt3TufPn9fKlSsVFxen/v37a9CgQfL19a3pGAEAAIBa16BBA917770Wy+8LCgp04MABK0YFAACAulataaHbtm1TWFiYevXqpXr16ikzM1MLFizQE088oUGDBunLL7/UyZMnazpWAAAAoE45OTkpICDA2mEAAACgDlUrYXrLLbeoX79++uyzz7R582ZNnjxZd955p8rKynTw4EH94x//0IMPPqhRo0bphx9+0Pnz52s6bgAAAAAAAACocde0h6kkNW7cWCNGjNCIESP0yy+/6Pvvv9eKFSuUnp6urVu3atu2bXJyclKfPn00aNAgi32iAAAAAAAAAOB6UqMnNbVu3VoTJ07Uxo0btXDhQj3xxBMyGo3Kz8/X999/r5EjR6pXr156//33a3JYAAAAAAAAAKgRtXa0fZcuXTRr1ixt27ZNc+bMUc+ePVWvXj1lZGRowYIFtTUsAAAAAAAAAFRbrSVMTezs7My/AAAAAAAAAOB6ds17mFYmLi5Oy5Yt09q1a5WXlydJKisrk4eHhwYNGlRbwwIAAAAAAABAtdVowvSXX37RsmXLzIc+SReSpE5OTurdu7cGDx6sbt26yWCo9YmtAAAAAAAAAHDVrjlhevr0aa1YsULLli3TgQMHJF1IkhoMBnXp0kWDBg1Snz59ZDQarzlYAAAAAAAAAKhN1UqY/v7774qNjdWyZcu0bds2lZSUqKysTJLUpk0bDRo0SAMGDJCnp2eNBgsAAAAAAAAAtalaCdNu3bqpoKBA0oXZpO7u7urfv78GDRqkO++8s0YDBAAAAAAAAIC6Uq2EaX5+vuzs7HTLLbfooYceUo8ePVSvXj0dPHhQBw8erFYggwcPrla7VatWKSYmRqmpqSoqKpKPj48GDBig4OBgOTg4XHV/ycnJmjdvnuLj45WbmysPDw89+OCDCgkJUZMmTS7bNjU1VQsXLtTOnTuVmZmp+vXrq1mzZgoICND48ePVqFGjat0jAAAAAAAAgLpxTXuY/v7771q1apVWrVp1TUHY2dlVK2E6c+ZMRUZGyt7eXl27dpXRaNSOHTs0e/Zsbdy4UfPnz1f9+vWr3N/q1as1ceJEFRcXq2PHjmrRooWSk5MVFRWl1atXKyYmRi1btqyw7RdffKE5c+aorKxMfn5+uvvuu5Wbm6sjR47o3//+t4KCgkiYAgAAAAAAANe5aidMTXuWWktsbKwiIyNlNBoVFRUlPz8/SVJWVpZGjBihhIQEhYeH64033qhSfxkZGZo0aZKKi4v19ttva+jQoZKkkpISTZo0ScuXL9fEiRO1ZMkS2dnZWbT99ttv9Y9//EO33367PvzwQ7Vt29ai/Oeff1azZs1q4K4BAAAAAAAA1KZqJUwjIyNrOo6rNnfuXEnSmDFjzMlSSWrcuLGmTp2qoKAgRUVFKSQkRC4uLlfsb+HChSooKFD37t3NyVJJqlevnqZNm6aNGzcqKSlJW7Zs0f33328uP3v2rP7+97+rfv36+te//iVvb+9yfbdp0+ZabhUAAAAAAABAHalWwrRz5841HcdVycjIUFJSkiSpf//+5coDAwPl5eWl9PR0bdq0qcI6fxQbG1tpf87OznrooYe0bNkyrVu3ziJh+t133ykvL08DBw6sMFkKAAAAAAAAwHZc0x6m1pKSkiJJcnNzqzRJ2aFDB6WnpyslJeWKCdO8vDwdOXLE3K6y/pYtW2Ye22TLli2SpHvvvVfnz5/X6tWrlZycrJKSErVs2VKPPvqovLy8rur+AAAAAAAAAFiHTSZMjx49KkmXTUSa9gw11b2cY8eOmb++9dZbK6xjGuuP/R08eFCSdO7cOfXv319paWkW5bNnz9bEiRP1wgsvXDEOAAAAAAAAANZlkwnTc+fOSZKcnJwqrePs7GxRtyr9Xa5Po9Eo6cJs1EtlZ2dLkubMmaOmTZtq7ty5uueee3T27FktXrxYn3/+ud599115eHhUaWsAAAAAANevjIwM5efnWzuMGmc0GuXp6WntMAAAuC7YZML0elJWViZJKi0t1bx583THHXdIklxdXfX6668rLy9PX331lT744AMSpgAAAIANy8nJ0YQJE8w/A9xIDAaDIiIi5Orqau1QAACwOptMmJpmjxYUFFRaxzRr1FS3Kv2Z+nRxcSlXx/QWuUGDBuXaZmdn65577jEnSy81bNgwffXVV0pLS1NaWhoHQwEAAAA2ytXVVWFhYXUyw/TYsWOKiIhQSEiImjdvXuvjGY1GkqUAAFxkkwlT0wNDenp6pXVOnDhhUbcq/UnS8ePH1a5du3J1TGP9sT9vb29lZ2dXmgi99HpmZiYJUwAAAMCG1fWy9ebNm+v222+v0zEBALjZGawdQHW0b99e0oX9Q/94yJJJcnKyJMnPz++K/TVo0EAtW7a0aFfV/kx/PnPmTIXtLr1u2gcVAAAAAAAAwPXJJhOmzZo1U8eOHSVJK1asKFceHx+v9PR0OTo6qlevXlXqs3fv3pX2d+7cOW3cuFGS9Mgjj1iU9e3bV5K0d+/eCpfmbN26VdKFZGnr1q2rFAsAAAAAAAAA67DJhKkkjR07VpI0b9487d+/33z9zJkzmj59uiTpueees9iPdN26derbt69GjBhRrr8RI0bIyclJ27Zt09dff22+XlJSounTpysnJ0cdO3bUfffdZ9GuW7duCgwM1OnTpzVjxgwVFhaay1JTUxUeHi5J+tOf/iQHB4cauHMAAAAAAAAAtcUm9zCVLswIHT58uBYtWqShQ4eqa9euMhqN2r59u3JychQQEKDQ0FCLNrm5uTp06JBFUtPE09NTs2bN0sSJE/XWW2/pm2++UfPmzZWUlKS0tDS5u7trzpw5srOzK9d29uzZCgoK0tKlS7V161Z17NhRZ8+e1Z49e1RUVKQePXpo/PjxtfVRAAAAAAAAAKghNpswlaQpU6YoICBAMTExSkxMVHFxsXx8fDR69GgFBwfL0dHxqvp77LHH5O3trc8++0zx8fFKSUlR06ZNFRQUpJCQELm7u1fYzsvLS8uWLdO8efO0du1abd68WQ4ODvLz89PgwYP1zDPPqF69ejVxywAAAAAAAABqkU0nTCWpX79+6tevX5XqDhkyREOGDLlsnQ4dOuijjz666jhcXFw0ceJETZw48arbAgAAAAAAALg+2OwepgAAAAAAAABQ00iYAgAAAAAAAMBFJEwBAAAAAAAA4CISpgAAAAAAAABwEQlTAAAAAAAAALiIhCkAAAAAAAAAXETCFAAAAAAAAAAuImEKAAAAAAAAABeRMAUAAAAAAACAi0iYAgAAAAAAAMBFJEwBAAAAAAAA4CISpgAAAAAAAABwEQlTAAAAAAAAALiIhCkAAAAAAAAAXETCFAAAAAAAAAAuImEKAAAAAAAAABeRMAUAAAAAAACAi0iYAgAAAAAAAMBFJEwBAAAAAAAA4CISpgAAAAAAAABwEQlTAAAAAAAAALiIhCkAAAAAAAAAXGRv7QAAAAAA4FqcOnVKubm51g6jRh07dszi9xuJi4uL3N3drR0GAACVImEKAAAAwGadOnVKE19/XUWFhdYOpVZERERYO4Qa5+DoqDmzZ5M0BQBct0iYAgAAALBZubm5KioslFuPTrJv6GztcHAFxWfPKXvrPuXm5pIwBQBct0iYAgAAALB59g2d5dCkobXDAAAANwAOfQIAAAAAAACAi0iYAgAAAAAAAMBFJEwBAAAAAAAA4CISpgAAAAAAAABwEQlTAAAAAAAAALiIhCkAAAAAAAAAXETCFAAAAAAAAAAusrd2ANdq1apViomJUWpqqoqKiuTj46MBAwYoODhYDg4OV91fcnKy5s2bp/j4eOXm5srDw0MPPvigQkJC1KRJkyr1kZGRof79+ysnJ0f16tVTSkrKVccBAAAAAAAAoO7Z9AzTmTNnavz48dq9e7c6deqk+++/X+np6Zo9e7ZGjBih8+fPX1V/q1ev1tChQ7VmzRrdeuutevjhh2UwGBQVFaWBAwfqyJEjVepnypQpys3Nrc4tAQAAAAAAALAim02YxsbGKjIyUkajUV9//bW++OILffTRR1qzZo3atm2rhIQEhYeHV7m/jIwMTZo0ScXFxXr77bf1zTff6IMPPtCaNWs0cOBAnTp1ShMnTlRZWdll+1myZIk2b96soKCga71FAAAAAAAAAHXMZhOmc+fOlSSNGTNGfn5+5uuNGzfW1KlTJUlRUVFVnum5cOFCFRQUqHv37ho6dKj5er169TRt2jS5uLgoKSlJW7ZsqbSPY8eOadasWbr77rsVHBxcjbsCAAAAAAAAYE02mTDNyMhQUlKSJKl///7lygMDA+Xl5aXCwkJt2rSpSn3GxsZW2p+zs7MeeughSdK6desqbF9WVqY333xTRUVF+vvf/y47O7sqjQsAAAAAAADg+mGTCVPTIUpubm7y9vausE6HDh0s6l5OXl6eeX9SU7ur7S8mJkY7duzQuHHj1Lp16yuOCQAAAAAAAOD6Y5MJ06NHj0qSvLy8Kq3TrFkzi7qXc+zYMfPXt956a4V1TGNV1N9vv/2m2bNny8/PT6NGjbrieAAAAAAAAACuTzaZMD137pwkycnJqdI6zs7OFnWr0t/l+jQajZIuzEa9VGlpqSZNmqSioiLNmjVL9vb2VxwPAAAAAAAAwPWJ7N41WrhwoRISEvTKK6+oXbt21g4HAAAAuCkVn827ciVYHd8nAIAtsMmEqWn2aEFBQaV1TLNGTXWr0p+pTxcXl3J18vPzJUkNGjQwX/v111/1/vvvy9fXVy+++GLVggcAAMBNa9WqVYqJiVFqaqqKiork4+OjAQMGKDg4WA4ODlfVV0FBgSIjI7Vy5UodOXJEdnZ2atWqlQYPHqxhw4apXr16FbYrLi7W4sWLtWLFCv3vf/9Tfn6+GjRoIF9fXw0ePFiDBg2SwWC5EO3o0aN6+OGHLxvP6NGj9frrr1/VPdSk7K1JVhsbAADcWGwyYdq8eXNJUnp6eqV1Tpw4YVG3Kv1J0vHjxyucKWoa69K6mzdv1u+//66CggKNHDnSov7vv/8uSSopKdHw4cMlXXiI7Nmz5xXjAXD1SktLlZqaquzsbLm5ucnX17fcD3sAAFjTzJkzFRkZKXt7e3Xt2lVGo1E7duzQ7NmztXHjRs2fP1/169evUl/Z2dkaMWKEUlNT5ezsrICAABkMBu3du1fvvPOONm7cqLlz58rR0dGiXWFhoUaOHKldu3bJwcFB99xzjxo3bqz09HTt3LlTO3bsUGxsrD7++GPZ2dmVG9doNOrRRx+tMCY/P7+r/1BqkFuPjrJv2ODKFWFVxWfzSG4DAK57Npkwbd++vaQLD4ppaWny9vYuVyc5OVlS1R7cGjRooJYtW+rIkSNKTk6uMGF6uf6OHDmiI0eOVNp/XFycJOmJJ564YiwArl5cXJyio6OVmZlpvubh4aGgoCB17tzZipEBAHBBbGysIiMjZTQaFRUVZX6mzMrK0ogRI5SQkKDw8HC98cYbVepv6tSpSk1NVdu2bTVv3jzzAaWnTp3SSy+9pK1bt+qTTz7Ra6+9ZtEuJiZGu3btUvPmzRUVFWVx4GlSUpJGjBih2NhYrVy5Uo8//ni5cRs1aqR33323uh9DrbJv2EAOTRpaOwwAAHADsMnpV82aNVPHjh0lSStWrChXHh8fr/T0dDk6OqpXr15V6rN3796V9nfu3Dlt3LhRkvTII4+YrwcHB+vgwYMV/lq/fr0kqV69euZrQ4YMubobBXBFcXFxCg8PV4sWLRQcHKwxY8YoODhYLVq0UHh4uPmFBQAA1jR37lxJ0pgxYyxewDdu3FhTp06VJEVFRSk3N/eKfWVkZGjNmjWSpClTppiTpZLk7u6uGTNmSJIWLFhQ7sDSHTt2SJKGDRtmkSyVpI4dO5qTpImJiVd1fwAAADcSm0yYStLYsWMlSfPmzdP+/fvN18+cOaPp06dLkp577jmL/UjXrVunvn37asSIEeX6GzFihJycnLRt2zZ9/fXX5uslJSWaPn26cnJy1LFjR9133321dUsArlJpaamio6N122236ejRo1qwYIHmzZunBQsW6OjRo7rtttsUHR2t0tJSa4cKALiJZWRkKCnpwhLk/v37lysPDAyUl5eXCgsLtWnTpiv2l5ycrLKyMjk4OOjee+8tV+7r66vGjRvr/Pnz2rx5s0XZH5foV6ZRo0ZVqgcAAHAjsskl+dKFGaHDhw/XokWLNHToUPM+UNu3b1dOTo4CAgIUGhpq0SY3N1eHDh1SYWFhuf48PT01a9YsTZw4UW+99Za++eYbNW/eXElJSUpLS5O7u7vmzJlT4V5OAKwjNTVVmZmZOnXqlPz9/TVu3Dh5e3srLS1Ny5Yt0+7du831TFt5AABQ11JSUiRJbm5uFW4lJUkdOnRQenq6UlJSKkyqXsp0GKmrq2ul+3U3atRIWVlZSk5OVr9+/czXe/bsqTVr1igmJkb9+vWzmGWanJysH3/8UfXr19egQYMqHXvevHk6evSoHBwc5O3trZ49e6pVq1aXjbkuFJ89Z+0QUAV8nwAAtsBmE6bShSVIAQEBiomJUWJiooqLi+Xj46PRo0crODi4ym/QTR577DF5e3vrs88+U3x8vFJSUtS0aVMFBQUpJCRE7u7utXQnAKojKytLknTXXXdpwoQJ5h8a27RpowkTJuif//yn9u7da64HAIA1HD16VJIsls7/UbNmzSzqXk6TJk0kSadPn9a5c+fk7OxsUV5aWqrjx49X2N+QIUO0a9cuff/99+rTp4/uueceNWnSROnp6UpMTFTbtm01ffp0tWjRosKxz5w5ozlz5lhce/fddzVgwABNmzatXCx1wcXFRQ6Ojsreuq/Ox0b1ODg6WqwEBADgemPTCVNJ6tevn8Vb88sZMmTIFfcR7dChgz766KNrjqtFixY6ePDgNfcDoHI5OTmSLixl/OMMG4PBoMDAQO3du9dcDzef0tJSpaamKjs7W25ubvL19a10NhYA1JZz5y7MqHNycqq0jinRaKp7OZ06dZKTk5MKCgq0ZMkSBQcHW5R///33KigoqLA/g8Ggd999V+3atVNYWJh5T1NTfN27d5ePj0+5MR0dHfXMM8/o0Ucf1R133CE3NzcdPXpUa9eu1b/+9S8tX75cWVlZ+vzzz+t8RZa7u7vmzJ5dpf1fa0JWVpb5861NmZmZWrJkiZ5++ml5eHjU+nhOTk5q3LhxrY8jXUhyMxkFAHA9s/mEKYCbl6urqyRp165deuCBBywSYaWlpYqPj7eoh5tLXFycoqOjlZmZab7m4eGhoKAgde7c2YqRAcC1adCggV544QVFREQoLCxMBoNBffv2Vb169bRhwwb9/e9/l4ODg4qKisolL/Py8jRhwgRt3rxZI0aM0J/+9Cd5enoqLS1Nn332mb788kutXbtW0dHRFjNimzZtaj5MyuSOO+7QHXfcofvuu0/PPvustmzZovXr15sPU61L7u7udZKAy8nJ0ZQpU1RWVlbrY5ksWbKkTsYxGAyKiIjguQkAAJEwBWDDTLMg9u7dq7CwMA0cONC8h+ny5cu1d+9ei3q4ecTFxSk8PLzCvW3Dw8MVGhpK0hRAnTHNHr3crETTTNCqLmkfN26csrKy9O9//1szZ87UzJkzzWX33nuvWrVqpcWLF6thw4YW7d59911t2rRJw4YN0+TJk83X27Ztqzlz5ig7O1tbtmzRBx98oPfee69KsXTq1EkPPvigYmNjtWHDBqskTOuKq6urwsLCzPvI3kiMRiPJUgAALiJhCsBm+fr6ysPDQy4uLvrtt980bdo0c5m7u7tatWql3Nxc+fr6Wi9I1LnS0lJFR0fL39+/wr1tw8LCFB0dXeFWDgBQG5o3by5JSk9Pr7TOiRMnLOpeSb169TR9+nQNGzZMGzZsUHp6uoxGozp37qwHHnhAf/nLXyRJ7dq1M7cpKSnRsmXLJEmPP/54hf0OGDBAW7Zs0bZt26oUh0nr1q0VGxurjIyMq2pnizw9Pa0dAgAAqGUkTAHYLIPBoKCgIIWHh+vuu+9W//795ejoqMLCQu3du1d79uxRaGgoSbGbTGpqqjIzMzVu3LgK97YdOHCgpk2bptTUVLVv395KUQK4mZj+rcnOzlZaWpq8vb3L1UlOTpYk+fn5XVXf7dq1s0iKSlJZWZl2794tSerevbv5+unTp1VYWCjpwrL+ipiunz179qriyM7OllT1GbIAAADXM7IIAGxa586dFRoaqqNHj2rBggWaN2+eFixYoKNHj7Ls+iZl+qG9ooTEpddN9QCgtjVr1kwdO3aUJK1YsaJceXx8vNLT0+Xo6KhevXpd83irVq3S8ePH5e/vrw4dOpivu7m5ydHRUZK0b1/FJ8qbtrNp0aJFlcfLz8/Xhg0bJMl8nwAAALaMhCkAm9e5c2e9//77mjJlisaNG6cpU6bo/fffJ1l6k3Jzc5MkpaWlVVhuum6qBwB1YezYsZKkefPmaf/+/ebrZ86c0fTp0yVJzz33nFxcXMxl69atU9++fTVixIhy/WVkZFS4xH/jxo1666235OjoaLFVjXThpPuHHnpIkhQeHq7U1FSL8u3bt2vhwoWSpP79+1uULV68uMLx0tLSFBISoszMTLm6uurJJ5+s9DMAAACwFSzJB3BDMBgMLK+GpP+/t+2yZcss9jCVLuxvunz5cnl4eLC3LYA61bt3bw0fPlyLFi3S0KFD1bVrVxmNRm3fvl05OTkKCAhQaGioRZvc3FwdOnTIvIz+UklJSRo3bpx8fX3VokUL2dvb6+DBg/r1119lNBr1ySefVPjv3Jtvvqn9+/crLS1NQ4YM0V133SVPT0+lpaWZtwXo2rWrRo0aZdEuJiZGU6dOVZs2bXTbbbfJwcFBR48e1YEDB1RYWCg3Nzd9/PHHHLQIAABuCCRMAQA3lEv3tg0LC9PAgQPl7e2ttLQ0LV++XImJiextC8AqpkyZooCAAMXExCgxMVHFxcXy8fHR6NGjFRwcbF4uXxVt2rTR4MGDlZiYqK1bt6q0tFReXl4KDg7WyJEjKz2YyNPTU99//70WLVqk9evX66efftLevXvl4uKizp07q3///nrqqadUr149i3bDhw/Xli1bdPDgQcXFxSkvL09Go1Ht2rVTr169NGzYMDVp0uSaPh8AAIDrhV1ZWVmZtYPA5T388MOSpPXr11s5EgCwHXFxcYqOjlZmZqb5moeHh4KCgtiuAagAzxuwNv4OAgCA2nQ1zxrMMAUA3JA6d+6swMBApaamKjs7W25ubvL19WVmKQAAAADgskiYAgBuWOxtCwAAAAC4WkyzAQAAAAAAAICLmGEKALCKjIwM5efnWzuMGmc0Gis9bAUAAAAAcP0jYQoAqHM5OTmaMGGCbsRzBw0GgyIiIuTq6mrtUAAAAAAA1UDCFABgdurUKeXm5tbJWBMmTFBBQUGtj5OZmaklS5bo6aefloeHR62P5+TkpNOnT+v06dO1PpaLi4vc3d1rfRwAAAAAuJmQMAUASLqQLJ34+usqKiy0dii1YsmSJdYOocY5ODpqzuzZJE0BAAAAoAaRMAUASJJyc3NVVFgonzadVd/IcvLr3fn8HP32c5xyc3NJmAIAAABADSJhCgCw8NvPcdYOAQAAAAAAqyFhCgCw0Pau3jI2aGTtMHAF+Xln9NPeWGuHAQAAAAA3HIO1AwAAAAAAAACA6wUzTIGbVF2ehp6VlVUnp6HXNScnJzVu3LjWx6mrk9BdXFzk4OjIrEUb4uDoKBcXF2uHAQAAAAA3FBKmwE3o1KlTen3iRBUWFVk7FFSBo4ODZs+ZU+tJU3d3d82ZPbtOEunnzp3TrFmzVFZWVutj1TWDwaBJkybJ2dm51seqq2Q6AAAAANxMSJgCN6Hc3FwVFhXpuXaN5Wms/X8Gsn8v0e8lpbU+Tl27pZ5BbrfUq9UxMvKLFXUwq85OQnd3d6+zBFxYWJjy8/PrZKy6ZDQa5enpae0wAAAAAADVRMIUuIl5Gu3l3cCx1sfxblDrQ8AGkVQEAAAAAFyPOPQJAAAAAAAAAC4iYQoAAAAAAAAAF5EwBQAAAAAAAICL2MMUuIll5BdZOwRcAd8jAAAAAADqFglT4CYWdfCMtUMAalVpaalSU1OVnZ0tNzc3+fr6ymBgcQUAAAAAoHIkTIGb2HPtGsnT6GDtMHAZGflFJLarKS4uTtHR0crMzDRf8/DwUFBQkDp37mzFyAAAAAAA1zMSpsBNzNPoIO8GjtYOA6hxcXFxCg8Pl7+/v8aNGydvb2+lpaVp2bJlCg8PV2hoKElTAAAAAECFSJgCN7GM/GJrh4Ar4Ht09UpLSxUdHS1/f39NmDDBvAS/TZs2mjBhgsLCwhQdHa3AwECW59/E2K4BAAAAQGVImAI3IRcXFzk6OCjqYJa1Q0EVODo4yMXFxdph2IzU1FRlZmZq3Lhx5RJgBoNBAwcO1LRp05Samqr27dtbKUpYE9s1AAAAALgcm0+Yrlq1SjExMUpNTVVRUZF8fHw0YMAABQcHy8Hh6vdmTE5O1rx58xQfH6/c3Fx5eHjowQcfVEhIiJo0aVKu/vHjx7V582Zt2bJF+/fvV2ZmphwcHOTt7a0HHnhAwcHBaty4cU3cKlBj3N3dNXvOHOXm5lo7lBp17NgxRUREKCQkRM2bN7d2ODXGxcVF7u7u1g7DZmRnZ0uSvL29Kyw3XTfVw82F7RoAAAAAXIlNJ0xnzpypyMhI2dvbq2vXrjIajdqxY4dmz56tjRs3av78+apfv36V+1u9erUmTpyo4uJidezYUS1atFBycrKioqK0evVqxcTEqGXLlhZtJk6cqN27d8ve3l533nmn7r77bp09e1Z79+7VZ599piVLlmj+/Pm68847a/r2gWvi7u5+wybhmjdvrttvv93aYcBK3NzcJElpaWlq06ZNufK0tDSLerh5sF0DAAAAgKqw2YRpbGysIiMjZTQaFRUVJT8/P0lSVlaWRowYoYSEBIWHh+uNN96oUn8ZGRmaNGmSiouL9fbbb2vo0KGSpJKSEk2aNEnLly/XxIkTtWTJEtnZ2ZnbeXp6avLkyRo0aJAaNWpkvp6VlaXQ0FDFxcVp/PjxWrlyperVq1eDnwBgOzIyMpSfn1/r4xw7dszi99pmNBrl6elZJ2Oh6nx9feXh4aFly5ZZJMWkCwmz5cuXy8PDQ76+vlaMEtbAdg0AAAAAqsJmE6Zz586VJI0ZM8acLJWkxo0ba+rUqQoKClJUVJRCQkKqtPffwoULVVBQoO7du5uTpZJUr149TZs2TRs3blRSUpK2bNmi+++/31z+wQcfVNhf48aN9c9//lO9evXS4cOHlZiYqMDAwGreLWC7cnJyNGHCBJWVldXZmBEREXUyjsFgUEREhFxdXetkPFSNwWBQUFCQwsPDFRYWpoEDB5qXXS9fvlyJiYkKDQ1lBuFNiO0aAAAAAFSFTSZMMzIylJSUJEnq379/ufLAwEB5eXkpPT1dmzZtqrDOH8XGxlban7Ozsx566CEtW7ZM69ats0iYXk6zZs3UqFEjnTlzRidOnKhSG+BG4+rqqrCwsDqZYVrXjEYjydLrVOfOnRUaGqro6GhNmzbNfN3Dw4M9Km9ibNcAAAAAoCpsMmGakpIi6cIPNJXNEunQoYPS09OVkpJyxYRpXl6ejhw5Ym5XWX/Lli0zj10VWVlZysnJkXThh3TgZsWydVhD586dFRgYqNTUVGVnZ8vNzU2+vr7MLL2JsV0DAAAAgKqwyYTp0aNHJUleXl6V1mnWrJlF3cu5dL/DW2+9tcI6prGq0p/J/PnzVVJSIg8PD/n7+1e5HQCgZhgMBvaihBnbNQAAAACoCptMmJ47d06S5OTkVGkdZ2dni7pV6e9yfRqNRkkXZqNWxbZt2zR//nxJ0qRJk+To6FildgAAoPawXQMAAACAK7HJhOn17uDBgwoNDVVJSYmGDx9epT1UAQBA3WC7BgAAAACXY5MJU9Ps0YKCgkrrmGaNmupWpT9Tny4uLuXqmA6sadCgwWX7+uWXX/TCCy8oJydHQ4YM0V//+tcrjg8AAOoW2zUAAAAAqIxNTqVo3ry5JCk9Pb3SOqZT6U11q9KfJB0/frzCOqaxLtffoUOHNGLECJ0+fVqDBw/WzJkzZWdnd8XxAQAAAAAAAFwfbHKGqWlGSHZ2ttLS0uTt7V2uTnJysiTJz8/viv01aNBALVu21JEjR5ScnPz/2LvzuCir/v/j72FTR0BEcJdcEhe0O03NNXMXV7RSS1PLNE0rby3Lvt6lebtUZpGm5J1LpLaKYO5rauISiiviUpmogAugyCIg8/tDmJ/EIqsD+no+Hj4a5jrXOZ9rhsaPnznnXKpXr16e+zt37pyGDh2qK1euqE+fPpo1axZL+wAAyIfIyEjzyo4HidFoVKVKlSwdBgAAAIB7KJEF08qVK6tx48Y6duyY1q5dqzFjxmQ4HhQUpPDwcNnZ2al9+/a56rNz585avHix1q5dq2eeeSbDsbi4OO3YsUOS1KVLl0znnj9/XkOHDtXly5fVp08fffTRRxRLAQDIhxs3bmjChAkymUyWDqXQWVlZacGCBXJ0dLR0KAAAAAByUCILppI0evRojR07VosWLdJTTz1lnvkZHR2tadOmSZKGDBmSYT/SLVu26NNPP1WlSpX0zTffZOhv2LBhWrlypQIDA/Xjjz9qwIABkqTbt29r2rRpunHjhho3bqy2bdtmOC8sLExDhw5VZGSk+vbtq9mzZ1MsBQAgnxwdHTV37tz7MsP04sWLWrBggV577bVcbeFTUEajkWIpAAAAUAKU2IJp586d9eKLL+rbb7/VwIED1bJlSxmNRu3du1c3btxQ06ZN9eabb2Y4JzY2Vn/99ZeSkpIy9VepUiXNmjVLEydO1H/+8x/9/PPPqlatmo4dO6awsDC5uLjo008/zbQn6RtvvGGezSpJ7733XpbxPvvss2rWrFkhXT0AAPfX1atXFRsba+kwSrT4+Hj99ddf92UsBwcHubi43JexAAAAgAdNiS2YStKUKVPUtGlTrVy5UsHBwUpJSZGbm5tGjhyp4cOHm4uYueXp6akaNWroq6++UlBQkEJCQlSxYkUNHjxYr732Wpb/8Lh+/bokKSkpSQEBAdn23aJFCwqmAIAS6erVq5o4YaKSU5ItHUqRWLBggaVDKHS2Nrb6dO6nFE0BAACAfCjRBVNJ6tGjh3r06JGrtv3791f//v1zbNOoUSPNmzcv1+Nv3749120BACiJYmNjH9hi6YMqOSVZsbGxFEwBAACAfCjxBVMAAHB/PFOvg1yN5S0dBu7hSny0Vp3aYekwAAAAgBKLuxMBAIBcMty7CYoB3icAAACgIJhhCgAAcuTg4CA7WzutOsU2NCWFna2dHBwcLB0GAAAAUCJRMAUAADlycXHRnE/nKDY21tKhFJrU1FQFBQUpICBAffv2VbNmzWRl9eAsvHFwcGD/UqAES01NVWhoqGJiYuTk5KT69es/UJ9RAAAUdxRMAQDAPbm4uNy3AlxkZKTi4+OLrP8TJ05ow4YNio6OliQFBARo165d8vT0lIeHR5GNazQaValSpSLrH8CD4cCBA1qxYoWuXLlifs7V1VWDBw9WixYtLBgZAAAPDwqmAACg2Lhx44YmTJggk8l0X8eNjo7WypUri3QMKysrLViwQI6OjkU6DoCS68CBA/L29laTJk00btw41ahRQ2FhYQoICJC3t7fefPNNiqYAANwHFEwBAECx4ejoqLlz5xbJDNPU1FTNnTtXlSpV0uDBgzMsb01NTdWKFSsUGRmpCRMmFMnSV6PRSLEUQLbSP4eaNGmS4XOobt26mjBhgubOnasVK1Y8cFuIAABQHFEwBQAAxUpRLVsPCQlRdHS0xo8frzp16mQ6PmjQIE2dOlW3bt1Sw4YNiyQGAMhOaGiorly5onHjxmUqiFpZWalPnz6aOnWqQkND+YwCAKCI8dUkAAB4KMTExEiSatSokeXx9OfT2wHA/cRnFAAAxQcFUwAA8FBwcnKSJIWFhWV5PP359HYAcD/xGQUAQPFBwRQAADwU6tevL1dXVwUEBCg1NTXDsdTUVK1Zs0aurq6qX7++hSIE8DDjMwoAgOKDgikAAHgoWFlZafDgwQoODtbcuXN1+vRpJSQk6PTp05o7d66Cg4Mz3QwKAO4XPqMAACg+uOkTAAB4aLRo0UJvvvmmVqxYoalTp5qfd3V11ZtvvqkWLVpYLjgADz0+owAAKB4omAIAgIdKixYt1KxZM4WGhiomJkZOTk6qX78+s7YAFAt8RgEAYHkUTAEAwEPHyspKDRs2tHQYAJAlPqMAALAsvqYEAAAAAAAAgDQUTAEAAAAAAAAgDQVTAAAAAAAAAEhDwRQAAAAAAAAA0lAwBQAAAAAAAIA0FEwBAAAAAAAAIA0FUwAAAAAAAABIY2PpAHBvly9f1u3bt9WpUydLhwIAAB5Q4eHhsra2tnQYeIiR8wIAgKKUl3yXGaYlQKlSpWRjQ20bAAAUHRsbG5UqVcrSYeAhRs4LAACKUl7yXYPJZDIVcTwAAAAAAAAAUCIwwxQAAAAAAAAA0lAwBQAAAAAAAIA0FEwBAAAAAAAAIA0FUwAAAAAAAABIQ8EUAAAAAAAAANJQMAUAAAAAAACANBRMAQAAAAAAACANBVMAAAAAAAAASEPBFAAAAAAAAADSUDAFAAAAAAAAgDQUTAEAAAAAAAAgDQVTAAAAAAAAAEhjY+kA8ODr2LGjLl68aP7ZYDCoTJkycnBw0COPPKJGjRrJ09NTjz32WI7n5Ua1atW0fft2SVK9evUyHS9VqpRcXFz0r3/9S4MHD1azZs3ycUUoTFm9z7a2tnJ2dpaHh4cGDBigDh06ZDpv3rx5mj9/fo59169fXwEBAeafX3zxRR04cCBDGxsbG5UrV04NGjRQnz591KdPHxkMhgJcEXKyd+9evfTSSypdurQCAgL0yCOPZNlu/vz5mjdvnh599FGtXr1adnZ2GY6fO3dOP/74ow4cOKALFy4oNjZWpUuXVqVKldSwYUO1b99eXbp0UenSpTOc5+fnp8mTJ2caz8bGRuXLl1ejRo00aNAgPf3005naXLhwQZ06dcr0fPq4zZo107Bhw7L87MEd6f+/z5o1S/3798/1eZGRkfrxxx+1d+9e/f3337p+/bpsbW3l6uqq+vXrq127durWrZscHR0znLd//34NHTo0U3/W1tZydHRUgwYN1K9fP/Xu3TvL/+/vfi8nT56s4cOHZxvjtGnTtHLlSkmSm5ubtmzZkuW13y03n3UASg5yXuSEnPfhQs778CLffXDyXQqmuG+aNm1q/osiMTFR0dHROnnypA4cOKAlS5aoRYsWmjlzpmrUqCFJ6tatm6KjozP0ER8fr02bNpmPG43GDMfLly+fady2bdvK1dVVkhQdHa3jx49r/fr12rBhgyZPnqxhw4YV+rUi7+7+/YiNjdXJkye1fft2bd++XcOHD8/yL3xJcnFxUbt27bI8VqVKlSyfr1+/vho0aCDpzu/U6dOn9dtvv+m3337Ttm3b5O3tTQJZRFq1aqUXXnhBK1as0LvvvqsVK1bIyirjYocTJ05o4cKFsrGx0UcffZQhcUxJSdGcOXP0zTffKDU1Vfb29mrcuLEqVKigxMREXbhwQWvXrtUvv/yiChUq6LvvvssyQTUajerWrZv557i4OJ05c0Y7duzQjh07NGrUKE2cODHb67j78+fKlSs6evSoVq1apYCAAH322Wfq2rVrQV8qpFm8eLE+//xzJSUlqXTp0mrcuLFcXV11+/ZtXbp0SVu3btWmTZs0e/ZsffXVV9kWBfr162d+nJiYqHPnzikwMFCBgYH69ddfNXfu3BzjWLVqVbYJ5K1bt7R27dpcXU9+P+sAlBzkvMgJOe/DgZwXeUG+W0yZgCLWoUMHk7u7u2nVqlWZjqWmppp+/fVXU9euXU3u7u6m1q1bm86fP59tX2FhYSZ3d3eTu7u7KSwsLMdx09vt27cvw/Px8fGmcePGmdzd3U0eHh6miIiI/F0YCkV2vx/JycmmDz/80Pw+HjlyJMPxL774wuTu7m4aMmRIrscaMmSIyd3d3fTFF19keD41NdW0aNEi81jr16/P/wXhnuLi4kydO3c2ubu7m/73v/9lOHbr1i1Tz549Te7u7iZvb+9M544fP97k7u5uatq0qemnn34yJScnZ2pz5coV07x580xNmzY1BQcHZzi2atUqk7u7u6lDhw5ZxrZ06VKTu7u7qV69eqbQ0NAMx3L6/ImKijINHDjQ5O7ubnryySdNCQkJuXkpHjo5/X2QlY8//tj8Wf2///0vy9f1xo0bpqVLl5ratGljWrt2bYZj+/btM79nWdm4caOpXr16Jnd3d9P27dszHU8/t3///ll+DqVbs2aNyd3d3fTMM8+Y3N3dTZ07d87UJr+fdQBKDnJe5ISc9+FDzvtwIt99cPJd9jCFRRkMBrVv314//fSTatasqatXr2rKlClFOmaZMmXMYyQnJ2v37t1FOh7yx8bGRpMmTZK9vb0kaceOHUU2lsFg0CuvvKJatWoV+Vi48033rFmzZGVlJW9vb509e9Z87PPPP9eZM2fk4eGhMWPGZDjvp59+0vr162Vra6tly5bp2WeflY1N5oUSLi4uGjdunNatW6eqVavmKbbhw4ercuXKMplM2rdvX67PK1++vCZNmiTpzqye4ODgPI2LzAIDA/X1119LuvN78corr2RabiZJDg4OGj58uNatW6dGjRrlaYxu3bqpSZMmku4sncvOM888I+nOt+5Z+fnnnzO0y4v7+VkHwHLIeZEdct4HFzkv7oV8t3ijYIpiwdHRUe+9954kad++fTp+/HiRjlepUiU5OTlJkq5du1akYyH/SpUqZZ7KX9Tvk8FgkLu7+30ZC1KzZs00fPhwJSUl6Z133lFKSooOHTqkpUuXytbWVrNnz5atra25vclk0sKFCyVJgwcPVuPGje85RuXKlVWxYsU8x1ahQgVJ0u3bt/N03t37//A7VHDp73eXLl3UuXPne7YvV65ctvuD5SR9+WpO7/dTTz0lV1dXrV+/Xrdu3cpwLCwsTPv371eTJk1Uu3btPI8v3d/POgCWRc6LrJDzPrjIeZET8t3ijYIpio2nnnrKnNAFBgYW6VipqamKj4+X9P//okDxFBcXJ+n+vE83b968b2NBGj9+vOrUqaPjx4/L29tbkydPVmpqqt544w1zIp/u1KlT5g3E+/btW2QxxcbG6q+//pIkPfroo3k6N/33R+J3qKCuX7+uoKAgSUX7ficnJyskJERSzu+3jY2N+vbtqxs3bpj3FEzn5+cnk8mUr2/b73Y/P+sAWBY5L7JCzvvgIudFVsh3iz8Kpig2DAaDGjZsKEk6c+ZMkY61d+9eJSUlydbWNtvN02F5f/zxh8LCwiTdueNeUYqKitLRo0fvy1i4o1SpUpo9e7asra21aNEinTt3Tk2aNNGIESMytU2fgWNra1skd+SMi4vTkSNHNHbsWMXHx6tJkyZ5/mzYuXOnJMnZ2dm87AX5ExISotTUVEnK1cyKvLp165ZOnTqlt956S2FhYapRo8Y9E9WslimlpqbK399fRqNRnp6e+Y7nfn7WAbA8cl78Eznvg42cF1kh3y3+Mm+EAVhQ+h0/Y2JiiqT/qKgoHThwQDNmzJCVlZXef/99VapUqUjGQv7FxsbqyJEjmjFjhm7fvq0xY8Zk+5fIgQMHsk0mtm3bpurVq+c4Vnx8vEJDQ/XRRx8pNjZWXl5e3O3xPnrsscfUunVr875q06ZNk7W1daZ26XcPdnJyyvJ4UlKS3n///UzPP/HEE3ruuecyPX/x4sUsf2/s7Oz02muvadSoUbm+a+yVK1f066+/6uOPP1apUqU0a9asLPceQu7dfbdoZ2fnLNtMnz7d/C11utq1a2vUqFFZts/q/baystLgwYM1bty4THeg/qfatWuradOm2r9/vy5cuKDq1atrz549unTpkvr372/ekykv8vJZB+DBQs4LiZz3YULOi38i3y3+KJiiWEn/hiW3H9q5MXTo0EzPlS5dWkuWLFGrVq0KbRwUzOTJkzV58uQMz1lbW+uTTz5Rnz59sj3PxcUl229Fs/sLYf78+Zo/f36m5ydOnJjtXz4oGnv37tVvv/1m/nndunX5+jY9OTlZq1evzvJYVsmj0WhUt27dMpwfHh6uw4cPa9myZSpVqpRGjx6d7XidOnXK9Fz58uW1YsWKIpkNgMzWrl2bqdDQokWLbP8f7tevn/lxSkqKIiMjdeTIEf3444+ysrLSO++8k2EPsaw888wzOnTokPz8/PTGG2+Yv33Py/Kk/H7WAXiwkPM+vMh5H07kvMgP8l3LomCKYiX9W5Zy5coVWp9t27aVq6urUlNTdfXqVf3+++9KTEzU22+/re+++041atQotLGQf02bNjVvAh0VFaWgoCDFxcVp6tSpqlmzph577LEsz6tdu7Zmz56dp7Hq16+vBg0aSLozs+PIkSOKiorSF198oTp16mSZGKDw3bx5U++9955MJpOGDBmiH374QV9//bU6d+6c6f1On4lz/fp13b59O9M37mXLltWpU6fMPy9YsEDe3t7Zjl2+fPksf2/OnTunF198UZ999pns7Oz08ssvZ3l+t27dZDQadfv2bUVEROjgwYOKjo7W+PHj9d1335n3pkP+pL/f0p3Pg8qVK2dqs3//fvPjgIAA8x1bs5PV+3358mW98sor+vbbb2UymfSf//wnxz48PT01Y8YM+fv7a8iQIdq2bZtq1qypZs2a3euSzPL7WQfgwULO+/Ai5334kPMiK+S7xR8FUxQbJpNJJ0+elKRMm18XxKhRo/Tkk0+af46MjNQrr7yi06dPa+LEifrhhx8K9dt95M9zzz2n/v37m3+OjY3V2LFjtX//fo0fP17r1q1TmTJlCmWszp076/XXXzf/nJSUpMmTJ2vt2rV65513tH79+nzdaRJ5M3PmTF26dEmtWrXSlClTVL58ec2bN0+TJ0/W6tWrZWdnZ27r4eEh6c57dfr0aXPyX9hq1qypUaNG6b///a8WLVqUbfI4adKkDEvf/vjjDw0fPlx//vmnPvjggxwTV9xbgwYNZGVlpdTUVB0/fjzLBLIwVKxYUePHj9eYMWP03Xffafz48XJwcMi2fdmyZdW9e3f5+fnpvffeU1JSUobPrdy4n591AIonct6HGznvw4ecF1kh3y3++S43fUKxsXPnTl2/fl3SnW/Ii0qlSpX0+eefy9bWVkeOHNGaNWuKbCzkn4ODgz7//HM5OTnp4sWLWrp0aZGNZWdnp5kzZ6pmzZqKjY3lL/774Ndff9WqVatkb2+vmTNnymAw6NVXX1XDhg119uxZffHFFxna169fX9WqVZOkIv9/Nn0GTnR0tKKionJ1Tp06dfTxxx9LkjZu3Gi+4yXyx8nJSU2bNpV0/97v27dv69y5c/dsn74caceOHbK2tpaXl1eBxr+fn3UAigdyXtyNnPfBRs6L7JDvFn8UTFEsxMbGatasWZKkNm3aFNk3aenq1KmjQYMGSbqzt09KSkqRjof8cXZ21pgxYyRJS5Ys0Y0bN4psrFKlSumtt96SJK1evVp///13kY31sIuJidGUKVMkSe+++66qVq0q6c7dQGfNmiVbW1stWbJER44cMZ+TnlxK0vLlyxUSElJk8Z0/f17SnQ3S87KRfatWrcx3fOQfIAWX/v/+5s2b9euvvxbZOOnvt5T9HnB3a9asmRo1aiQnJyd16dKlUG6icj8/6wBYFjkvskLO+2Ai58W9kO8WbxRMYVEmk0k7d+7Us88+q3PnzsnV1VXTp0+/L2O/9tprMhqNOn/+fLYbZ8PyXnjhBVWtWlWxsbFasmRJkY7VpUsX/etf/9Lt27ez3CAfhWP69Om6cuWKnnrqqUyb09evX19jxozR7du39e677+rWrVvmYwMGDFC3bt2UlJSkoUOHys/PL8t/+N28eTPD3k55ce7cOf3vf/+TJLVu3TpXCcXdJkyYICsrKx04cEB79+7NVwy4o23btnr55ZdlMpn0+uuva+nSpUpMTMzULikpScePH8/XGJcvXzYn+rVq1VKdOnVydd6qVau0f//+Qv1Hwv38rANw/5Hz4l7IeR885Ly4F/Ld4o09THHf/PTTTzpw4ICkO//DR0dHKyQkxHzXtxYtWmjmzJnmJQhFzdnZWS+99JK+/PJLLVy4UF5eXve8YxzuPzs7O40bN07vvfeefH19NXz48CLdXHzChAkaNmyY1q1bpzFjxqh27dpFNtbDaNOmTVq7dq0cHR313//+N8s2r776qrZt26YTJ07I29vbvLm5wWDQp59+qkqVKmn58uWaPHmyZs6cqcaNG8vZ2VmpqamKiIjQ8ePHlZSUpAoVKujpp5/Ocozo6Gi9++675p/vvmPo7du3VbVqVU2dOjXP11e3bl316dNH/v7++uKLL7grcTYWLFig77//PtvjH3zwgTw8PPTOO++ofPny+uKLLzR79mx5e3urcePGcnV1lcFg0OXLl3X8+HHFx8eb91vKzt3vd0pKii5fvqzDhw/r1q1bKleunHl5maXc7886AEWHnBf5Qc77YCHnBfluZiUt36Vgivvm0KFDOnTokKQ708Dt7e3l7u6uRo0aydPT0yJ3Snv55Zf13Xff6eLFi1q1apV5yRKKFy8vLy1ZskRnz57V4sWLNXHixCIbq2XLlmrbtq1+++03zZ8/X3Pnzi2ysR42165d0wcffCBJ+r//+79sl3bY2Nho9uzZ6t+/v5YuXaquXbvq8ccfl3RnCdP//d//6fnnn9dPP/2k/fv3KyQkRDdv3lSpUqVUsWJFdenSRU8//bS6dOmS7Wbi8fHxGWbZGAwG2dvby8PDQx07dtSLL74oe3v7fF3nG2+8ofXr1+vQoUPavXu32rVrl69+HmRhYWEKCwvL9vjNmzfNj0eNGqU+ffroxx9/1N69e3X27FkdOnRIdnZ2qlChgtq0aaN27dqpe/fuOd5t+p/vd5kyZVS7dm21bdtWw4YNk6ura+FcXAHcz886AEWHnBf5Rc77YCDnhUS+m52SlO8aTCaTydJBAAAAAAAAAEBxwB6mAAAAAAAAAJCGgikAAAAAAAAApKFgCgAAAAAAAABpKJgCAAAAAAAAQBoKpgAAAAAAAACQhoIpAAAAAAAAAKShYAoAAAAAAAAAaSiYAgAAAAAAAEAaCqYAAAAAAAAAkIaCKQBA8+bNU7169VSvXr0iG6Njx46qV6+e3n333SIbAwAAAMgOOS+A3LKxdAAAUJLt379fQ4cONf9sNBoVGBioMmXK5HheYmKi2rRpo5s3b5qf8/X11ZNPPllksQIAAAD5Qc4L4GHDDFMAKETx8fHaunXrPdtt27YtQ+IIAAAAlBTkvAAedBRMAaCQlCpVSpIUEBBwz7bpbdLPAQAAAEoCcl4ADwMKpgBQSDp27ChJCgwM1JUrV7Jtd+3aNe3Zs0eS1KlTp/sSGwAAAFAYyHkBPAwomAJAIWnTpo1cXV11+/ZtrVu3Ltt2a9euVUpKilxdXdW6dev7GCEAAABQMOS8AB4G3PQJAAqJtbW1evbsqWXLlikgIEDDhw/Psl360qRevXrJ2tr6nv0mJSXpp59+0saNG3XmzBndvHlT5cqVU8OGDdWrVy/17t1bVlY5f/8VERGhr776Srt27dLly5dVrlw5NWrUSEOHDs1TAhsbG6uVK1dqx44dOnfunG7evCknJyc1atRIXl5e6tatmwwGQ677AwAAQMlCzkvOCzwMKJgCQCHq27evli1bppCQEJ05c0Z169bNcPzs2bM6ceKEue3Jkydz7O/ChQsaOXKk/vzzzwzPX716Vbt27dKuXbv0ww8/aMGCBXJycsqyj6CgIL366qsZNty/cuWKduzYoR07duj111/P1bXt3btX48ePV0xMTIbn7+6rffv2+uyzz1S2bNlc9QkAAICSh5yXnBd40LEkHwAKUcOGDc0JY1Yb4ac/5+7urgYNGuTYV1xcnIYPH25OHDt37qyFCxdq1apV8vb2VosWLSRJBw8e1OjRo3X79u1MfVy6dMmcOFpZWWnQoEFatmyZfv75Z82YMUM1a9bUvHnz9Ouvv+YYy8GDBzVy5EjFxMTIxcVF48ePl4+Pj/z8/OTj46M+ffpIknbu3Kl333035xcJAAAAJRo5Lzkv8KCjYAoAhaxv376S7uzbZDKZzM+bTCb98ssvGdrkZP78+QoLC5MkjRkzRl9++aU6duyoRo0aqXv37vL19VXv3r0lScHBwfrhhx8y9TF79mzzt+yffPKJpk2bplatWqlx48Z69tlntWrVKtWvX1/Hjx/PNo7k5GS9/fbbSk5OVrt27bR161aNGTNGHTp0kIeHhzp06KBPPvlE06dPlyRt3rzZvME/AAAAHkzkvOS8wIOMgikAFLI+ffrIyspK4eHh2r9/v/n5/fv3Kzw8XFZWVuakLztJSUn6+eefJUl169bNcgmRwWDQ1KlTzcuSVqxYkeH4lStXtHXrVklShw4d1KtXr0x92Nvbm5O+7Kxbt04XL15UqVKl9PHHH6tMmTJZthswYIAee+wxSZKfn1+OfQIAAKBkI+cl5wUeZBRMAaCQVapUSU8++aSkjEuU0h+3bNlSlSpVyrGP48eP68aNG5Kkfv36ZbtRvr29vTw9PSXd2Svq8uXL5mP79+83L1nq379/tmM99thjmfadutv27dslSc2bN5ezs3OOcTdr1kySdPjw4RzbAQAAoGQj5yXnBR5k3PQJAIqAl5eX9u7dq82bN+uDDz6QJG3atElS7pYmnTlzxvz4X//6V45t//Wvf+m7774zn1exYkVJ0unTp81tGjdunGMfjRs3zjDm3dKXLv3222+qV6/ePWOX7mzQDwAAgAcbOS85L/CgYoYpABSBLl26qEyZMrp586a2bdumrVu3Ki4uTkajUV27dr3n+devXzc/vtc33C4uLlmed/edPStUqJDrPv4pKioqx3OzkpiYmOdzAAAAULKQ85LzAg8qZpgCQBEoW7asOnfurF9++UUBAQHmjfA7d+4so9GYp74MBkNRhJhr6UucnnrqKb399tsWjQUAAADFBzkvgAcVBVMAKCJeXl765ZdfMtw908vLK1fnlitXzvz42rVrqlWrVrZt714KdPd5/+yjSpUquerjn5ycnHT58mUlJyfL3d39nrEDAADg4UHOC+BBxJJ8ACgirVq1kqurq1JSUpSSkqKKFSuqVatWuTr37g3pjxw5kmPbo0ePZnne3YnesWPHcuwjfc+mrDRs2NDcJikpKcd+AAAA8HAh5wXwIKJgCgBFxNraWn379pWdnZ3s7OzUt29fWVnl7mO3UaNGcnR0lCT5+/srNTU1y3Y3b97Uhg0bJEmPPvqoefN7SXryySfNdxpdvXp1tmMdPXo0w2b5/9SxY0dJUmxsrPz8/HIVPwAAAB4O5LwAHkQUTAGgCL399ts6duyYjh07prfeeivX59nZ2enZZ5+VdOfOnwsWLMjUxmQyafr06YqOjpYkDR48OMPxihUrqlOnTpKk7du3a/369Zn6iIuLM9/RNDv9+vUzL2366KOP9Pvvv+fYPigoSAcOHMixDQAAAB4c5LwAHjTsYQoAxdTYsWO1ZcsWhYWFad68eTp9+rT69+8vV1dXXbhwQcuXLzcnaU2aNNHAgQMz9fHOO+9oz549iouL01tvvaXff/9d3bp1k729vU6dOqVFixbp3LlzatSoUbZLlOzs7PT555/rxRdfVHx8vIYNG6YePXqoc+fOql69ulJTU3XlyhWdOHFCW7Zs0enTp/Wf//xHLVq0KNLXBwAAACUfOS+A4oiCKQAUU/b29lq2bJlGjhypP//8U5s2bdKmTZsytWvatKkWLlxoXop0t+rVq2vhwoUaM2aM4uLitHLlSq1cuTJDm7Fjx8pgMOS4p9Pjjz+ub7/9VuPHj1d4eLh++eUX/fLLLznGDgAAANwLOS+A4oiCKQAUY9WrV1dAQIB++uknbdy4UadPn1ZcXJzKlSunBg0aqHfv3urdu3eO+0Q9+eSTWrdunb766ivt2rVLly9fVrly5dSoUSMNGTJE7dq107x58+4Zy+OPP67NmzfLz89PO3bsUEhIiKKjo2VlZSVnZ2fVqVNHzZs3V9euXVW7du3CfBkAAADwACPnBVDcGEwmk8nSQQAAAAAAAABAccBNnwAAAAAAAAAgDQVTAAAAAAAAAEhDwRQAAAAAAAAA0lAwBQAAAAAAAIA0FEwBAAAAAAAAIA0FUwAAAAAAAABIQ8EUAAAAAAAAANJQMAUAAAAAAACANBRMAQAAAAAAACANBVMAAAAAAAAASEPBFAAAAAAAAADSUDAFADyw/Pz8VK9ePXXs2NHSoQAAAAD5Mm/ePNWrV08vvviipUMBHho2lg4AQPE1b948zZ8/P9Pztra2cnJyUr169dS9e3d5eXnJ1tY2yz4uXLigTp06mX9u27atFi9enOO4GzZs0Pjx480/jxs3Tq+//nqmdiaTSRs3btTatWsVEhKia9euydraWhUqVJCrq6see+wxNWvWTK1atZK9vX2Gc999912tXr06xzjSVatWTdu3b89V26zcvHlTq1ev1p49e3Tq1ClFR0crNTXV/Bq2bt1avXr1kqura77HAAAAQNH4Z048d+5c9ezZM8dzRo0apZ07d5p/3rZtm6pXr57jOStXrtS0adMkSU2aNNH3339/z9hefPFFHThw4J7tJKlFixb69ttvc9U2K9euXdOqVau0d+9e/fHHH4qJiZGVlZWcnZ1Vv359tW/fXp6ennJ0dMz3GABQXFAwBZArLi4u5sdxcXG6cuWKrly5ot9++03ff/+9lixZonLlyt2zn8DAQEVERKhy5crZtlm1atU9+7lx44bGjh2bIUG0sbFRmTJlFB4errCwMB06dEjLli3TrFmz1L9//yz7SU/yclK+fPl7xpOdn376SZ988omuX79ufq506dKys7NTZGSkIiMjtWvXLn322WcaM2aMxowZk++xkJmDg4Nq1aqlSpUqWToUAADwgPDz88uxYBoZGanffvstz/3+/PPP5sfBwcH6888/Vbt27Vyda2tre89cPDe5elZMJpO++uor+fj4KCEhwfy80WiUwWDQxYsXdfHiRW3btk2ffPKJ3n33XT377LP5GgtZK1++vGrVqqUqVapYOhTgoUHBFECu7NmzJ8PPly5d0sKFC/Xjjz/q+PHj+u9//6tPPvkkxz6qVaumixcvyt/fX6NHj86yTWRkpPbs2SOj0ahSpUopOjo6y3aTJk3SgQMHZG1trWHDhmngwIFyc3OTlZWVUlJSdPbsWe3evVtr167NMaYqVaoUaPZoTj777DP5+PhIkurUqaNRo0apXbt2qlChgiQpMTFRQUFBCggI0Lp167Rx40YKpoWsS5cu6tKli6XDAAAAD4Dy5cvr1q1b95wAEBAQoNu3b5tz39wIDQ3ViRMnVK5cOT311FP65Zdf9PPPP2vSpEm5Or9JkyYFmj2aHZPJpLffflu//PKLJOlf//qXXnnlFbVs2dI8k/TmzZvat2+ffv75Z+3YsUPbt2+nYFrIhgwZoiFDhlg6DOChwh6mAPKlatWqmj59ulq2bCnpzjL6uLi4HM/p16+fJOW4FH716tVKTU1V9+7dZTQas2xz7tw57dixQ5I0fvx4vfPOO6pZs6asrO58pNnY2Kh+/foaOXKkAgIC1KNHjzxfX0GtX7/eXCz19PSUv7+/vLy8zMVS6c5M07Zt2+qTTz6Rv7+/Hn300fseJwAAAHLHaDSqW7duSk1NlZ+fX7bt0ldLZbfCKSvps0s9PT01YMAASXcKrykpKQWIuOD+97//mYulw4YN0w8//KCuXbtmWHZvb2+vzp07y8fHR8uXL89xJRkAlBTMMAVQIO3atdO+ffuUnJysv//+Ww0bNsy2bfPmzVW9enWdO3dOQUFBatasWaY26cXU/v37a//+/Vn2c/LkSfPju/dHzU7p0qXv2aYwJSUl6eOPP5YkPfroo/roo49kZ2eX4znu7u7ZztANCQnRsmXL9Pvvv+vq1asqXbq06tSpo+7du+uFF17Ism8/Pz9NnjzZvP9qUFCQvv76ax05ckQJCQmqWbOmBg8erOeee858zq+//qpvvvlGJ0+eVEJCgh599FGNGDEi24JzvXr1JEm+vr6qXbu2Fi5cqF9//VVXrlyRo6OjWrZsqddee0116tTJ8vzTp09r06ZN+v3333Xp0iVdvnxZNjY2cnNzU/v27TVs2LBst0vo2LGjLl68qFmzZqlbt276+uuvtXXrVl24cEHx8fHmfcL++Tr805EjR+Tr66vg4GBduXJF1tbWKl++vKpVq6ZWrVrpmWeeyTLpv3LlipYsWaJdu3aZZ45Uq1ZN7du318svv5xhC4t0d+/nu23bNpUuXVo+Pj7avn27rly5IgcHBz355JMaN25ctq8ZAACwrP79+2v16tVavXq1XnvttUzHg4KCdO7cOdWoUSPLXDcrSUlJ5qJkv3799K9//cs8O/XXX39V586dC/UacisqKkoLFy6UJLVq1UqTJ0+WwWDI8ZzmzZvriSeeyPLY/v37tWLFCgUHBys6Olply5ZV/fr11adPH3l5ecna2jrTOen7x6bvv7pt2zb5+voqNDRUycnJcnd31yuvvJLhNfL399f333+vP/74QykpKWrYsKHGjRunVq1aZer/n/lZSkqKfHx8FBgYqKioKLm4uOipp57S2LFjs93i6fDhw9qyZYuCg4MVHh6uq1evqlSpUqpdu7Y6d+6swYMHq2zZslmee3c+/eijj2rRokX69ddfFRERocTERJ06dSrL1+Gfdu/erR9++EFHjx5VVFSU7OzsVL58eT3yyCNq06aNnnnmGTk5OWU67/z581q8eLH27t2riIgI2djY6JFHHlGnTp00fPjwTPeBkO68j0OHDpUknTp1Sn///bf5Nbt27ZqcnZ311FNP6fXXX2dbLJRoFEwBFIjJZDI/vn37do5tDQaD+vXrp3nz5mnVqlWZksj0BNPNzS3XCWZERESxKy5t27ZN4eHhku5s+F+qVKlcnZc+Q/Zuy5Yt0+zZs82vs4ODgxISEhQcHKzg4GD5+fnp66+/VsWKFbPt96efftL7778vk8kke3t7JSQk6OTJk5oyZYrOnz+viRMn6osvvtCXX34pKysrlS1bVomJiTp+/Lj+/e9/6/r163r++eez7f/ChQuaOHGirly5otKlS8vGxkZXr17V2rVrtWXLFs2fP19PPfVUpvNGjx5tLjaWKlVKZcqU0fXr13Xy5EmdPHlSq1ev1rJly3LcuysmJkb9+/fXuXPnZGtrqzJlymTb9p9Wr16tyZMnm19bOzs7WVtb69KlS7p06ZJ+//13ValSJdPskAMHDmjs2LG6ceOGJJlnQp89e1Znz57Vzz//rAULFuT4O3z27Fm99957unbtmjnma9euaf369dq1a5dWrFih+vXr5/paAADA/dG8eXO5ubnp/Pnz+v3339W8efMMx9Nnnvbr1++excV0W7ZsUUxMjGrWrKnHH39ckuTl5aUvv/xSP//8s8UKpn5+foqPj5d05yasub2erHLaWbNmadmyZZLu/JvAwcFBsbGx2rdvn/bt26c1a9boyy+/zLJAl+6f+WpcXJyCg4M1duxYTZs2TQMHDtTkyZO1evVq2djYqFSpUoqPj1dQUJBGjBihBQsW6Omnn862/6NHj2rKlCmKi4uT0WiUtbW1wsPD9cMPP2jTpk1asmSJPDw8Mp03cOBA8+MyZcqYc9ojR47oyJEjCggIkK+vb4aVZv90/vx5TZgwwVxstbHJfalm/vz5mjdvXoYYTCaTLly4oAsXLmjPnj1q1KiRnnzyyQznrV+/Xu+8846SkpIkSWXLllVycrJCQkIUEhKin3/+WYsXL87x31r79u3TmDFjFB8fr7Jly8pkMikyMlI//fSTdu7cqZ9//pmiKUosluQDKJD0De0NBsM97/wp3flW3srKShs3bsy0hP/u5Us5JWSNGzc2H589e7b++uuv/IZfJPbu3SvpTrKYmxmw2dmxY4dmzZolk8mkTp06aevWrQoKCtKhQ4f00UcfqWzZsjp16pTeeOONbIvVUVFRmjZtmgYPHqzAwEAFBQVp//795u0Rvv76a/3vf/+Tj4+Pxo8frwMHDigoKEi7d+9Wu3btJEkff/yxYmNjs41z1qxZsrW11ZIlS3T48GEFBwfrp59+kru7u27duqV///vfioiIyHRe8+bNNXv2bO3YsUNHjx7V/v37dfToUS1btkyPPfaYIiMj9dZbb+X4Gs2bN09xcXH68ssvFRwcrN9//107d+7MMSGVpISEBE2fPl0mk0l9+vTRli1bdOzYMR08eFDBwcFatWqVRowYkamf8PBwc7H00Ucf1cqVK83F6xUrVqhWrVq6fv26xo4dq8jIyGzHnzRpkh555BH9/PPP5tds6dKlcnV11c2bNzV9+vQc4wcAAJaRPgFAynyj0vj4eG3YsEFWVlb5Wo7ft29f83NeXl6S7swcvHLlSgGjzp/0nNbZ2TnXkxmysnz5cnOxdODAgdq9e7d+//13BQUFafLkybKxsdG+ffv0n//8J9s+Tp48KR8fH/373/8256u7du1S27ZtJd3JV+fNm6cNGzZo2rRp5px506ZNatSokW7fvq1p06YpNTU12zHef/99Va9eXT/99JOCg4N1+PBhLV68WFWrVlVMTIzGjRunmzdvZjqvQ4cO+uyzz/Tbb7/p8OHDOnDggI4cOaL58+erVq1aOnv2rD744IMcX6OZM2fKwcFBy5Yt0+HDh3Xo0CFt3Ljxnq/txYsX9eWXX0qSXnrpJe3atcucWwYFBWnFihV64YUXMs1wPXHihCZNmqSkpCQ1bdpUa9as0aFDh3TkyBEtXLhQrq6uCg8P1+jRo3Pcdu2NN95Qy5YttX79eh06dEjBwcH67LPPVLZsWV2+fFmffvrpPa8BKK4omALIl0uXLuk///mP9u3bJ+lOopCbu8lXrVpVLVu2VHx8fIYkIC4uThs3bpSVlZU5Cc1O9erVzUvJT58+LU9PT/Xr10/Tpk3Tzz//rNOnT2eY+ZqT8PBwtWnTJsc/ixcvzlVf6c6ePStJcnNzy/Fb8ntJX6LfrFkzzZs3TzVq1JB0Zyakl5eX5syZI+nOXVS3bNmSZR8JCQny8vLSlClTzMvbnZycNGPGDFWvXl2pqamaM2eOXn/9dY0ZM0YODg6SpIoVK+rzzz+X0WhUfHx8jjfGSkxM1Ndff602bdqYC9mPPfaYli1bJicnJ928eVNfffVVpvM++ugj9evXT1WrVjU/Z2dnp1atWmnZsmVycXHRiRMnFBQUlO3Yt27d0qJFi9S5c2fZ2tpKkipXrnzPmaZnzpwxzx6YNWuW3NzczMeMRqMaNWqkSZMmqX379hnO8/Hx0Y0bN1SuXDktW7Ysw5KzZs2aadmyZbK3t1dMTEyW15yuQoUKWrp0qRo3bizpzr67rVu31ocffijpzmzrrIrMAADA8vr16ycrKytt2rQpQzFpw4YNio+PV6tWrXJ9N/MLFy5o7969MhgMGQqmbm5uatq0qVJSUnLc/z9dcHDwPXPa9evX5+k603PaBg0a5Om8uyUmJppnP/bq1UsffvihXF1dJd3JuYYPH653331X0p0Zj8ePH8+yn9jYWL3++usaPXq0OV+tVKmSvL29ZTQazV+gT58+XYMGDTLngjVr1tRnn30m6c6/Xw4dOpRtrNbW1lq6dKkee+wxSXeK423bttXXX38tW1tbXbp0Sd9//32m83x8fNSjRw/zdUl3tgTr0qWLvvnmG9nZ2Wnr1q26dOlStmNbWVlp2bJlatWqlXmGbq1atbJtn+7IkSNKTU1VzZo19e6772aYzeng4KBmzZrpgw8+UKNGjTKc99lnnyk5OVmPPPKIlixZYt4awMrKSh07dtSiRYtkY2Oj8+fPZ3nN6erXr68vv/zSPAvVzs5OPXr00L///W9J0qZNmyy+Dy+QXxRMAeTK3cnW448/rg4dOujHH3+UJNWuXVtTp07NdV/PPPOMJGXYLD89wWzdunWuNor/4IMP9Nprr8loNMpkMikkJEQrV67U//3f/6l3795q06aNZs2apatXr+bYT2pqqq5evZrjn/SlSLkVExMjSSpXrlyezrtbaGio/vjjD0nSmDFjstzTqWPHjuaEbt26ddn2NWrUqEzPWVtbm/dxKlWqlIYNG5apjb29vXlZWPr+SVnp3r17lkt1KlSooEGDBklSnhP0smXLmpe45ZTYtmvXLsd9c7OTnmgnJyeb3697MZlM5iL/oEGDMiTF6SpXrmy+5pzek5dffjnLvXWfeuopc+E3p9ccAABYTpUqVdS6dWvzjNJ06blteq6bG35+fjKZTGrevLmqVauW4Vh2M1mzkpycfM+cNjExMddxSYWT0+7Zs8fcz7hx47Js88ILL5jzqrVr12bZJjf5atWqVdW7d+9Mbdzc3PTII49Iyjm/GjRoUJarlOrUqaNu3bpJyntOW6lSJdWvX18mk0nBwcHZtuvbt2++bpaVfvOtuLi4XP+b5caNG+ZVgiNGjMhyokHDhg3VpUsXSTnntKNHj85yC4b0VXaJiYn6+++/cxUXUNywhymAXMmu8Ojl5aUPP/ww1/t0SlKXLl3k6OiooKAg/f3333rkkUfMiWBuE0wbGxu9+eabevnll7V9+3b9/vvvOnbsmP744w8lJyfr2rVrWrZsmQICArRo0SJzYfGfsrsZkKWlf7tuY2OjFi1aZNuudevWOnr0aLbfxjs5OWWYPXm39ITw0UcfNe/DmV2b9P06s9KyZcscj/n4+CgmJkZhYWHmWbLpduzYoYCAAB07dkzXrl1TQkJCpj5ymmnZtGnTbI/lxM3NTbVr19aff/6pAQMGaNCgQWrXrp3c3d2zLE5Ld2aApCf8Wd00IF2bNm309ddfZ3vNkrL9fbSxsZGzs7MiIyN1/fr1vF8YAAC4L/r376/ffvtNq1at0rPPPqu///5bQUFBKleuXK73HE1NTTXPHk1fgn83T09P/fe//83xhqnpsrsZkKWl56hVqlTJdsaktbW1WrZsqV9++SXbnDY3+WqjRo2y3darQoUK+vvvvwuU065du1anTp1ScnKy+Qtu6c77uG7dOq1bt06hoaGKiorSrVu3MvVRFDntY489pvLly+vKlSvmnLZVq1aqXbt2tq/FiRMnzKvxWrdunW3fbdq00YYNG7K85rvHz8rd91fI7eQEoLhhhimAXDl16pROnTql0NBQ7d69W9OmTZOjo6P8/f21fPnyPPVVqlQp9ezZU9Kdb9XPnTunQ4cO5SnBTOfg4KC+ffvqv//9rwICAnTw4EEtXbpUHTp0kCRFR0fr9ddfzzJpKSrpd6AsSMErKipKklS+fHnZ2dll2y79m+hr165leTy7O3JKMm8mn5s2OS2lyWkj97uTpfRrku4klhMnTtTo0aO1YcMGXbhwQcnJySpXrpxcXFzk4uJiLsJnVURNl77NQF5ZW1vrs88+U/Xq1XXx4kV9+umn8vLy0hNPPKGXXnpJK1euzDTu3a9xTtd897G7r/luBX3NAQCAZXXp0kXlypXToUOHdO7cOfPs0p49e+Z6IkFgYKAuXbqkMmXKmGcw3s3BwcGcG+dmlmlhK4ycNj1/uteNf4p7Tpt+LCUlJcPrkZCQoOHDh+utt97Sjh07FB4ertTUVDk5OZlz2vRCY0457b3238+Oo6Oj5s6dK2dnZ505c0bTp09Xjx491Lx5c40ePVoBAQFKTk7OcM7d+Wl+rvlu2W0/dvdNq8hpUVJRMAWQJwaDQRUrVtSgQYM0f/58GQwGffLJJ+ZN4XMrfSN8f39//fTTT5Lu7GuUU3EwN0qVKqXWrVvLx8fHvIwpIiJCu3fvLlC/efHoo49KunO3y6w2hsedmxusXbtW1tbWGjt2rDZv3qxjx47pwIED2rNnj/bs2WP+h0NO+9FmNxs0N+rXr68NGzZo3rx5GjhwoNzd3ZWYmKjAwEBNmzZNnp6eLIsHAABZsrOzM08A+Omnn+Tv7y9J+brZU0JCgp544gnVq1cv05/05dAbN26873llek578uTJ+zpuSeLj46P9+/erdOnSmjx5snbs2KFjx45p//795pw2fRZmTjltVsvac6t169batm2b+f4ANWvWVGxsrHbs2KFJkyapX79+Od6MFEDWKJgCyLcnn3xSffv2lclk0n//+99s79Selccee0x169ZVRESEvvnmG0l5SzBzY8CAAebHf/75Z6H2nZP05dqpqanatm1bvvpInzkZHR2tpKSkbNulL+3J77fShSGnBOzy5cvmx3fPBk1P/p999lm98cYbeuSRRzIlivfaf7Yw2NnZqWvXrvrwww/1yy+/aO/evZo2bZqcnJwUHh5uvgmBlPE1zuma7z6W3xmwAACg+EvPXb/55htFRETI3d3dfEPHe4mOjtbWrVtzPVZ8fHye988sqPScNioqKsebcOYkPX+6180si3tOm37MxsYmw56u6Tnt2LFjNXz4cFWtWjXTUvj7kdMajUZ5eXlp9uzZ2rRpk3bt2qW33npLpUqVMs88TXd3fprT+5LdNQMPCwqmAApk7Nixsra21tmzZ3N1B8+7pe9XmpycrHr16mW6e2NB3b3PUUFnruZFp06dzMuKFi1alOvtAFJTU82P01+LlJQUHThwINtz0mf25jY5Lwr79+/P9ti+ffsk3VnSdfdenunJWXY3bIqLi9ORI0cKMcrcKV++vAYNGqS33npLkhQSEqLo6GhJUvXq1c1L03KaUR0YGCgp8zUDAIAHS+PGjeXu7m5e8pyXmz2tWbNGycnJqlChgg4ePKhDhw5l+2fo0KGS7v+y/P79+5tvCDR//vwcZ0jeLaucNiIiQn/99VeW7W/fvm3OJ4trTpt+rF69ehn28kzPaRs0aJDleRcuXLDITY8qVaqkkSNH6qWXXpJ05+Zb6Tw8PMwTFXKT0/7zmoGHBQVTAAXi5uYmT09PSdKCBQsy7ZGTk759++rll1/Wyy+/rIkTJ+b6vLCwsGwTrrulL42S7iQG94udnZ3efvttSdLZs2f1zjvv5DhLNL3dpEmTzD/Xr1/fvAxq4cKFWc7e3blzp7momL4kzBI2btyY5QzeqKgo/fDDD5Jk/h1Jl77fUWhoaJZ9LliwQHFxcYUc6f93r/fj7r3H0hNKg8Fgvo4ffvhBV65cyXReZGSk+Zp79epVWOECAIBi6q233jLns3369Mn1eenL8bt06SJ7e3uVLVs22z/ped7hw4d19uzZIrmOrDg7O2vMmDGS7hTWZs+efc+i6cGDBzVjxgzzz23atDF/4Tx//vwsz/n+++/Nq5IsmdN+//33We4//+eff2rTpk2S8p7Tfvrpp4UcZUb3ymlLly4tKeOSf0dHR7Vt21aStHjx4iz3Vg0NDdXmzZslkdPi4UXBFECBvfrqqzIYDLp48aI5+csNZ2dnvfPOO3rnnXfUvn37XJ939uxZ9ejRQ6NGjZK/v78uXLhgPpacnKyQkBBNnjxZS5culXRn+f8TTzyR+wsqBL169dIrr7wiSdqwYYP69esnf3//DEnYrVu3tHfvXk2ePFl9+/bVmTNnMvSRPssxKChIb7zxhsLCwiTducY1a9ZowoQJkqQmTZrk+WZZhalUqVJ65ZVXFBgYaE6ijx49qpdeeknR0dEqW7asRo0aleGcdu3aSbqz59cPP/xgTvauXLmimTNn6uuvvzYn10Vh3bp1GjRokL7//nvz6yrdmeGwe/duc3LbpEmTDEuQRo8eLUdHR8XExOill17SoUOHzMcOHjyol156STdu3JCTk1OmawYAAA+e9u3bm/PZ3G7Fc/ToUZ0+fVpS5gJcVv71r3+patWqkpSnXLswjBo1Sj169JAkLVu2TM8//7y2bNmSYT/VmzdvaseOHRo3bpwGDx6s8PBw87HSpUvr9ddflyStXbtW77//vnmJekJCgnx9fTVr1ixJUo8ePQp9xVlepKSk6OWXX9bRo0cl3dlzNDAwUK+88oqSkpJUpUoVPf/88xnOSc9pFy5cqM2bN5tvcBQWFqaJEydqw4YNRbqcfdGiRXrllVfk7++fYXl9UlKS1q9fr8WLF0uSnn766QznjR8/Xra2tvr77781YsQI8779qamp2rlzp0aOHKmUlBS5ublp4MCBRRY/UJzZ3LsJAOTM3d1dHTt21LZt2+Tj46NnnnmmSJfA29jYmP8y37lzpyTJ1tZWZcuW1fXr1zN88+3h4aH58+dnu5F6eHi42rRpc88xf/75Z1WpUiVPcb799ttyc3PTnDlzzDNNJalMmTKytbXVjRs3zG3LlCmj3r17Zzi/Q4cOmjx5smbPnq2tW7dq69atcnR0VEJCgnkmr7u7u7y9vQt086OCmjx5sj777DO99NJLKlOmjAwGg+Lj4yXdmW07d+5cc5Kf7uWXX9amTZv0559/6v3339fUqVNlb2+v2NhYmUwmDRw4UElJSXne5iG3TCaTgoODFRwcbI7TaDTqxo0b5mVkFStWzDBDQrpzB9cvv/xSr732ms6cOaPnn3/evPVD+jU7Ojrqyy+/vOfdYAEAwMMpvejp4uKi5s2b37O9wWBQt27dtHTpUq1Zs0YTJ07MtEQ6ODg4Vznt3Uuzc8NgMGju3LmqU6eO/ve//yk4OFjjxo2T9P/vSn/3qiAnJyd17do1Qx9DhgxRWFiYli1bph9++EE//vijHB0dFRcXZy4wPvnkkxn22bSEDz/8UFOmTNFzzz0no9Eok8lknn3p6OioefPmZbor/Pjx4xUYGKirV6/q9ddfl42NjcqUKaPY2FhJ0oQJE/Tbb7/luMVWQZhMJu3evdt8g9vSpUurdOnSGf5NVKdOnQz78kt3/o308ccfa9KkSTp48KD69Okje3t7JScnm7cTq1Klinx8fMzvM/CwoWAKoFCMHj1a27ZtU0REhL7//nvzXktFoV27dtq8ebN27typgwcP6syZM4qIiNCNGzdUpkwZVaxYUQ0aNFDXrl3VvXv3HO86mZqamquN2PNyQ6u7DRw4UD169JCfn5/27Nmj06dPKzo6WomJiapUqZLq1aundu3aqVevXlnOShg+fLiaN2+uZcuW6ffff9fVq1dVunRpeXh4yNPTUy+88MJ93Z81K9WrV9fq1au1cOFC/frrr7p8+bIqVKigVq1a6bXXXlOdOnUynePo6Kjvv/9eX375pbZu3arLly/L2tpaLVq00MCBA9WzZ89MiV1h6tixoz766CPt379fISEhunLliq5fv66yZcuqVq1a6tChg4YMGSJHR8dM57Zo0ULr16/X0qVLtXPnTl28eFEGg0F16tRR+/bt9fLLL8vV1bXIYgcAACVXYmKi+UZBXbp0yfWX3p6enlq6dKmuXbumHTt2ZCpKJicnF9nNhQwGg8aNG6eBAwfKz89PgYGB+vPPPxUTEyMrKytVq1ZNDRo00NNPPy1PT89MRUXpzhfsHTp00MqVK3Xo0CHFxMSobNmyql+/vvr27SsvLy+LTgCQ7qxKW7VqlXx8fLR3715FRUWpUqVKat++vcaOHWu+R8HdqlWrplWrVmnevHnatWuXoqKiVKpUKTVr1kxDhgxR27Zt9dtvvxVZzAMGDFClSpW0f/9+nT59WpcvX9bNmzdVrlw5Pfroo+ratasGDRqUYbupdD169JCHh4cWL16svXv3KiIiQjY2NmrQoIE6d+6s4cOHZ/leAg8Lgym3OzcDAHCXevXqSZJ8fX315JNPWjgaAAAAIG8uXLigTp06SZK2bdum6tWrWzgiAMUFe5gCAAAAAAAAQBoKpgAAAAAAAACQhoIpAAAAAAAAAKShYAoAAAAAAAAAabjpEwAAAAAAAACksbF0ALi3Zs2aKSkpSa6urpYOBQAAPKCuXLkiOzs7BQUFWToUPKTIeQEAQFHKS75LwbQEuHXrlm7fvm3pMAAAwAMsJSVFLDyCJZHzAgCAopSXfJeCaQlQsWJFSdK2bdssHAkAAHhQderUydIh4CFHzgsAAIpSXvJdbvoEAAAAAAAAAGkomAIAAAAAAABAGgqmAAAAAAAAAJCGgikAAAAAAAAApKFgCgAAAAAAAABpKJgCAAAAAAAAQBoKpgAAAAAAAACQhoIpAAAAAAAAAKShYAoAAAAAAAAAaWwsHQCQF6mpqQoNDVVMTIycnJxUv359WVlR9wcAAAAAAEDhoGCKEuPAgQNasWKFrly5Yn7O1dVVgwcPVosWLSwYGQAAAAAAAB4UFExRIhw4cEDe3t5q0qSJxo0bpxo1aigsLEwBAQHy9vbWm2++SdEUAAAAAAAABcZaZhR7qampWrFihZo0aaIJEyaobt26Kl26tOrWrasJEyaoSZMmWrFihVJTUy0dKgAAAAAAAEo4Zpii2AsNDdWVK1c0bty4TPuVWllZqU+fPpo6dapCQ0PVsGFDC0UJAACAh0FkZKTi4+MtHUahMxqNqlSpkqXDAACgWKBgimIvJiZGklSjRo0sj6c/n94OAAAAKAo3btzQhAkTZDKZLB1KobOystKCBQvk6Oho6VAAALA4CqYo9pycnCRJYWFhqlu3bqbjYWFhGdoBAAA8aDZs2KCVK1cqNDRUycnJcnNzU+/evTV8+HDZ2trmup+QkBDt3r1bgYGBOnPmjK5fvy6j0ai6deuqZ8+eGjBgQJb97d+/X0OHDs2x76lTp+r555/P87WVJI6Ojpo7d+59mWF68eJFLViwQK+99pqqVatW5OMZjUaKpQAApKFgimKvfv36cnV1VUBAgCZMmJBhWX5qaqrWrFkjV1dX1a9f34JRAgAAFI0ZM2bI19dXNjY2atmypYxGo/bt26c5c+Zox44dWrJkiUqXLn3PflJSUtSvXz9Jd4pjjRs3louLiyIiInT48GEdPHhQ/v7+Wrx4cbaFMxcXF7Vr1y7LY7Vq1cr/RZYg93vZerVq1R6a1xYAgOKCgimKPSsrKw0ePFje3t6aO3eu+vTpoxo1aigsLExr1qxRcHCw3nzzzUz7mwIAAJR0W7dula+vr4xGo5YvXy4PDw9JUlRUlIYNG6aDBw/K29tb77zzTq768/Dw0MiRI9WpUyfZ2dmZnz916pRGjBiho0ePatasWZo1a1aW59euXVuzZ88u+IUBAAAUY1SYUCK0aNFCb775psLCwjR16lSNGDFCU6dOVVhYmN588021aNHC0iECAAAUOh8fH0nSqFGjzMVSSXJ2dtYHH3wgSVq+fLliY2Pv2ZeNjY38/Pzk6emZoVgqSfXq1dPbb78tSVq/fr2Sk5ML6xIAAABKHGaYosRo0aKFmjVrptDQUMXExMjJyUn169dnZikAAHggRUZG6tixY5KkXr16ZTrerFkzValSReHh4dq5c2eWbfKiYcOGkqTExERFR0erYsWKBeoPAACgpKJgihLFysrKnMwDAAA8yEJCQiTdubFljRo1smzTqFEjhYeHKyQkpMAF07///luSZGtrm+3NNK9evar58+fr8uXLsrOzU+3atfX000+ratWqBRobAACgOKFgCgAAABRDFy5ckCRVqVIl2zaVK1fO0Da/TCaTvv76a0lShw4dMi3ZT/fnn39q3rx5GZ6bMWOGhgwZorfffls2NvzzAgAAlHxkNAAAAEAxFBcXJ0kqU6ZMtm3Kli2boW1+zZ8/X8HBwTIajZo4cWKm4w4ODho2bJi6dOmimjVryt7eXufPn5efn59WrFihZcuWKT4+XtOnTy9QHAAAAMUBBVMAAADgIebv768vv/xSVlZWmjlzpmrWrJmpTcOGDTNti1SvXj1NnjxZTzzxhF5//XX9+OOPeuGFF9SgQYP7FDkAAEDR4G45AAAAQDGUPns0ISEh2zbpM0vT2+bVhg0b9N5770mSpk+fLk9Pzzz30bVrV3ORdPv27fmKAwAAoDihYAoAAAAUQ9WqVZMkhYeHZ9smIiIiQ9u82Lx5s9566y2lpqbqww8/1LPPPpu/QCXVqVNHkhQZGZnvPgAAAIoLCqYAAABAMZS+BD4mJkZhYWFZtjl+/LgkycPDI099b926VRMmTNDt27c1depUDRgwoECxxsTESMr/TFcAAIDipMTvYbphwwatXLlSoaGhSk5Olpubm3r37q3hw4fL1tY21/0cOnRIa9as0cmTJ3Xp0iXFxMTI2tpaVatWVatWrfTSSy+pevXqmc7bv3+/hg4dmmPfU6dO1fPPP5/nawMAAMDDq3LlymrcuLGOHTumtWvXasyYMRmOBwUFKTw8XHZ2dmrfvn2u+92+fbvGjx+vlJQUTZ06VYMGDSpQnJGRkQoKCpIkNW7cuEB9AQAAFAclumA6Y8YM+fr6ysbGRi1btpTRaNS+ffs0Z84c7dixQ0uWLFHp0qVz1dfOnTv13XffqWrVqqpVq5ZcXFwUGxurkJAQLV++XH5+fvLx8dGTTz6Z5fkuLi5q165dlsdq1aqV72sEAADAw2v06NEaO3asFi1apKeeeso8kzQ6OlrTpk2TJA0ZMkQODg7mc7Zs2aJPP/1UlSpV0jfffJOhv507d+qNN95QSkqKpk2bpoEDB+Yqjm+++Ua9e/eWs7NzhudDQ0M1efJkJSYmys3NTZ07dy7I5QIAABQLJbZgunXrVvn6+spoNGr58uXm5DEqKkrDhg3TwYMH5e3trXfeeSdX/fXp00fPPfdcplmkSUlJ+uSTT+Tr66tJkyZp+/btsra2znR+7dq1NXv27IJfGAAAAJCmc+fOevHFF/Xtt99q4MCB5kkCe/fu1Y0bN9S0aVO9+eabGc6JjY3VX3/9paSkpAzPX7t2TePGjVNycrIqV66s4OBgBQcHZznupEmTMhRH582bp48++kj169dX9erVZWVlpfPnz+vkyZNKTU1V1apV5ePjIzs7u8J/EQAAAO6zElsw9fHxkSSNGjUqw55Nzs7O+uCDDzR48GAtX75cr732WoZv3LOTvlH9P9nZ2WnSpEn64YcfFBERobNnz6pevXqFcxEAAADAPUyZMkVNmzbVypUrFRwcrJSUFLm5uWnkyJEaPnx4rouUCQkJ5iJqRESEVq9enW3bcePGZSiYjh49WocOHdLZs2cVGBiohIQE2dvbq0mTJurUqZMGDhwoe3v7gl0oAABAMVEiC6aRkZE6duyYJKlXr16Zjjdr1kxVqlRReHi4du7cmWWbvDAYDLKyunN/LL41BwAAwP3Wo0cP9ejRI1dt+/fvr/79+2d6vnr16jp16lS+xn/llVfydR4AAEBJVCILpiEhIZIkJycn1ahRI8s2jRo1Unh4uEJCQgpUML19+7bmz5+vhIQEPfroo3rkkUeybHf16lXNnz9fly9flp2dnWrXrq2nn35aVatWzffYAAAAAAAAAO6vElkwvXDhgiSpSpUq2bapXLlyhra5denSJX3xxReSpJiYGJ08eVIRERF65JFH9Pnnn5tnmv7Tn3/+qXnz5mV4bsaMGRoyZIjefvtt2diUyJcaAAAAKPauXr2q2NhYS4dRqC5evJjhvw8SBwcHubi4WDoMAACyVSKreHFxcZKkMmXKZNumbNmyGdrm1vXr1zPt5+Th4aGZM2eqbt26mdo7ODho2LBh6tKli2rWrCl7e3udP39efn5+WrFihZYtW6b4+HhNnz49T3EAAAAAuLerV69q4ltvKfkfN7l6UCxYsMDSIRQ6Wzs7fTpnDkVTAECxVSILpkWpQYMGOnXqlEwmky5fvqxDhw7piy++UP/+/fXuu+9q6NChGdo3bNhQDRs2zPBcvXr1NHnyZD3xxBN6/fXX9eOPP+qFF15QgwYN7uelAAAAAA+82NhYJSclyanNY7IpV9bS4eAeUq7HKWbPUcXGxlIwBQAUWyWyYJo+ezQhISHbNukzS9Pb5pXBYFClSpXk6empNm3aqGfPnpo1a5ZatGih+vXr56qPrl27qkGDBjp58qS2b99OwRQAAAAoIjblysq2QjlLhwEAAB4AJbJgWq1aNUlSeHh4tm0iIiIytC0IR0dHdenSRStWrNC2bdtyXTCVpDp16ujkyZOKjIwscBzFXWRkpOLj4y0dRqEzGo2qVKmSpcMAAAAAAADAfVAiC6bpS+BjYmIUFhamGjVqZGpz/PhxSXf2Hy0M6fulRkVF5em8mJgYSfmf6VpS3LhxQxMmTJDJZLJ0KIXOyspKCxYskKOjo6VDAQAAAAAAQBErkQXTypUrq3Hjxjp27JjWrl2rMWPGZDgeFBSk8PBw2dnZqX379oUy5r59+yRJNWvWzPU5kZGRCgoKkiQ1bty4UOIorhwdHTV37tz7MsP04sWLWrBggV577bVCmUF8L0ajkWIpAABAMZdy/aalQ0Au8D4BAEqCElkwlaTRo0dr7NixWrRokZ566inzTNLo6GhNmzZNkjRkyBA5ODiYz9myZYs+/fRTVapUSd98802G/r766is999xzcnZ2zvD89evX9cUXX+j48eNycHCQp6dnhuPffPONevfunem80NBQTZ48WYmJiXJzc1Pnzp0L7dqLq/u9bL1atWqqVavWfR0TAAAAxVPMnmOWDgEAADwgSmzBtHPnznrxxRf17bffauDAgWrZsqWMRqP27t2rGzduqGnTpnrzzTcznBMbG6u//vpLSUlJmfqbO3euvL295e7uLjc3N1lbWysyMlInT55UfHy8HBwc5O3tnelOjvPmzdNHH32k+vXrq3r16rKystL58+d18uRJpaamqmrVqvLx8ZGdnV2Rvh4AAADAw8ypTWPZlLO3dBi4h5TrNyluAwCKvRJbMJWkKVOmqGnTplq5cqWCg4OVkpIiNzc3jRw5UsOHD89TkfL9999XUFCQQkJCtHfvXsXHx6ts2bJyd3dX27Zt9fzzz2cqlkp3ZroeOnRIZ8+eVWBgoBISEmRvb68mTZqoU6dOGjhwoOztSdwAAACAomRTzl62FcpZOgwAAPAAKNEFU0nq0aOHevTokau2/fv3V//+/bM8NnjwYA0ePDjP47/yyit5PgcAAAAAAABA8WRl6QAAAAAAAAAAoLigYAoAAAAAAAAAaSiYAgAAAAAAAEAaCqYAAAAAAAAAkIaCKQAAAAAAAACksbF0AAAAAABQUCnX4ywdAnKB9wkAUBJQMAUAAABQYjk4OMjWzk4xe45aOhTkkq2dnRwcHCwdBgAA2aJg+oC7evWqYmNjLR1Gobp48WKG/z5IHBwc5OLiYukwAAAASgwXFxd9OmfOA5nzLliwQK+99pqqVatm6XAKFTkvAKC4o2D6ALt69aomvvWWkpOSLB1KkViwYIGlQyh0tnZ2+nTOHBJIAACAPHBxcXlg86dq1aqpVq1alg4DAICHCgXTB1hsbKySk5Lk1OYx2ZQra+lwcA8p1+MUs+eoYmNjH9iEHwAAAAAAoLijYPoQsClXVrYVylk6DAAAAAAAAKDYs7J0AAAAAAAAAABQXDDD9CGQcv2mpUNALvA+AQAAAAAAWB4F04dAzJ5jlg4BAAAAAAAAKBEomD4EnNo0lk05e0uHgXtIuX6T4jYAAAAAAICFUTB9CNiUs+emTwAAAAAAAEAucNMnAAAAAAAAAEhDwRQAAAAAAAAA0lAwBQAAAAAAAIA0FEwBAAAAAAAAIA0FUwAAAAAAAABIQ8EUAAAAAAAAANJQMAUAAAAAAACANBRMAQAAAAAAACANBVMAAAAAAAAASEPBFAAAAAAAAADS2Fg6AAAAAAAoKSIjIxUfH1/k41y8eDHDf4ua0WhUpUqV7stYAAAUdxRMHwIp1+MsHQJygfcJAACgeLtx44YmTJggk8l038ZcsGDBfRnHyspKCxYskKOj430ZDwCA4oyC6QPMwcFBtnZ2itlz1NKhIJds7ezk4OBg6TAAAACQBUdHR82dO/e+zDC934xGI8VSAADSUDB9gLm4uOjTOXMUGxtr6VAK1cWLF7VgwQK99tprqlatmqXDKVQODg5ycXGxdBgAAADIBsvWAQB48FEwfcC5uLg8sAW4atWqqVatWpYOAwAAAAAAAA8QK0sHAAAAAAAAAADFBQVTAAAAAAAAAEhDwRQAAAAAAAAA0lAwBQAAAAAAAIA03PQJhSYyMlLx8fFFPs7Fixcz/LeoGY1G7oYKAAAAAADwkKBgikJx48YNTZgwQSaT6b6NuWDBgvsyjpWVlRYsWCBHR8f7Mh4AAAAAAAAsh4IpCoWjo6Pmzp17X2aY3m9Go5FiKQAAAAAAwEOCgikKDcvWAQAAAAAAUNJx0ycAAAAAAAAASEPBFAAAAAAAAADSUDAFAAAAAAAAgDQUTAEAAAAAAAAgTYm/6dOGDRu0cuVKhYaGKjk5WW5uburdu7eGDx8uW1vbXPdz6NAhrVmzRidPntSlS5cUExMja2trVa1aVa1atdJLL72k6tWrZ3v+33//rYULFyowMFBRUVFydnZW69atNXbsWNWoUaMwLhUAAAAAAABAESvRM0xnzJih8ePH69ChQ3rsscfUrl07hYeHa86cORo2bJgSExNz3dfOnTv13Xff6fLly6pVq5a6dOmi5s2b6/r161q+fLl69+6t/fv3Z3nuwYMH1bdvX61evVqOjo7q0qWLHB0dtXr1avXp00eHDx8upCsGAAAAAAAAUJRK7AzTrVu3ytfXV0ajUcuXL5eHh4ckKSoqSsOGDdPBgwfl7e2td955J1f99enTR88991ymWaRJSUn65JNP5Ovrq0mTJmn79u2ytrY2H09ISND48eOVkJCgV199VRMmTDAfmzt3rr766iuNHz9eGzduVOnSpQvhygEAAAAAAAAUlRI7w9THx0eSNGrUKHOxVJKcnZ31wQcfSJKWL1+u2NjYXPVXp06dLJfc29nZadKkSSpVqpQiIiJ09uzZDMf9/Px0+fJl1axZU+PHj89wbPz48apZs6bCw8Pl7++fh6sDAAAAAAAAYAklsmAaGRmpY8eOSZJ69eqV6XizZs1UpUoVJSUlaefOnQUez2AwyMrqzktlZ2eX4djWrVslST179jS3SWdlZaUePXpIkrZs2VLgOAAAAAAAAAAUrRJZMA0JCZEkOTk5ZXtDpUaNGmVom1+3b9/W/PnzlZCQoEcffVSPPPJIlrGkj1dUcQAAAAAAAAAoeiVyD9MLFy5IkqpUqZJtm8qVK2dom1uXLl3SF198IUmKiYnRyZMnFRERoUceeUSff/55hlmkN2/eVExMjCSpatWqWfaXHmNUVJTi4+NlNBrzFA8AAAAAAACA+6dEFkzj4uIkSWXKlMm2TdmyZTO0za3r169r9erVGZ7z8PDQzJkzVbdu3SzjyCmWuwukN2/epGAKAAAAAAAAFGMlckl+UWrQoIFOnTql0NBQ7dq1S59//rkSEhLUv39/+fr6Wjo8AAAAAAAAAEWoRBZM02ePJiQkZNsmffZnetu8MhgMqlSpkjw9PfXDDz+oQoUKmjVrlkJDQzPFkVMs8fHx5sf29vb5igUAAAAAAADA/VEiC6bVqlWTJIWHh2fbJiIiIkPbgnB0dFSXLl2Umpqqbdu2mZ+3t7eXk5OTpDt7n2YlPcby5cuzHB8AAAAAAAAo5kpkwbRhw4aS7tyUKSwsLMs2x48fl3Rn/9HCkL5HaVRUVJaxpI9X1HEAAAAAAAAAKDolsmBauXJlNW7cWJK0du3aTMeDgoIUHh4uOzs7tW/fvlDG3LdvnySpZs2aGZ7v3LmzJGndunVKTU3NcCw1NVXr16+XJHXp0qVQ4gAAAAAAAABQdEpkwVSSRo8eLUlatGiRTpw4YX4+Ojpa06ZNkyQNGTJEDg4O5mNbtmxR9+7dNWzYsEz9ffXVV5lmj0rS9evXNX36dB0/flwODg7y9PTMcLx///6qWLGizp07J29v7wzHvL29de7cOVWuXFleXl75vlYAAAAAAAAA94eNpQPIr86dO+vFF1/Ut99+q4EDB6ply5YyGo3au3evbty4oaZNm+rNN9/McE5sbKz++usvJSUlZepv7ty58vb2lru7u9zc3GRtba3IyEidPHlS8fHxcnBwkLe3t1xcXDKcV6ZMGX3++ecaMWKEfHx8tH37dtWtW1dnzpzR6dOnZTQa5e3trdKlSxfp6wEAAAAAAACg4EpswVSSpkyZoqZNm2rlypUKDg5WSkqK3NzcNHLkSA0fPlx2dna57uv9999XUFCQQkJCtHfvXsXHx6ts2bJyd3dX27Zt9fzzz2cqlqZ74oknFBAQoAULFigwMFCbN29W+fLl5eXlpbFjx8rNza2wLhkAAAAAAABAETKYTCaTpYNAzjp16iRJ2rZtm4UjAQAADyryDVgav4MAAKAo5SXXKLF7mAIAAAAAAABAYaNgCgAAAAAAAABpKJgCAAAAAAAAQJoSfdMnAAAA4GGwYcMGrVy5UqGhoUpOTpabm5t69+6t4cOHy9bWNtf9hISEaPfu3QoMDNSZM2d0/fp1GY1G1a1bVz179tSAAQNy7O/vv//WwoULFRgYqKioKDk7O6t169YaO3asatSoURiXCgAAYHEUTAEAAIBibMaMGfL19ZWNjY1atmwpo9Goffv2ac6cOdqxY4eWLFmi0qVL37OflJQU9evXT5JkNBrVuHFjubi4KCIiQocPH9bBgwfl7++vxYsXy9HRMdP5Bw8e1IgRI5SQkKC6devqiSee0JkzZ7R69Wpt2rRJS5cu1eOPP17Ylw8AAHDfUTAFAAAAiqmtW7fK19dXRqNRy5cvl4eHhyQpKipKw4YN08GDB+Xt7a133nknV/15eHho5MiR6tSpk+zs7MzPnzp1SiNGjNDRo0c1a9YszZo1K8N5CQkJGj9+vBISEvTqq69qwoQJ5mNz587VV199pfHjx2vjxo25Kt4CAAAUZ+xhCgAAABRTPj4+kqRRo0aZi6WS5OzsrA8++ECStHz5csXGxt6zLxsbG/n5+cnT0zNDsVSS6tWrp7fffluStH79eiUnJ2c47ufnp8uXL6tmzZoaP358hmPjx49XzZo1FR4eLn9//7xeIgAAQLFDwRQAAAAohiIjI3Xs2DFJUq9evTIdb9asmapUqaKkpCTt3LmzwOM1bNhQkpSYmKjo6OgMx7Zu3SpJ6tmzp6ysMv4TwsrKSj169JAkbdmypcBxAAAAWBoFUwAAAKAYCgkJkSQ5OTlle0OlRo0aZWhbEH///bckydbWVk5OTlnGkj5eUcYBAABgaRRMAQAAgGLowoULkqQqVapk26Zy5coZ2uaXyWTS119/LUnq0KFDhiX7N2/eVExMjCSpatWqWZ6fHmNUVJTi4+MLFAsAAIClUTAFAAAAiqG4uDhJUpkyZbJtU7Zs2Qxt82v+/PkKDg6W0WjUxIkTs4wjp1iMRqP58c2bNwsUCwAAgKVRMAUAAAAeYv7+/vryyy9lZWWlmTNnqmbNmpYOCQAAwKIomAIAAADFUPrs0YSEhGzbpM/+TG+bVxs2bNB7770nSZo+fbo8PT2zjSOnWO5ehm9vb5+vWAAAAIoLCqYAAABAMVStWjVJUnh4eLZtIiIiMrTNi82bN+utt95SamqqPvzwQz377LNZtrO3tzffBOrSpUtZtkmPsXz58hmW5wMAAJREFEwBAACAYqhhw4aSpJiYGIWFhWXZ5vjx45IkDw+PPPW9detWTZgwQbdv39bUqVM1YMCAXMWSPl5hxQEAAFAcUTAFAAAAiqHKlSurcePGkqS1a9dmOh4UFKTw8HDZ2dmpffv2ue53+/btGj9+vFJSUjR16lQNGjTonud07txZkrRu3TqlpqZmOJaamqr169dLkrp06ZLrOAAAAIorCqYAAABAMTV69GhJ0qJFi3TixAnz89HR0Zo2bZokaciQIXJwcDAf27Jli7p3765hw4Zl6m/nzp164403lJKSomnTpuWqWCpJ/fv3V8WKFXXu3Dl5e3tnOObt7a1z586pcuXK8vLyyuslAgAAFDs2lg4AAAAAQNY6d+6sF198Ud9++60GDhyoli1bymg0au/evbpx44aaNm2qN998M8M5sbGx+uuvv5SUlJTh+WvXrmncuHFKTk5W5cqVFRwcrODg4CzHnTRpkpydnc0/lylTRp9//rlGjBghHx8fbd++XXXr1tWZM2d0+vRpGY1GeXt7q3Tp0oX/IgAAANxnFEwBAACAYmzKlClq2rSpVq5cqeDgYKWkpMjNzU0jR47U8OHDZWdnl6t+EhISzEXUiIgIrV69Otu248aNy1AwlaQnnnhCAQEBWrBggQIDA7V582aVL19eXl5eGjt2rNzc3PJ/kQAAAMUIBVMAAACgmOvRo4d69OiRq7b9+/dX//79Mz1fvXp1nTp1qkBxPPLII/roo48K1AcAAEBxxx6mAAAAAAAAAJCGgikAAAAAAAAApKFgCgAAAAAAAABpKJgCAAAAAAAAQBoKpgAAAAAAAACQhoIpAAAAAAAAAKShYAoAAAAAAAAAaSiYAgAAAAAAAEAaCqYAAAAAAAAAkCZfBVNfX1/5+vrq+vXrBRo8PDxc48aN0+uvv16gfgAAAAAAAACgMNjk56SZM2fKYDCodevWKleuXKbjZ86cUe/evWVlZaWQkJBs+7l586a2bt0qg8GQnzAAAAAAAAAAoFAV6ZJ8k8lUlN0DAAAAAAAAQKFiD1MAAAAAAAAASEPBFAAAAAAAAADSUDAFAAAAAAAAgDQUTAEAAAAAAAAgDQVTAAAAAAAAAEhDwRQAAAAAAAAA0lAwBQAAALIwa9YszZo1S9euXcvy+O3bt3Xp0iVdunQpx37CwsLUr18/9e/fvyjCBAAAQCGzKcjJ27Zt0/HjxzM9HxkZaX7s7++f7fl3twMAAACKk2+++UYGg0HPPfecKlSokOn4n3/+qd69e8vKykohISHZ9pOYmKiTJ0/KYDAUZbgAAAAoJAUqmH7++efZHktPCCdPnlyQIQAAAIBizWQyWToEAAAAFKJ8F0xJDAEAAAAAAAA8aPJVMJ01a1ZhxwEAAAAAAAAAFpevgmm/fv0KO45827Bhg1auXKnQ0FAlJyfLzc1NvXv31vDhw2Vra5vrfkJCQrR7924FBgbqzJkzun79uoxGo+rWrauePXtqwIABWfa3f/9+DR06NMe+p06dqueffz7P1wYAAAAAAADg/irQHqaWNmPGDPn6+srGxkYtW7aU0WjUvn37NGfOHO3YsUNLlixR6dKl79lPSkqKuQhsNBrVuHFjubi4KCIiQocPH9bBgwfl7++vxYsXy9HRMcs+XFxc1K5duyyP1apVK/8XCQAAAAAAAOC+KbEF061bt8rX11dGo1HLly+Xh4eHJCkqKkrDhg3TwYMH5e3trXfeeSdX/Xl4eGjkyJHq1KmT7OzszM+fOnVKI0aM0NGjRzVr1qxstyOoXbu2Zs+eXfALAwAAAAAAAGAxVvdroNDQUG3atEmbN2/WyZMnC9yfj4+PJGnUqFHmYqkkOTs764MPPpAkLV++XLGxsffsy8bGRn5+fvL09MxQLJWkevXq6e2335YkrV+/XsnJyQWOHQAAAAAAAEDxlO8Zpn/99ZckydHRURUqVMi23d69ezVt2jT9/fffGZ6vWrWqJk+erM6dO+d57MjISB07dkyS1KtXr0zHmzVrpipVqig8PFw7d+7Msk1eNGzYUJKUmJio6OhoVaxYsUD9AQAAAAAAACie8lUwDQ0NlZeXlwwGg2bNmiUvL68s2+3evVtjxozR7du3ZTKZMhy7ePGi3njjDX300Ufq3bt3nsYPCQmRJDk5OalGjRpZtmnUqJHCw8MVEhJS4IJperHX1tZWTk5OWba5evWq5s+fr8uXL8vOzk61a9fW008/rapVqxZobAAAAFjWypUr5ezsnOn5qKgo8+P58+dne/7d7QAAAFD85atgumfPHkmSg4ODevbsmWWbhIQEvffee0pJSZEklStXTk8//bQqVqyo48ePa+/evUpNTdX06dPVrl27bAuRWblw4YIkqUqVKtm2qVy5coa2+WUymfT1119Lkjp06JBpyX66P//8U/Pmzcvw3IwZMzRkyBC9/fbbsrEpsdvFAgAAPNS+++67bI8ZDAZJ0pdffnm/wgEAAEARy1cV7+jRozIYDGrfvr1sbW2zbLN27VpduXJFBoNBjz76qJYsWSJXV1fzcT8/P7333nuKjY3VL7/8ohdffDHX48fFxUmSypQpk22bsmXLZmibX/Pnz1dwcLCMRqMmTpyY6biDg4OGDRumLl26qGbNmrK3t9f58+fl5+enFStWaNmyZYqPj9f06dMLFAcAAADuv3+ukgIAAMCDL18F0z///FOS1Lx582zbbNy40fx4ypQpGYqlktS/f39t3LhRu3bt0p49e/JUML1f/P399eWXX8rKykozZ85UzZo1M7Vp2LCheY/TdPXq1dPkyZP1xBNP6PXXX9ePP/6oF154QQ0aNLhPkQMAAKCgfH19LR0CAAAALCBfBdOIiAhJUu3atbM8npqaqkOHDslgMKhy5cp68skns2zn6empXbt26fTp03kaP332aEJCQrZt0meWprfNqw0bNui9996TJE2fPl2enp557qNr165q0KCBTp48qe3bt1MwBQAAKEFatGhh6RAAAABgAVb5OSk+Pl6SZG9vn+XxM2fOmIuZOc1CTS+4xsTE5Gn8atWqSZLCw8OzbZNe1E1vmxebN2/WW2+9pdTUVH344Yd69tln89xHujp16kiSIiMj890HAAAAAAAAgPsjXwXT9BsfZbc/6NGjR82PPTw8su2nVKlSkqSkpKQ8jZ++BD4mJkZhYWFZtjl+/Pg9x8/K1q1bNWHCBN2+fVtTp07VgAED8nT+P6UXg/M70xUAAAAlX0hIiGbOnGnpMAAAAJAL+SqYVqxYUZIUGhqa5fGgoCDz48cffzzbfq5fvy5JMhqNeRq/cuXKaty4saQ7N5fKavzw8HDZ2dmpffv2ue53+/btGj9+vFJSUjR16lQNGjQoT3H9U2RkpPm1SI8XAAAAD4fLly/r66+/Vu/evfXMM8/o22+/tXRIAAAAyIV8FUwbNWokk8mkVatWZToWHx+vHTt2SLozq7JRo0bZ9vPXX39JkipVqpTnGEaPHi1JWrRokU6cOGF+Pjo6WtOmTZMkDRkyRA4ODuZjW7ZsUffu3TVs2LBM/e3cuVNvvPGGUlJSNG3atFwXS7/55htFRUVlej40NFSjR49WYmKi3Nzc1Llz5zxdHwAAAEqexMRErVmzRiNGjFCHDh306aef6uzZszKZTJYODQAAALmUr5s+9ezZU+vWrdPJkyc1ZcoUvfvuu7K3t9eNGzc0ZcoU3bhxQwaDQd26dZO1tXW2/fz++++SpLp16+Y5hs6dO+vFF1/Ut99+q4EDB6ply5YyGo3au3evbty4oaZNm+rNN9/McE5sbKz++uuvTFsAXLt2TePGjVNycrIqV66s4OBgBQcHZznupEmT5OzsbP553rx5+uijj1S/fn1Vr15dVlZWOn/+vE6ePKnU1FRVrVpVPj4+5m0MAAAA8ODZt2+fAgICtHnzZvN+/+lFUldXV3Xp0kVdu3a1ZIgAAADIpXwVTDt27KimTZvq0KFDWrVqlfz9/VW+fHldu3bNnBja2Nho5MiR2faRkJCgHTt2yGAwqGnTpvkKfsqUKWratKlWrlyp4OBgpaSkyM3NTSNHjtTw4cNzXaRMSEgwF1EjIiK0evXqbNuOGzcuQ8F09OjROnTokM6ePavAwEAlJCTI3t5eTZo0UadOnTRw4MBsb44FAACAkuuPP/5QQECAfvnlF/MNR9Nz4cqVK6tr167q1q2bmjZtKoPBYMlQAQAAkAf5KphKd2ZWDh8+XGfOnFFKSoquXLliPmZlZaUPPvhANWvWzPb81atXKz4+XgaDQW3bts1vGOrRo4d69OiRq7b9+/dX//79Mz1fvXp1nTp1Kl/jv/LKK/k6DwAAACVPdHS01q1bJ39/f/O2UOlFUkdHR/NKq0mTJuU6RwUAAEDxku+CaYUKFeTn56cff/xR27dv16VLl2RraysPDw89//zzeuyxx3I8PzAwUB4eHqpcuXKOhVUAAADAkpKTk7Vjxw75+/tr9+7dSklJMRdJbW1t1b59e/Xp00dPP/30PXNgAAAAFH/5LphKdxLEwYMHa/DgwXk+d/78+QUZGgAAAChShw8flr+/vzZs2KAbN25IujObNH1LqT59+sjT01PlypWzcKQAAAAoTAUqmAIAAAAPqkGDBslgMJhnk9aqVUt9+vRR7969Vb16dQtHBwAAgKJCwRQAAADIQdmyZTVlyhT169fP0qEAAADgPrCydAAAAABAcWUymRQfH6/33ntP/fr109KlS3X58mVLhwUAAIAilK8ZpkWx/+i4ceMKvU8AAAAgv7799lv5+flp8+bNiouL08mTJxUaGqo5c+aoRYsW6tu3r7p06aKyZctaOlQAAAAUonwXTA0GQ6EGQsEUAAAAxUnz5s3VvHlzTZ06VVu2bJG/v7/27t2r27dva9++fdq3b5+mTZumDh06qG/fvmrbtq2lQwYAAEAhKNAepukb4BdUYRdfAQAAgMJSqlQp9erVS7169dKVK1e0Zs0arVmzRqdOnVJCQoI2bNigDRs2yMnJydKhAgAAoBAUqGBaunRpderUSX379lWdOnUKKyYAAACgWHJ1ddWIESM0YsQIhYaGavXq1Vq3bp2uXr2q6Oho80SA2bNn69ChQ+revbuaNWtm4agBAACQFwZTPqaJvvTSS9q/f79SU1PNSaGHh4f69u2rnj17ytnZudADfZh16tRJkrRt2zYLRwIAAB5U5Bv5d/v2bf3222/y9/fX9u3bdevWLUn/fxVVhQoV1LlzZ3Xr1k2tWrWyZKjFGr+DAACgKOUl18hXwVSSIiMj9csvv2jNmjU6ffr0nc4MBllbW6tt27bq06ePOnfuLDs7u/x0j7uQPAIAgKJGvlE4bt68qfXr1ysgIECHDh0yb2FlMBhkMBgUEhJi4QiLL34HAQBAUcpLrpHvJfmVKlXSK6+8oldeeUWhoaHy9/fX2rVrdfXqVf3666/auXOn7O3t1b17d/Xp00fNmzfP71AAAABAiWBvb68BAwZowIABunDhgvz9/bVmzRqdP3/e0qEBAAAgl6wKo5P69evr3Xff1a5du/T111+rV69eKl26tGJjY/Xzzz9r6NCh6tixo7y9vfXXX38VxpAAAABAsVa9enWNGzdOmzdv1ooVK/Tcc89ZOiQAAADkQoFu+vRPVlZWatu2rdq2bav4+Hht3rxZ/v7+OnDggC5duiQfHx/5+PioSZMmWrlyZWEODQAAABRbTzzxhJ544glLhwEAAIBcKNSC6d2MRqO8vLzk5eWlyMhIrVq1Sl999ZVu3bqlEydOFNWwAAAAQKH4/fffC71PtqkCAAAo/oqsYJouODhYAQEB2rBhg5KSkop6OAAAAKBQvPjii+Y73RcGbvoEAABQMhRJwfT8+fNas2aN1qxZo7CwMEmSyWRSqVKl1LFjR3l5eRXFsAAAAEChS7/TPQAAAB4OhVYwvX79utatW6c1a9boyJEjku4klwaDQc2aNVOfPn3k6ekpe3v7whoSAAAAKHKlS5dWp06d1Lp1a1lZFco9UwEAAFCMFahgmpycrB07diggIEC7du1SSkqK+Rv4mjVrqm/fvurbt6+qVq1aKMECAAAA90vZsmUVFxenxMRErV+/XgcOHFCvXr3Ut29f1a9f39LhAQAAoIjkq2AaFBSkNWvWaNOmTbpx44a5SOrk5KSePXuqb9++euyxxwo1UAAAAOB+CgwM1LZt2xQQEKA9e/boypUrWrZsmZYtWyZ3d3d5eXmpZ8+eqlixoqVDBQAAQCHKV8F0yJAhMhgMMplMsrOzU8eOHdW3b1+1a9dONjZFfh8pAAAAoMiVKlVKPXr0UI8ePRQVFaVffvlFAQEBCgkJ0alTp/Txxx9rzpw5atmypby8vNSlSxeVLl3a0mEDAACggApU3SxdurTatm2rMmXKaPPmzdq8eXO++jEYDJo5c2ZBQgEAAACKjLOzs4YNG6Zhw4bpjz/+kL+/v9auXavw8HDt2bNHgYGBKlOmjLp27aq+ffuqVatWlg4ZAAAA+VSggumtW7e0bdu2QgmEgikAAABKgjp16mjixImaOHGi9u/fL39/f23evFlxcXHy9/dXQECAKlasKC8vL/373/+2dLgAAADIo3zf5tNkMhXqHwAAAKCkefLJJzVr1iwFBgbq008/1VNPPSVra2tFRkZq2bJllg4PAAAA+ZCvGaahoaGFHQcAAABQYhkMBvMfAAAAlGzcoQkAAADIpwMHDiggIECbN2/WzZs3Jd1ZieXq6qq+fftaODoAAADkR7EomB4/flyNGjWydBgAAADAPf3xxx8KCAgw3/RJulMkLVOmjDp37iwvLy+1atVKVlb53v0KAAAAFmTRgumhQ4e0YMECBQYGKiQkxJKhAAAAANm6du2a1q5dq4CAAJ08eVLSnSKplZWVnnzySfXt21ddu3aV0Wi0cKQAAAAoKIsUTPfu3asFCxYoKCjIEsMDAAAA93Tr1i1t3bpVAQEBCgwM1O3bt803K61bt6769u2r3r17q1KlShaOFAAAAIWpQAVTk8mkLVu2KDAwUBEREbKxsVG1atXUrVs3NW3aNFP7/fv367PPPtORI0fM50tSmzZtChIGAAAAUOhatWqlhIQESXfyVhcXF/Xq1Ut9+/ZVgwYNLBwdAAAAikq+C6YXL17Ua6+9ptOnT2c65uvrq+7du2vOnDmytrZWdHS0pkyZou3bt0u6k3AaDAZ16tRJo0ePVuPGjfN/BQAAAEARiI+Pl8FgUKlSpdSxY0e1adNG1tbWOnXqlE6dOpWvPr28vAo3SAAAABS6fBVMk5KSNHr0aJ05cybbNhs3blSVKlX04osvasiQIbp06ZJMJpOsra3VvXt3jR49WnXr1s134AAAAMD9cOvWLW3YsEEbNmwoUD8Gg4GCKQAAQAmQr4LpL7/8ojNnzshgMKhq1aoaM2aM3N3dZWdnpz/++EOLFy9WSEiIvvvuOx0+fFgXL16UJHXt2lUTJkxQzZo1C/MaAAAAgCKRvoUUAAAAHh75Kphu2bJFklS5cmWtWbNGZcuWNR+rX7++PD09NXjwYAUHB+vQoUOytrbWjBkz+EYdAAAAJYavr6+lQwAAAIAF5KtgGhoaKoPBoBEjRmQolqazsrLSG2+8oZdeekkGg0F9+vShWAoAAIASpUWLFpYOwWzDhg1auXKlQkNDlZycLDc3N/Xu3VvDhw+Xra1trvuJjo7Wjh07dOLECZ04cUInT55UYmKiWrVqpWXLlmV73v79+zV06NAc+546daqef/75XMcCAABQXOWrYBoTEyNJOe5BWq9ePfPj7t2752cYAAAA4KE3Y8YM+fr6ysbGRi1btpTRaNS+ffs0Z84c7dixQ0uWLFHp0qVz1dfBgwc1efLkfMfi4uKidu3aZXmsVq1a+e4XAACgOMlXwTQxMVEGg0EVKlTIto2zs7P5caVKlfIzDAAAAPBQ27p1q3x9fWU0GrV8+XJ5eHhIkqKiojRs2DAdPHhQ3t7eeuedd3LVX4UKFTRw4EB5eHioYcOGOnHihD744INcx1O7dm3Nnj07X9cCAABQUljdj0FsbPJVlwUAAAAeaj4+PpKkUaNGmYul0p3JCemFzuXLlys2NjZX/TVp0kQffvihBg4cqMaNG8vOzq7wgwYAACjh7kvBFAAAAEDeREZG6tixY5KkXr16ZTrerFkzValSRUlJSdq5c+f9Dg8AAOCBVaCpnytXrsyw9L4g7caNG1eQUAAAAIAHSkhIiCTJyclJNWrUyLJNo0aNFB4erpCQkCyLqoXt6tWrmj9/vi5fviw7OzvVrl1bTz/9tKpWrVrkYwMAANwvBSqYfvfddzkeNxgMuWonUTAFAAAA7nbhwgVJUpUqVbJtU7ly5Qxti9qff/6pefPmZXhuxowZGjJkiN5++2224gIAAA+EfGc0JpOp0IJIL6wCAAAAuCMuLk6SVKZMmWzblC1bNkPbouLg4KBhw4apS5cuqlmzpuzt7XX+/Hn5+flpxYoVWrZsmeLj4zV9+vQijQMAAOB+yFfB1NfXt7DjAAAAAFBMNWzYUA0bNszwXL169TR58mQ98cQTev311/Xjjz/qhRdeUIMGDSwUJQAAQOHIV8G0RYsWhR0HAAAAgLukzx5NSEjItk36zNL0tpbQtWtXNWjQQCdPntT27dspmAIAgBKvxG8ytGHDBq1cuVKhoaFKTk6Wm5ubevfureHDh8vW1jbX/YSEhGj37t0KDAzUmTNndP36dRmNRtWtW1c9e/bUgAEDcuzv77//1sKFCxUYGKioqCg5OzurdevWGjt2bLab9AMAAADZqVatmiQpPDw82zYREREZ2lpKnTp1dPLkSUVGRlo0DgAAgMJQogumM2bMkK+vr2xsbNSyZUsZjUbt27dPc+bM0Y4dO7RkyRKVLl36nv2kpKSoX79+kiSj0ajGjRvLxcVFEREROnz4sA4ePCh/f38tXrxYjo6Omc4/ePCgRowYoYSEBNWtW1dPPPGEzpw5o9WrV2vTpk1aunSpHn/88cK+fAAAADzA0pfAx8TEKCwsLMsv4Y8fPy5J8vDwuK+x/VNMTIwky850BQAAKCxWlg4gv7Zu3SpfX18ZjUb9+OOPWrx4sebNm6dNmzbJ3d1dBw8elLe3d6778/Dw0Oeff679+/fL19dXc+fO1cqVK7V69Wq5urrq6NGjmjVrVqbzEhISNH78eCUkJOjVV1/V2rVr9dlnn2nt2rV69dVXFR8fr/HjxysxMbEwLx8AAAAPuMqVK6tx48aSpLVr12Y6HhQUpPDwcNnZ2al9+/b3OzyzyMhIBQUFSZI5XgAAgJKsxBZMfXx8JEmjRo3K8I26s7OzPvjgA0nS8uXLFRsbe8++bGxs5OfnJ09PT9nZ2WU4Vq9ePb399tuSpPXr1ys5OTnDcT8/P12+fFk1a9bU+PHjMxwbP368atasqfDwcPn7++f1EgEAAPCQGz16tCRp0aJFOnHihPn56OhoTZs2TZI0ZMgQOTg4mI9t2bJF3bt317Bhwwotjm+++UZRUVGZng8NDdXo0aOVmJgoNzc3de7cudDGBAAAsJQSuSQ/MjJSx44dkyT16tUr0/FmzZqpSpUqCg8P186dO7Nskxfpy6ESExMVHR2tihUrmo9t3bpVktSzZ09ZWWWsP1tZWalHjx5asGDB/2vv/gOiqvL/j78YBXUCRGTCVExtQUSsIJay3xZmWZrRD9tFk93KUilc+mnrrrSVWSkr6ZK1u2Yl9i1XC1PLNK221SSVJRVR2yLREDEgBtAAZ75/CPNx4oeAzAwDz8c/Mveee897uHh58557ztGGDRt09913n1UcAAAA6FxiYmI0adIkvfXWW5owYYJtGqqtW7eqrKxMkZGRSkxMtDvGbDbru+++U1VVVYPnvOuuu2xf1xVBd+3aZbd92rRpuvbaa22vFy5cqBdeeEGhoaHq37+/DAaDDh48qL1798pisahv375avHhxvYcPAAAA3JFbFkxzcnIkSX5+fo0uqBQeHq6CggLl5OScdcH0+++/lyR5enrKz8+vwVjCw8MbjeP0dgAAAEBLzJo1S5GRkVq+fLmysrJUU1OjAQMG6P7771d8fHyLi5TZ2dn1tpWXl9tt/+XTpA8++KB27typb775Rlu2bNHx48fl7e2tiIgIXX/99ZowYYK8vb1b9wYBAADaGbcsmB46dEiSdN555zXapk+fPnZtW8tqteof//iHJGnkyJF2CWl5ebltgvu+ffs2eHxdjMXFxaqsrJTRaDyreAAAAND5jBkzRmPGjGlW29jYWMXGxja6f9++fS3u/7777mvxMQAAAO7KLecwraiokCT16NGj0TZ1K3TWtW2tRYsWKSsrS0ajUY888kiDcTQVy+kF0vLy8rOKBQAAAAAAAIBjuWXB1Fnef/99/e1vf5PBYNCcOXM0cOBAV4cEAAAAAAAAwIHcsmBa9/To8ePHG21T9/RnXduW+vDDD/XUU09Jkp555hnddNNNjcbRVCyVlZW2r5nXCQAAAAAAAGjf3LJg2q9fP0lSQUFBo22OHDli17YlPv74Yz366KOyWCz6y1/+ojvuuKPBdt7e3rZFoH744YcG29TF2KtXL+YvBQAAAAAAANo5tyyYhoWFSZJKS0uVn5/fYJvdu3dLkoYNG9aic2/cuFFJSUk6efKkkpOTdddddzUrlrr+2ioOAAAAAAAAAM7nlgXTPn36aPjw4ZKkNWvW1Nu/fft2FRQUyMvLS9dcc02zz7tp0ybNmDFDNTU1Sk5O1t13333GY2JiYiRJa9eulcVisdtnsVi0bt06SdKoUaOaHQeAlrNYLMrJydGWLVuUk5NT7/8jAAAAAABAc7hlwVSSHnzwQUnSa6+9pj179ti2l5SU6Omnn5YkTZw4UT4+PrZ9GzZs0I033qjJkyfXO99nn32mhx9+WDU1NXr66aebVSyVpNjYWJ177rnKy8tTamqq3b7U1FTl5eWpT58+Gj9+fEvfIoBmyszM1B/+8Ac9++yzWrRokZ599ln94Q9/UGZmpqtDAwAAAAAAbqarqwNorZiYGE2aNElvvfWWJkyYoMsuu0xGo1Fbt25VWVmZIiMjlZiYaHeM2WzWd999p6qqKrvtP/74oxISElRdXa0+ffooKytLWVlZDfb7+OOPy9/f3/a6R48eWrBgge69914tXrxYmzZtUnBwsA4cOKD9+/fLaDQqNTVV3bt3b/tvAgBlZmYqNTVVF198sW6++WZ5eXmpqqpK2dnZSk1NVWJioqKjo10dJgAAAAAAcBNuWzCVpFmzZikyMlLLly9XVlaWampqNGDAAN1///2Kj4+Xl5dXs85z/PhxWxH1yJEjeu+99xptm5CQYFcwlaRLLrlEGRkZSktL05YtW/Txxx+rV69eGj9+vKZPn64BAwa0/k0CaJTFYlF6eroGDhyoQ4cO2X3QYTKZNHDgQKWnpysqKkoGg9s+UA8AAAAAAJzIrQumkjRmzBiNGTOmWW1jY2MVGxtbb3v//v21b9++tv6uFgAANp9JREFUs4rj/PPP1wsvvHBW5wDQMrm5uSoqKtKxY8cUERGhhIQEBQUFKT8/XxkZGdq5c6etXd0CbQAAAAAAAE3hkSsAbqu4uFiSdNFFFykpKUnBwcHq3r27goODlZSUpIsuusiuHQAAAAAAwJlQMAXgtsrKyiSpwSH3BoNBUVFRdu0AAAAAAADOhIIpALfl6+srSfrqq69ksVjs9lksFm3fvt2uHTofi8WinJwcbdmyRTk5OfV+TgAAAAAA+CW3n8MUQOdVtwBbdna2UlJSNG7cONscpqtXr1Z2drZdO3QumZmZSk9PV1FRkW2byWRSXFycoqOjXRgZAAAAAKA9o2AKwG2FhobKZDLJx8dHBw8eVHJysm1fQECABg8eLLPZrNDQUNcFCZfIzMxUampqg4uBpaamKjExkaIpAAAAAKBBDMkH4LYMBoPi4uL03XffKSgoSPHx8ZoyZYri4+MVFBSk7777TnFxcfXmN0XHZrFYlJ6eroiIiAYXA4uIiFB6ejrD8wEAAAAADeIJUwBuLTo6WomJiUpPT1dWVpZtu8lk4inCTio3N1dFRUVKSEhocDGwcePGKTk5Wbm5uQoLC3NRlAAAAACA9oqCKQC3Fx0draioKOXm5qq0tFR+fn4KDQ3lydJOqrS0VJIUFBTU4P667XXtAAAAAAA4HQVTAB2CwWDgaUFIkvz8/CRJ+fn5Cg4Orrc/Pz/frh0AAAAAAKfj8SsAQIdStxhYRkZGvXlKLRaLVq9eLZPJxGJgAAAAAIAGUTAFAHQodYuBZWVlKSUlRfv379fx48e1f/9+paSkKCsri8XAAAAAAACNYkg+AKDDOX0xsOTkZNt2FgMDAAAAAJwJBVMAQIfEYmAAAAAAgNagYAoA6LBYDAwAAAAA0FI8ZgMAAAAAAAAAtSiYAgAAAAAAAEAthuQDAAAAAAA4QGFhoSorK10dRpszGo0KDAx0dRiAw1AwBQAAAAAAaGNlZWVKSkqS1Wp1dShtzmAwKC0tTb6+vq4OBXAICqYAAJfg03YAAAB0ZL6+vkpJSXFKznv48GGlpaVp2rRp6tevn8P7MxqNFEvRoVEwBQA4HZ+2AwAAoDNw9gfp/fr106BBg5zaJ9ARUTAFANgcO3ZMZrPZKX0lJSXp+PHjDu+nqKhIK1as0J133imTyeTw/nr06KEff/xRP/74o8P78vHxUUBAgMP7AQAAAIDOhIIpAEDSqWLpI48+quqqKleH4hArVqxwdQhtztPLS/PnzaNoCgAAAABtiIIpAECSZDabVV1VpZCLYmT07uXqcHAGleUl2p+9UWazmYIpAABACzhzVJWzHD582O7fjoRRVXAFCqYAAAAAAKBT6OijqtLS0lwdQptjVBVcgYIpAMDO/uyNrg4BAAAAcAhGVbkXRlXBVSiYAgDskDy6h7rkEQAAAADQtiiYAgDsGL17ybun41eTBwAAAFyFD54BNIWCKQDATmV5iatDQDNwnQAAAFpvQHC0uht9XR0GzuBEZZkOHsh0dRjohCiYAnC4wsJCVVZWujqMNmc0GhUYGOjqMNqMj4+PPL28+LTdjXh6ecnHx8fVYQAAALiNupyXIpz7IOeFK1AwBTqpY8eOyWw2O7yfiooKPf/887JarQ7vy9kMBoOefPJJnXPOOQ7tx8fHxykTnAcEBGj+vHlO+blwpsOHDystLU3Tpk1Tv379XB1Om3LWzwYAAEBH4eyct7i4WMePH3d4P0VFRVqxYoXuvPNOmUyOn16rR48e8vf3d3g/EjkvXIOCKdAJHTt2TI8+8oiqqqtdHYpbs1gsmjNnjsP78fL01Lz5851WNHVWMsKTxwAAAHAFZ+W8ZWVlmjVrllMfHlmxYoVT+jEYDEpLS5OvL9MaoGOiYAp0QmazWVXV1Zo4xF+BRm4D7VlhZY2W7SuW2WzuUJ+qlpWVKSkpyanJY1pamlP6IXkEAACAJPn6+iolJaXDPiRAvouOjEoJ0IkFGrsqyNvL1WGgEyJ5BAAAQGfAyCPAPVEwBQC4BMkjAAAAAKA9Mrg6AAAAAAAAAABoLyiYAgAAAAAAAEAthuQDAAAAAAC4KYvFotzcXJWWlsrPz0+hoaEyGHg+DjgbFEwBAAAAAADcUGZmptLT01VUVGTbZjKZFBcXp+joaBdGBrg3CqYAAAAAAABuJjMzU6mpqYqIiFBCQoKCgoKUn5+vjIwMpaamKjExkaIp0EoUTIFOrLCy2tUh4Ay4RgAAAAB+yWKxKD09XREREUpKSrINwQ8ODlZSUpJSUlKUnp6uqKgohucDrUDBFOjElu0rcXUIAAAAgNsrLCxUZWWlq8Noc0ajUYGBga4OAw3Izc1VUVGREhIS6hVEDQaDxo0bp+TkZOXm5iosLMxFUQLui4Ip0IlNHNJLgUZPV4eBJhRWVlPYBgAAaMfKysqUlJQkq9Xq6lDanMFgUFpamnx9fV0dCn6htLRUkhQUFNTg/rrtde0AtAwFU6ATCzR6Ksjby9VhAAAAAG7L19dXKSkpTnnC9PDhw0pLS9O0adPUr18/h/dnNBoplrZTfn5+kqT8/HwFBwfX25+fn2/XDkDLuH3B9MMPP9Ty5cuVm5ur6upqDRgwQGPHjlV8fLw8PZv/5FxJSYk2b96sPXv2aM+ePdq7d69OnDihESNGaOnSpY0et23bNt1zzz1Nnjs5OVm/+c1vmh0LAKBtWCwW5ebmqrS0VH5+fgoNDWUOJwAA0OacPWy9X79+GjRokFP7RPsSGhoqk8mkjIwMuzlMpVM58OrVq2UymRQaGurCKAH35dYF0+eee05vvvmmunbtqssuu0xGo1Fffvml5s2bp82bN2vJkiXq3r17s861Y8cOzZw5s9WxBAQE6KqrrmpwH7/IAMD5MjMzlZ6erqKiIts2k8mkuLg4VgsFAACAWzMYDIqLi1NqaqpSUlI0btw4BQUFKT8/X6tXr1ZWVpYSExN5WABoJbctmG7cuFFvvvmmjEajli1bpmHDhkmSiouLNXnyZO3YsUOpqal64oknmnW+3r17a8KECRo2bJjCwsK0Z88ezZ49u9nxDB48WHPnzm3VewEAtK3MzEylpqYqIiJCCQkJtuQxIyNDqampSkxMpGgKAAAAtxYdHa3ExESlp6crOTnZtt1kMpHvAmfJbQumixcvliRNmTLFViyVJH9/f82ePVtxcXFatmyZpk2bJh8fnzOeLyIiQhEREbbXBw4caPuggXamsLLG1SHgDLhGLWexWJSenq6IiAi74UnBwcFKSkpSSkqK0tPTFRUVxSfuAAAAcGvR0dGKiopiGiqgjbllwbSwsFC7du2SJN1yyy319kdFRem8885TQUGBPvvsswbbAJ2Zj4+PvDw9tWxfsatDQTN4eXo264MfnJKbm6uioiIlJCTUSxQNBoPGjRun5ORk5ebmKiwszEVRAgAAAG3DYDCQ1wJtzC0Lpjk5OZJOrfYWFBTUYJvw8HAVFBQoJyfHKQXTY8eOadGiRTp69Ki8vLw0ePBgXXvtterbt6/D+wZaKiAgQPPmz5fZbHZ1KG3K2auGOouPj48CAgJcHYbbKC0tlaRGfz/Uba9rh86JBcEAoHM4duxYh8p5Dx8+bPdvR0LOC6A9ccuC6aFDhyRJ5513XqNt+vTpY9fW0b799lstXLjQbttzzz2niRMn6rHHHlPXrm75rUYHFhAQ0GETElYN7dz8/PwkSfn5+QoODq63Pz8/364dOh8WBAOAzuHYsWN69JFHVFVd7epQ2lxaWpqrQ2hzXp6emjd/fof9GwWAe3HLKl5FRYUkqUePHo22Oeecc+zaOoqPj48mT56sUaNGaeDAgfL29tbBgwe1atUqpaena+nSpaqsrNQzzzzj0DgAAKeEhobKZDIpIyPDbg5T6dRThatXr5bJZFJoaKgLo4SrsCAYAHQeZrNZVdXVmjjEX4FGt/zTt9MorKzRsn3FMpvNFEwBtAv81jhLYWFh9eYKGTJkiGbOnKlLLrlEDz30kN5991399re/1dChQ10UJQB0HgaDQXFxcUpNTVVKSorGjRtnK4qtXr1aWVlZSkxMZPh1J8SCYADQOQUauyrI28vVYQAA3Ihb/jVQ9/To8ePHG21T92RpXVtXuOGGG2xF0k2bNrksDgDobKKjo5WYmKj8/HwlJyfr3nvvVXJysvLz83mCsBOrWxDs1ltvbXRBsKKiIuXm5rooQgAAAADtgVs+YVq3mEtBQUGjbY4cOWLX1lUuuOAC7d27V4WFhS6NA3ClwsJCVVZWOrwfZ0+CbzQaFRgY6JS+0HLR0dGKiopiYR/YsCAYAAAAgOZwy4Jp3RD40tJS5efnN/iHz+7duyVJw4YNc2psv1T3R5crn3QFXKmsrExJSUmyWq1O69NZk+AbDAalpaXJ19fXKf2h5QwGQ71pU9B5sSAYAHROhZUdb9GnjoZrBKC9ccuCaZ8+fTR8+HDt2rVLa9as0dSpU+32b9++XQUFBfLy8tI111zjoihPPVW3fft2SdLw4cNdFgfgSr6+vkpJSXHKE6bOZjQaKZYCboQFwQCgc1q2r8TVIQAA3IxbFkwl6cEHH9T06dP12muv6eqrr7Y9SVpSUqKnn35akjRx4kT5+PjYjtmwYYPmz5+vwMBAvfHGG20SxxtvvKGxY8fK39/fbntubq5mzpypEydOaMCAAYqJiWmT/gB3xLB1AO0BC4IBQOc0cUgvBRo9XR0GmlBYWU1hG0C74rYF05iYGE2aNElvvfWWJkyYoMsuu0xGo1Fbt25VWVmZIiMjlZiYaHeM2WzWd999p6qqqgbPedddd9m+Li4uliTt2rXLbvu0adN07bXX2l4vXLhQL7zwgkJDQ9W/f38ZDAYdPHhQe/fulcViUd++fbV48WJ5ebEqIwAArla3IFh6erqSk5Nt200mEwuCAUAHFWj0VJA3f48BAJrPbQumkjRr1ixFRkZq+fLlysrKUk1NjQYMGKD7779f8fHxLS5SZmdn19tWXl5ut72ukFrnwQcf1M6dO/XNN99oy5YtOn78uLy9vRUREaHrr79eEyZMkLe3d+veIAAAaHMsCAYAAACgKW5dMJWkMWPGaMyYMc1qGxsbq9jY2Eb379u3r8X933fffS0+BgAAuBYLggEAAABoDI9SAAAAAAAAAEAtCqYAAAAAAAAAUMvth+QDAAAAANCYwsoaV4eAM+AaAWhvKJgCAAAAADocHx8feXl6atm+4jM3hst5eXrKx8fH1WEAgCQKpgAAAEC79+GHH2r58uXKzc1VdXW1BgwYoLFjxyo+Pl6enp7NPk9JSYk2b96sPXv2aM+ePdq7d69OnDihESNGaOnSpWc8/vvvv9crr7yiLVu2qLi4WP7+/rr88ss1ffp0BQUFncU7BNpeQECA5s2fL7PZ7OpQ2szhw4eVlpamadOmqV+/fq4Op035+PgoICDA1WEAgCQKpgAAAEC79txzz+nNN99U165dddlll8loNOrLL7/UvHnztHnzZi1ZskTdu3dv1rl27NihmTNntiqOHTt26N5779Xx48cVHBysSy65RAcOHNB7772n9evX6/XXX9fFF1/cqnMDjhIQENAhi3D9+vXToEGDXB0GgLNQWFioyspKV4fR5oxGowIDA10dxlmjYAoAAAC0Uxs3btSbb74po9GoZcuWadiwYZKk4uJiTZ48WTt27FBqaqqeeOKJZp2vd+/emjBhgoYNG6awsDDt2bNHs2fPPuNxx48f14wZM3T8+HE98MADSkpKsu1LSUnRq6++qhkzZuijjz5qdvEW6EicVfg4fPiw3b+O1lEKH0B7U1ZWpqSkJFmtVleH0uYMBoPS0tLk6+vr6lDOCgVTAAAAoJ1avHixJGnKlCm2Yqkk+fv7a/bs2YqLi9OyZcs0bdq0Zs39FxERoYiICNvrAwcONCuOVatW6ejRoxo4cKBmzJhht2/GjBlav3698vLy9P777+vuu+9u1jmBjsIVhY+0tDSn9NNRCh9Ae+Pr66uUlBSnfdDizKk8jEZjh7hnUDAFAADtCsOTgFMKCwu1a9cuSdItt9xSb39UVJTOO+88FRQU6LPPPmuwTVvZuHGjJOnmm2+WwWCw22cwGDRmzBilpaVpw4YNFEzR6Tiz8OFsHaXwAbRHzs4LmcqjZSiYAgCAdoPhScD/ycnJkST5+fk1uqBSeHi4CgoKlJOT49CCaV0s4eHhjcZxejugs+EDMQDoWCiYAgCAdoPhScD/OXTokCTpvPPOa7RNnz597No6Qnl5uUpLSyVJffv2bbBNXYzFxcWqrKyU0Wh0WDwAAACORsEUAAC0KwxPAk6pqKiQJPXo0aPRNuecc45dW0fG0VQspxdIy8vLKZgCAAC3RsEUAACc0bFjx2Q2m10dRpty9krDzuTj46OAgABXhwEAAAC4JQqmAACgSceOHdOjjzyqquoqV4fiEM5aadiZvDy9NG/+PIqmbq7u6dHjx4832qbu6c+6to6Mo6lYTp9Gw9vb22GxAAAAOAMFUwAA0CSz2ayq6irdPuQ6mYx+rg4HZ1BUWaqV+zbJbDZTMHVzdXPrFhQUNNrmyJEjdm0dwdvbW35+fiotLdUPP/yg0NDQem3qYuzVqxfD8QEAgNszuDoAAADgLjreyvUdE9epowgLC5MklZaWKj8/v8E2u3fvliQNGzbMKbHU9eeqOAAAAJyBJ0wBAECzrNy32dUhAJ1Knz59NHz4cO3atUtr1qzR1KlT7fZv375dBQUF8vLy0jXXXOPQWGJiYrRlyxatXbtWCQkJMhj+77kLi8WidevWSZJGjRrl0DgAAACcgYIpAABoltuHjJTJ2MvVYeAMiipLKG53IA8++KCmT5+u1157TVdffbXtCc6SkhI9/fTTkqSJEyfKx8fHdsyGDRs0f/58BQYG6o033miTOGJjY7V48WLl5eUpNTVVf/jDH2z7UlNTlZeXpz59+mj8+PFt0h8AAK7AQqfuxZELnVIwBQAAzWIy9lJfb5OrwwA6lZiYGE2aNElvvfWWJkyYoMsuu0xGo1Fbt25VWVmZIiMjlZiYaHeM2WzWd999p6qqhhdqu+uuu2xfFxcXS5J27dplt33atGm69tprba979OihBQsW6N5779XixYu1adMmBQcH68CBA9q/f7+MRqNSU1PVvXv3Nnz3AAA4Dwuduh9HLnRKwRQAAABox2bNmqXIyEgtX75cWVlZqqmp0YABA3T//fcrPj5eXl5eLTpfdnZ2vW3l5eV22+sKqae75JJLlJGRobS0NG3ZskUff/yxevXqpfHjx2v69OkaMGBAy98cAADtBAuduhdHL3RKwRQAADRLUWWpq0NAM3CdOqYxY8ZozJgxzWobGxur2NjYRvfv27ev1XGcf/75euGFF1p9PAAA7Z3J6MeoKlAwBQAATfPx8ZGXp5dW7tvk6lDQTF6eXnZzWgIAAABoPgqmAACgSQEBAZo3f16HnAA/LS1N06ZNU79+/VwdTpty5AT4AAAAQEdHwRQAAJxRQEBAhy3A9evXT4MGDXJ1GAAAAGgHiipLXB0CmsHR14mCKQAAAAAAACBp5b7Nrg4B7QAFUwAAAAAAAEDS7UNGymTs5eowcAZFlSUOLW5TMAUAAO1KYWGhKisrHd7P4cOH7f51NKPRqMDAQKf0BQAAgNYxGXupr7fJ1WHAxSiYAgCAdqOsrExJSUmyWq1O6zMtLc0p/RgMBqWlpcnX19cp/QEAAABoHQqmAACg3fD19VVKSorDnzC1WCzKy8uT2WyWj4+PBg4cKIPB4NA+jUYjxVIAAADADVAwBQAA7Yqjh61nZmYqPT1dRUVFtm0mk0lxcXGKjo52aN8AAABo34oqS10dAprB0deJgikAAOg0MjMzlZqaqoiICCUkJCgoKEj5+fnKyMhQamqqEhMTKZoCAAB0Qj4+PvLy9NLKfZtcHQqaycvTSz4+Pg45NwVTAADQKVgsFqWnpysiIkJJSUm2IfjBwcFKSkpSSkqK0tPTFRUV5fDh+QAAAGhfAgICNG/+PJnNZleH0qYOHz6stLQ0TZs2Tf369XN1OG3Kx8dHAQEBDjk3BVMAANAp5ObmqqioSAkJCfUKogaDQePGjVNycrJyc3MVFhbmoigBAADgKgEBAQ4rwP1SYWGhw+ftdwWj0ejwKbacgYIpAADoFEpLSyVJQUFBDe6v217XDgAAAHCEsrIyJSUlyWq1Oq3PtLQ0p/RjMBiUlpbm9oudUjAFAACdgp+fnyQpPz9fwcHB9fbn5+fbtQMAAAAcwdfXVykpKR32CVN3L5ZKFEwBAEAnERoaKpPJpIyMDLs5TKVT85uuXr1aJpNJoaGhLowSAAAAnUFHGLbekbGiAQAA6BQMBoPi4uKUlZWllJQU7d+/X8ePH9f+/fuVkpKirKwsxcXFseATAAAA0MnxhCkAAOg0oqOjlZiYqPT0dCUnJ9u2m0wmJSYmKjo62nXBAQAAAGgXKJgCAIBOJTo6WlFRUcrNzVVpaan8/PwUGhrKk6UAAAAAJFEwBQAAnZDBYFBYWJirwwAAAADQDvEoBQAAAAAAAADUomAKAAAAAAAAALUomAIAAAAAAABALQqmAAAAAAAAAFCLgikAAAAAAAAA1KJgCgAAAAAAAAC1KJgCAAAAAAAAQK2urg4AZ3b06FGdPHlS119/vatDAQAAHVRBQYG6dOni6jDQiZHzAgAAR2pJvssTpm6gW7du6tqV2jYAAHCcrl27qlu3bq4OA50YOS8AAHCkluS7Hlar1ergeAAAAAAAAADALfCEKQAAAAAAAADUomAKAAAAAAAAALUomAIAAAAAAABALQqmAAAAAAAAAFCLgikAAAAAAAAA1KJgCgAAAAAAAAC1KJgCAAAAAAAAQC0KpgAAAAAAAABQi4IpAAAAAAAAANSiYAoAAAAAAAAAtSiYAgAAAAAAAEAtCqYAAAAAAAAAUKurqwNAx3fdddfp8OHDttceHh7q0aOHfHx8dP755ys8PFw33XSTLrzwwiaPa45+/fpp06ZNkqQhQ4bU29+tWzcFBATooosuUlxcnKKiolrxjtCWGrrOnp6e8vf317Bhw3TXXXdp5MiR9Y5buHChFi1a1OS5Q0NDlZGRYXs9adIkZWZm2rXp2rWrevbsqaFDh2rcuHEaN26cPDw8zuIdoSlbt27V7373O3Xv3l0ZGRk6//zzG2y3aNEiLVy4UL/61a/03nvvycvLy25/Xl6e3n33XWVmZurQoUMym83q3r27AgMDFRYWpmuuuUajRo1S9+7d7Y5btWqVZs6cWa+/rl27qlevXgoPD9fdd9+ta6+9tl6bQ4cO6frrr6+3va7fqKgoTZ48ucF7D06p+//+/PPPKzY2ttnHFRYW6t1339XWrVv1/fff66effpKnp6dMJpNCQ0N11VVXafTo0fL19bU7btu2bbrnnnvqna9Lly7y9fXV0KFDddttt2ns2LEN/r8//VrOnDlT8fHxjcb49NNPa/ny5ZKkAQMGaMOGDQ2+99M1514HwH2Q86Ip5LydCzlv50W+23HyXQqmcJrIyEjbL4oTJ06opKREe/fuVWZmppYsWaLo6GjNmTNHQUFBkqTRo0erpKTE7hyVlZVav369bb/RaLTb36tXr3r9XnnllTKZTJKkkpIS7d69W+vWrdOHH36omTNnavLkyW3+XtFyp/98mM1m7d27V5s2bdKmTZsUHx/f4C98SQoICNBVV13V4L7zzjuvwe2hoaEaOnSopFM/U/v379cXX3yhL774Qp988olSU1NJIB1kxIgR+u1vf6v09HQ9+eSTSk9Pl8FgP9hhz549euWVV9S1a1e98MILdoljTU2N5s2bpzfeeEMWi0Xe3t4aPny4evfurRMnTujQoUNas2aNPvjgA/Xu3Vtvv/12gwmq0WjU6NGjba8rKip04MABbd68WZs3b9aUKVP0yCOPNPo+Tr//FBUV6euvv9bKlSuVkZGhv/71r7rhhhvO9luFWv/85z+1YMECVVVVqXv37ho+fLhMJpNOnjypH374QRs3btT69es1d+5cvfrqq40WBW677Tbb1ydOnFBeXp62bNmiLVu26NNPP1VKSkqTcaxcubLRBPLnn3/WmjVrmvV+WnuvA+A+yHnRFHLezoGcFy1BvttOWQEHGzlypDUkJMS6cuXKevssFov1008/td5www3WkJAQ6+WXX249ePBgo+fKz8+3hoSEWENCQqz5+flN9lvX7ssvv7TbXllZaU1ISLCGhIRYhw0bZj1y5Ejr3hjaRGM/H9XV1da//OUvtuuYnZ1tt//ll1+2hoSEWCdOnNjsviZOnGgNCQmxvvzyy3bbLRaL9bXXXrP1tW7duta/IZxRRUWFNSYmxhoSEmL9+9//brfv559/tt58883WkJAQa2pqar1jZ8yYYQ0JCbFGRkZaV6xYYa2urq7XpqioyLpw4UJrZGSkNSsry27fypUrrSEhIdaRI0c2GNvrr79uDQkJsQ4ZMsSam5trt6+p+09xcbF1woQJ1pCQEOull15qPX78eHO+FZ1OU78PGvLiiy/a7tV///vfG/y+lpWVWV9//XXrFVdcYV2zZo3dvi+//NJ2zRry0UcfWYcMGWINCQmxbtq0qd7+umNjY2MbvA/VWb16tTUkJMR6++23W0NCQqwxMTH12rT2XgfAfZDzoinkvJ0POW/nRL7bcfJd5jCFS3l4eOiaa67RihUrNHDgQB07dkyzZs1yaJ89evSw9VFdXa1///vfDu0PrdO1a1c9/vjj8vb2liRt3rzZYX15eHjovvvu06BBgxzeF0590v3888/LYDAoNTVV33zzjW3fggULdODAAQ0bNkxTp061O27FihVat26dPD09tXTpUt1xxx3q2rX+QImAgAAlJCRo7dq16tu3b4tii4+PV58+fWS1WvXll182+7hevXrp8ccfl3TqqZ6srKwW9Yv6tmzZon/84x+STv1c3HffffWGm0mSj4+P4uPjtXbtWoWHh7eoj9GjRysiIkLSqaFzjbn99tslnfrUvSH/+te/7Nq1hDPvdQBch5wXjSHn7bjIeXEm5LvtGwVTtAu+vr566qmnJElffvmldu/e7dD+AgMD5efnJ0n68ccfHdoXWq9bt262R/kdfZ08PDwUEhLilL4gRUVFKT4+XlVVVXriiSdUU1OjnTt36vXXX5enp6fmzp0rT09PW3ur1apXXnlFkhQXF6fhw4efsY8+ffro3HPPbXFsvXv3liSdPHmyRcedPv8PP0Nnr+56jxo1SjExMWds37Nnz0bnB2tK3fDVpq731VdfLZPJpHXr1unnn3+225efn69t27YpIiJCgwcPbnH/knPvdQBci5wXDSHn7bjIedEU8t32jYIp2o2rr77altBt2bLFoX1ZLBZVVlZK+r9fFGifKioqJDnnOpWXlzutL0gzZszQBRdcoN27dys1NVUzZ86UxWLRww8/bEvk6+zbt882gfitt97qsJjMZrO+++47SdKvfvWrFh1b9/Mj8TN0tn766Sdt375dkmOvd3V1tXJyciQ1fb27du2qW2+9VWVlZbY5BeusWrVKVqu1VZ+2n86Z9zoArkXOi4aQ83Zc5LxoCPlu+0fBFO2Gh4eHwsLCJEkHDhxwaF9bt25VVVWVPD09G508Ha73v//9T/n5+ZJOrbjnSMXFxfr666+d0hdO6datm+bOnasuXbrotddeU15eniIiInTvvffWa1v3BI6np6dDVuSsqKhQdna2pk+frsrKSkVERLT43vDZZ59Jkvz9/W3DXtA6OTk5slgsktSsJyta6ueff9a+ffv06KOPKj8/X0FBQWdMVBsapmSxWPT+++/LaDTqpptuanU8zrzXAXA9cl78Ejlvx0bOi4aQ77Z/9SfCAFyobsXP0tJSh5y/uLhYmZmZeu6552QwGPTnP/9ZgYGBDukLrWc2m5Wdna3nnntOJ0+e1NSpUxv9JZKZmdloMvHJJ5+of//+TfZVWVmp3NxcvfDCCzKbzRo/fjyrPTrRhRdeqMsvv9w2r9rTTz+tLl261GtXt3qwn59fg/urqqr05z//ud72Sy65RHfeeWe97YcPH27w58bLy0vTpk3TlClTmr1qbFFRkT799FO9+OKL6tatm55//vkG5x5C852+WrS/v3+DbZ555hnbp9R1Bg8erClTpjTYvqHrbTAYFBcXp4SEhHorUP/S4MGDFRkZqW3btunQoUPq37+//vOf/+iHH35QbGysbU6mlmjJvQ5Ax0LOC4mctzMh58Uvke+2fxRM0a7UfcLS3Jt2c9xzzz31tnXv3l1LlizRiBEj2qwfnJ2ZM2dq5syZdtu6dOmil156SePGjWv0uICAgEY/FW3sF8KiRYu0aNGietsfeeSRRn/5wDG2bt2qL774wvZ67dq1rfo0vbq6Wu+9916D+xpKHo1Go0aPHm13fEFBgf773/9q6dKl6tatmx588MFG+7v++uvrbevVq5fS09Md8jQA6luzZk29QkN0dHSj/4dvu+0229c1NTUqLCxUdna23n33XRkMBj3xxBN2c4g15Pbbb9fOnTu1atUqPfzww7ZP31syPKm19zoAHQs5b+dFzts5kfOiNch3XYuCKdqVuk9Zevbs2WbnvPLKK2UymWSxWHTs2DF99dVXOnHihB577DG9/fbbCgoKarO+0HqRkZG2SaCLi4u1fft2VVRUKDk5WQMHDtSFF17Y4HGDBw/W3LlzW9RXaGiohg4dKunUkx3Z2dkqLi7Wyy+/rAsuuKDBxABtr7y8XE899ZSsVqsmTpyod955R//4xz8UExNT73rXPYnz008/6eTJk/U+cT/nnHO0b98+2+u0tDSlpqY22nevXr0a/LnJy8vTpEmT9Ne//lVeXl76/e9/3+Dxo0ePltFo1MmTJ3XkyBHt2LFDJSUlmjFjht5++23b3HRonbrrLZ26H/Tp06dem23bttm+zsjIsK3Y2piGrvfRo0d133336a233pLVatWf/vSnJs9x00036bnnntP777+viRMn6pNPPtHAgQMVFRV1prdk09p7HYCOhZy38yLn7XzIedEQ8t32j4Ip2g2r1aq9e/dKUr3Jr8/GlClTdOmll9peFxYW6r777tP+/fv1yCOP6J133mnTT/fROnfeeadiY2Ntr81ms6ZPn65t27ZpxowZWrt2rXr06NEmfcXExOihhx6yva6qqtLMmTO1Zs0aPfHEE1q3bl2rVppEy8yZM0c//PCDRowYoVmzZqlXr15auHChZs6cqffee09eXl62tsOGDZN06lrt37/flvy3tYEDB2rKlCl69tln9dprrzWaPD7++ON2Q9/+97//KT4+Xt9++61mz57dZOKKMxs6dKgMBoMsFot2797dYALZFs4991zNmDFDU6dO1dtvv60ZM2bIx8en0fbnnHOObrzxRq1atUpPPfWUqqqq7O5bzeHMex2A9omct3Mj5+18yHnREPLd9p/vsugT2o3PPvtMP/30k6RTn5A7SmBgoBYsWCBPT09lZ2dr9erVDusLrefj46MFCxbIz89Phw8f1uuvv+6wvry8vDRnzhwNHDhQZrOZX/xO8Omnn2rlypXy9vbWnDlz5OHhoQceeEBhYWH65ptv9PLLL9u1Dw0NVb9+/STJ4f9n657AKSkpUXFxcbOOueCCC/Tiiy9Kkj766CPbipdoHT8/P0VGRkpy3vU+efKk8vLyzti+bjjS5s2b1aVLF40fP/6s+nfmvQ5A+0DOi9OR83Zs5LxoDPlu+0fBFO2C2WzW888/L0m64oorHPZJWp0LLrhAd999t6RTc/vU1NQ4tD+0jr+/v6ZOnSpJWrJkicrKyhzWV7du3fToo49Kkt577z19//33DuursystLdWsWbMkSU8++aT69u0r6dRqoM8//7w8PT21ZMkSZWdn246pSy4ladmyZcrJyXFYfAcPHpR0aoL0lkxkP2LECNuKj/wBcvbq/u9//PHH+vTTTx3WT931lhqfA+50UVFRCg8Pl5+fn0aNGtUmi6g4814HwLXIedEQct6OiZwXZ0K+275RMIVLWa1WffbZZ7rjjjuUl5cnk8mkZ555xil9T5s2TUajUQcPHmx04my43m9/+1v17dtXZrNZS5YscWhfo0aN0kUXXaSTJ082OEE+2sYzzzyjoqIiXX311fUmpw8NDdXUqVN18uRJPfnkk/r5559t++666y6NHj1aVVVVuueee7Rq1aoG//ArLy+3m9upJfLy8vT3v/9dknT55Zc3K6E4XVJSkgwGgzIzM7V169ZWxYBTrrzySv3+97+X1WrVQw89pNdff10nTpyo166qqkq7d+9uVR9Hjx61JfqDBg3SBRdc0KzjVq5cqW3btrXpHwnOvNcBcD5yXpwJOW/HQ86LMyHfbd+YwxROs2LFCmVmZko69R++pKREOTk5tlXfoqOjNWfOHNsQBEfz9/fX7373O/3tb3/TK6+8ovHjx59xxTg4n5eXlxISEvTUU0/pzTffVHx8vEMnF09KStLkyZO1du1aTZ06VYMHD3ZYX53R+vXrtWbNGvn6+urZZ59tsM0DDzygTz75RHv27FFqaqptcnMPDw/Nnz9fgYGBWrZsmWbOnKk5c+Zo+PDh8vf3l8Vi0ZEjR7R7925VVVWpd+/euvbaaxvso6SkRE8++aTt9ekrhp48eVJ9+/ZVcnJyi99fcHCwxo0bp/fff18vv/wyqxI3Ii0tTf/v//2/RvfPnj1bw4YN0xNPPKFevXrp5Zdf1ty5c5Wamqrhw4fLZDLJw8NDR48e1e7du1VZWWmbb6kxp1/vmpoaHT16VP/973/1888/q2fPnrbhZa7i7HsdAMch50VrkPN2LOS8IN+tz93yXQqmcJqdO3dq586dkk49Bu7t7a2QkBCFh4frpptucslKab///e/19ttv6/Dhw1q5cqVtyBLal/Hjx2vJkiX65ptv9M9//lOPPPKIw/q67LLLdOWVV+qLL77QokWLlJKS4rC+Opsff/xRs2fPliT98Y9/bHRoR9euXTV37lzFxsbq9ddf1w033KCLL75Y0qkhTH/84x/1m9/8RitWrNC2bduUk5Oj8vJydevWTeeee65GjRqla6+9VqNGjWp0MvHKykq7p2w8PDzk7e2tYcOG6brrrtOkSZPk7e3dqvf58MMPa926ddq5c6f+/e9/66qrrmrVeTqy/Px85efnN7q/vLzc9vWUKVM0btw4vfvuu9q6dau++eYb7dy5U15eXurdu7euuOIKXXXVVbrxxhubXG36l9e7R48eGjx4sK688kpNnjxZJpOpbd7cWXDmvQ6A45DzorXIeTsGcl5I5LuNcad818NqtVpdHQQAAAAAAAAAtAfMYQoAAAAAAAAAtSiYAgAAAAAAAEAtCqYAAAAAAAAAUIuCKQAAAAAAAADUomAKAAAAAAAAALUomAIAAAAAAABALQqmAAAAAAAAAFCLgikAAAAAAAAA1KJgCgAAAAAAAAC1KJgCALRw4UINGTJEQ4YMcVgf1113nYYMGaInn3zSYX0AAAAAjSHnBdBcXV0dAAC4s23btumee+6xvTYajdqyZYt69OjR5HEnTpzQFVdcofLyctu2N998U5deeqnDYgUAAABag5wXQGfDE6YA0IYqKyu1cePGM7b75JNP7BJHAAAAwF2Q8wLo6CiYAkAb6datmyQpIyPjjG3r2tQdAwAAALgDcl4AnQEFUwBoI9ddd50kacuWLSoqKmq03Y8//qj//Oc/kqTrr7/eKbEBAAAAbYGcF0BnQMEUANrIFVdcIZPJpJMnT2rt2rWNtluzZo1qampkMpl0+eWXOzFCAAAA4OyQ8wLoDFj0CQDaSJcuXXTzzTdr6dKlysjIUHx8fIPt6oYm3XLLLerSpcsZz1tVVaUVK1boo48+0oEDB1ReXq6ePXsqLCxMt9xyi8aOHSuDoenPv44cOaJXX31Vn3/+uY4ePaqePXsqPDxc99xzT4sSWLPZrOXLl2vz5s3Ky8tTeXm5/Pz8FB4ervHjx2v06NHy8PBo9vkAAADgXsh5yXmBzoCCKQC0oVtvvVVLly5VTk6ODhw4oODgYLv933zzjfbs2WNru3fv3ibPd+jQId1///369ttv7bYfO3ZMn3/+uT7//HO98847SktLk5+fX4Pn2L59ux544AG7CfeLioq0efNmbd68WQ899FCz3tvWrVs1Y8YMlZaW2m0//VzXXHON/vrXv+qcc85p1jkBAADgfsh5yXmBjo4h+QDQhsLCwmwJY0MT4ddtCwkJ0dChQ5s8V0VFheLj422JY0xMjF555RWtXLlSqampio6OliTt2LFDDz74oE6ePFnvHD/88IMtcTQYDLr77ru1dOlS/etf/9Jzzz2ngQMHauHChfr000+bjGXHjh26//77VVpaqoCAAM2YMUOLFy/WqlWrtHjxYo0bN06S9Nlnn+nJJ59s+psEAAAAt0bOS84LdHQUTAGgjd16662STs3bZLVabdutVqs++OADuzZNWbRokfLz8yVJU6dO1d/+9jddd911Cg8P14033qg333xTY8eOlSRlZWXpnXfeqXeOuXPn2j5lf+mll/T0009rxIgRGj58uO644w6tXLlSoaGh2r17d6NxVFdX67HHHlN1dbWuuuoqbdy4UVOnTtXIkSM1bNgwjRw5Ui+99JKeeeYZSdLHH39sm+AfAAAAHRM5Lzkv0JFRMAWANjZu3DgZDAYVFBRo27Zttu3btm1TQUGBDAaDLelrTFVVlf71r39JkoKDgxscQuTh4aHk5GTbsKT09HS7/UVFRdq4caMkaeTIkbrlllvqncPb29uW9DVm7dq1Onz4sLp166YXX3xRPXr0aLDdXXfdpQsvvFCStGrVqibPCQAAAPdGzkvOC3RkFEwBoI0FBgbq0ksvlWQ/RKnu68suu0yBgYFNnmP37t0qKyuTJN12222NTpTv7e2tm266SdKpuaKOHj1q27dt2zbbkKXY2NhG+7rwwgvrzTt1uk2bNkmSfv3rX8vf37/JuKOioiRJ//3vf5tsBwAAAPdGzkvOC3RkLPoEAA4wfvx4bd26VR9//LFmz54tSVq/fr2k5g1NOnDggO3riy66qMm2F110kd5++23bceeee64kaf/+/bY2w4cPb/Icw4cPt+vzdHVDl7744gsNGTLkjLFLpyboBwAAQMdGzkvOC3RUPGEKAA4watQo9ejRQ+Xl5frkk0+0ceNGVVRUyGg06oYbbjjj8T/99JPt6zN9wh0QENDgcaev7Nm7d+9mn+OXiouLmzy2ISdOnGjxMQAAAHAv5LzkvEBHxROmAOAA55xzjmJiYvTBBx8oIyPDNhF+TEyMjEZji87l4eHhiBCbrW6I09VXX63HHnvMpbEAAACg/SDnBdBRUTAFAAcZP368PvjgA7vVM8ePH9+sY3v27Gn7+scff9SgQYMabXv6UKDTj/vlOc4777xmneOX/Pz8dPToUVVXVyskJOSMsQMAAKDzIOcF0BExJB8AHGTEiBEymUyqqalRTU2Nzj33XI0YMaJZx54+IX12dnaTbb/++usGjzs90du1a1eT56ibs6khYWFhtjZVVVVNngcAAACdCzkvgI6IgikAOEiXLl106623ysvLS15eXrr11ltlMDTvthseHi5fX19J0vvvvy+LxdJgu/Lycn344YeSpF/96le2ye8l6dJLL7WtNPree+812tfXX39tN1n+L1133XWSJLPZrFWrVjUrfgAAAHQO5LwAOiIKpgDgQI899ph27dqlXbt26dFHH232cV5eXrrjjjsknVr5My0trV4bq9WqZ555RiUlJZKkuLg4u/3nnnuurr/+eknSpk2btG7dunrnqKiosK1o2pjbbrvNNrTphRde0FdffdVk++3btyszM7PJNgAAAOg4yHkBdDTMYQoA7dT06dO1YcMG5efna+HChdq/f79iY2NlMpl06NAhLVu2zJakRUREaMKECfXO8cQTT+g///mPKioq9Oijj+qrr77S6NGj5e3trX379um1115TXl6ewsPDGx2i5OXlpQULFmjSpEmqrKzU5MmTNWbMGMXExKh///6yWCwqKirSnj17tGHDBu3fv19/+tOfFB0d7dDvDwAAANwfOS+A9oiCKQC0U97e3lq6dKnuv/9+ffvtt1q/fr3Wr19fr11kZKReeeUV21Ck0/Xv31+vvPKKpk6dqoqKCi1fvlzLly+3azN9+nR5eHg0OafTxRdfrLfeekszZsxQQUGBPvjgA33wwQdNxg4AAACcCTkvgPaIgikAtGP9+/dXRkaGVqxYoY8++kj79+9XRUWFevbsqaFDh2rs2LEaO3Zsk/NEXXrppVq7dq1effVVff755zp69Kh69uyp8PBwTZw4UVdddZUWLlx4xlguvvhiffzxx1q1apU2b96snJwclZSUyGAwyN/fXxdccIF+/etf64YbbtDgwYPb8tsAAACADoycF0B742G1Wq2uDgIAAAAAAAAA2gMWfQIAAAAAAACAWhRMAQAAAAAAAKAWBVMAAAAAAAAAqEXBFAAAAAAAAABqUTAFAAAAAAAAgFoUTAEAAAAAAACgFgVTAAAAAAAAAKhFwRQAAAAAAAAAalEwBQAAAAAAAIBaFEwBAAAAAAAAoBYFUwAAAAAAAACoRcEUAAAAAAAAAGpRMAUAAAAAAACAWhRMAQAAAAAAAKDW/wcvhWL+AEkQ4wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Importance"
      ],
      "metadata": {
        "id": "B55bumqwChWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature importances\n",
        "feature_importances = lgbm_model.feature_importances_\n",
        "\n",
        "# Get feature names\n",
        "feature_names = X_train.columns\n",
        "\n",
        "# Create a DataFrame to store feature names and their importances\n",
        "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
        "\n",
        "# Sort the DataFrame by importance in ascending order (reversed)\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=True)\n",
        "\n",
        "# Plot feature importances\n",
        "plt.figure(figsize=(16, 8))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette=\"viridis\")\n",
        "\n",
        "plt.xlabel('Importance', fontsize=16)\n",
        "plt.ylabel('Feature', fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "id": "7pIlVKbZwQec",
        "outputId": "1139c974-485f-4aa9-9fdb-ea778222ff8c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-111b236231f9>:15: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette=\"viridis\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A1QJmC5YNDaK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LGBMR with different weather parameter**"
      ],
      "metadata": {
        "id": "KaqK2MI6C9ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "QKIjjY-WV-G8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "# Initialize the LGBM Regressor model (you can adjust hyperparameters)\n",
        "lgbm_model = lgb.LGBMRegressor(n_estimators=100, random_state=0)\n",
        "\n",
        "# Fit the model to the training data\n",
        "lgbm_model.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importance scores\n",
        "feature_importance = lgbm_model.feature_importances_\n",
        "\n",
        "# Get feature names from the original DataFrame (assuming you have it)\n",
        "feature_names = X_train.columns\n",
        "\n",
        "# Create a DataFrame to store feature importance scores\n",
        "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
        "\n",
        "# Sort features by importance in descending order\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# List to store selected features incrementally\n",
        "selected_features = []\n",
        "\n",
        "# Lists to store evaluation metric results\n",
        "rmse_scores = []\n",
        "r2_scores = []\n",
        "mae_scores = []\n",
        "mse_scores = []   # Add MSE scores\n",
        "\n",
        "# Train the model incrementally with the top important features\n",
        "for _, row in feature_importance_df.iterrows():\n",
        "    selected_features.append(row['Feature'])\n",
        "    X_train_selected = X_train[selected_features]\n",
        "\n",
        "    # Fit the model on selected features\n",
        "    lgbm_model.fit(X_train_selected, y_train)\n",
        "\n",
        "    # Make predictions on the testing data\n",
        "    y_pred = lgbm_model.predict(X_test[selected_features])\n",
        "\n",
        "    # Calculate RMSE, R-squared (R2), MAE, and MAPE\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "    # Calculate MAPE\n",
        "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "    # Calculate MSE\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    # Append results to the respective lists\n",
        "    rmse_scores.append(rmse)\n",
        "    r2_scores.append(r2)\n",
        "    mae_scores.append(mae)\n",
        "    mse_scores.append(mse)    # Append MSE scores\n",
        "\n",
        "# Print results for each incremental feature set\n",
        "for i, (feature, rmse, r2, mae,  mse) in enumerate(zip(selected_features, rmse_scores, r2_scores, mae_scores,  mse_scores), start=1):\n",
        "    print(f\"Features selected: {i}\")\n",
        "    print(f\"Selected Feature: {feature}\")\n",
        "    print(f\"RMSE: {rmse}\")\n",
        "    print(f\"R-squared (R2): {r2}\")\n",
        "    print(f\"MAE: {mae}\")\n",
        "    print(f\"MAPE: {mape:.2f}%\")  # Display MAPE as a percentage\n",
        "    print(f\"MSE: {mse}\")\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W3mcuVpPVOH",
        "outputId": "da03ea1b-bb14-4005-cda8-e8a5da0b577e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001507 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 6500, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.244554\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 255\n",
            "[LightGBM] [Info] Number of data points in the train set: 6500, number of used features: 1\n",
            "[LightGBM] [Info] Start training from score 7.244554\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000161 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 499\n",
            "[LightGBM] [Info] Number of data points in the train set: 6500, number of used features: 2\n",
            "[LightGBM] [Info] Start training from score 7.244554\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000362 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 754\n",
            "[LightGBM] [Info] Number of data points in the train set: 6500, number of used features: 3\n",
            "[LightGBM] [Info] Start training from score 7.244554\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000291 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1009\n",
            "[LightGBM] [Info] Number of data points in the train set: 6500, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 7.244554\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000368 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1250\n",
            "[LightGBM] [Info] Number of data points in the train set: 6500, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 7.244554\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000422 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1505\n",
            "[LightGBM] [Info] Number of data points in the train set: 6500, number of used features: 6\n",
            "[LightGBM] [Info] Start training from score 7.244554\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000493 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1760\n",
            "[LightGBM] [Info] Number of data points in the train set: 6500, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score 7.244554\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000509 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1925\n",
            "[LightGBM] [Info] Number of data points in the train set: 6500, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 7.244554\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2177\n",
            "[LightGBM] [Info] Number of data points in the train set: 6500, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 7.244554\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000707 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2432\n",
            "[LightGBM] [Info] Number of data points in the train set: 6500, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 7.244554\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001240 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2686\n",
            "[LightGBM] [Info] Number of data points in the train set: 6500, number of used features: 11\n",
            "[LightGBM] [Info] Start training from score 7.244554\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001371 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2941\n",
            "[LightGBM] [Info] Number of data points in the train set: 6500, number of used features: 12\n",
            "[LightGBM] [Info] Start training from score 7.244554\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000918 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 6500, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.244554\n",
            "Features selected: 1\n",
            "Selected Feature: u(x)\n",
            "RMSE: 2.5551507554668325\n",
            "R-squared (R2): 0.21036298833064582\n",
            "MAE: 2.2275835194921365\n",
            "MAPE: 1.66%\n",
            "MSE: 6.528795383162725\n",
            "\n",
            "\n",
            "Features selected: 2\n",
            "Selected Feature: Tx\n",
            "RMSE: 0.5781042863512097\n",
            "R-squared (R2): 0.9595790219766657\n",
            "MAE: 0.43560629254830163\n",
            "MAPE: 1.66%\n",
            "MSE: 0.33420456589764147\n",
            "\n",
            "\n",
            "Features selected: 3\n",
            "Selected Feature: RH\n",
            "RMSE: 0.3872330764544344\n",
            "R-squared (R2): 0.9818640908477366\n",
            "MAE: 0.29960895949003064\n",
            "MAPE: 1.66%\n",
            "MSE: 0.14994945550036584\n",
            "\n",
            "\n",
            "Features selected: 4\n",
            "Selected Feature: Rs\n",
            "RMSE: 0.18793246780651926\n",
            "R-squared (R2): 0.9957283262900432\n",
            "MAE: 0.13515582883020597\n",
            "MAPE: 1.66%\n",
            "MSE: 0.03531861245584839\n",
            "\n",
            "\n",
            "Features selected: 5\n",
            "Selected Feature: Ra\n",
            "RMSE: 0.13152958522514316\n",
            "R-squared (R2): 0.9979076162442961\n",
            "MAE: 0.09374953236606023\n",
            "MAPE: 1.66%\n",
            "MSE: 0.0173000317894982\n",
            "\n",
            "\n",
            "Features selected: 6\n",
            "Selected Feature: e(a)\n",
            "RMSE: 0.1345535665394979\n",
            "R-squared (R2): 0.9978102987500804\n",
            "MAE: 0.09521727591427066\n",
            "MAPE: 1.66%\n",
            "MSE: 0.01810466226849909\n",
            "\n",
            "\n",
            "Features selected: 7\n",
            "Selected Feature: e(s)\n",
            "RMSE: 0.13314997815657392\n",
            "R-squared (R2): 0.9978557439821321\n",
            "MAE: 0.09459072455309192\n",
            "MAPE: 1.66%\n",
            "MSE: 0.017728916683096115\n",
            "\n",
            "\n",
            "Features selected: 8\n",
            "Selected Feature: N\n",
            "RMSE: 0.12848662876472994\n",
            "R-squared (R2): 0.9980033115440845\n",
            "MAE: 0.0892127736907715\n",
            "MAPE: 1.66%\n",
            "MSE: 0.016508813771325525\n",
            "\n",
            "\n",
            "Features selected: 9\n",
            "Selected Feature: Tn\n",
            "RMSE: 0.13019471907921812\n",
            "R-squared (R2): 0.9979498710599656\n",
            "MAE: 0.08997361422350103\n",
            "MAPE: 1.66%\n",
            "MSE: 0.01695066487611652\n",
            "\n",
            "\n",
            "Features selected: 10\n",
            "Selected Feature: Rnl\n",
            "RMSE: 0.12691474080945078\n",
            "R-squared (R2): 0.9980518671353019\n",
            "MAE: 0.08901288561159557\n",
            "MAPE: 1.66%\n",
            "MSE: 0.01610735143473007\n",
            "\n",
            "\n",
            "Features selected: 11\n",
            "Selected Feature: n\n",
            "RMSE: 0.12785816208625422\n",
            "R-squared (R2): 0.998022796579135\n",
            "MAE: 0.08912005987502285\n",
            "MAPE: 1.66%\n",
            "MSE: 0.016347709612074858\n",
            "\n",
            "\n",
            "Features selected: 12\n",
            "Selected Feature: Rn\n",
            "RMSE: 0.1349632777275998\n",
            "R-squared (R2): 0.997796943310868\n",
            "MAE: 0.09570006145710151\n",
            "MAPE: 1.66%\n",
            "MSE: 0.018215086334977235\n",
            "\n",
            "\n",
            "Features selected: 13\n",
            "Selected Feature: u2\n",
            "RMSE: 0.1349632777275998\n",
            "R-squared (R2): 0.997796943310868\n",
            "MAE: 0.09570006145710151\n",
            "MAPE: 1.66%\n",
            "MSE: 0.018215086334977235\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "g3fJ4lpEC7FO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Increase the font size for better readability\n",
        "plt.rcParams.update({'font.size': 18})\n",
        "\n",
        "# Create a 2x2 grid of subplots\n",
        "fig, axs = plt.subplots(2, 2, figsize=(13, 10))\n",
        "\n",
        "# Plot RMSE for each incremental feature set\n",
        "axs[0, 0].plot(selected_features, rmse_scores, marker='o', linestyle='-', color='b')\n",
        "axs[0, 0].set_title('RMSE for Incremental Feature Sets', fontsize=16)  # Increase title font size\n",
        "axs[0, 0].set_xlabel('Features', fontsize=14)  # Increase x-axis label font size\n",
        "axs[0, 0].set_ylabel('RMSE', fontsize=14)  # Increase y-axis label font size\n",
        "axs[0, 0].tick_params(axis='x', rotation=90, labelsize=12)  # Increase tick label font size\n",
        "axs[0, 0].tick_params(axis='y', rotation=90, labelsize=12)  # Increase tick label font size\n",
        "axs[0, 0].grid(True)\n",
        "\n",
        "# Plot R-squared (RÂ²) for each incremental feature set with superscript\n",
        "axs[0, 1].plot(selected_features, r2_scores, marker='o', linestyle='-', color='g')\n",
        "axs[0, 1].set_title('$R^2$ for Incremental Feature Sets', fontsize=16)\n",
        "axs[0, 1].set_xlabel('Features', fontsize=14)\n",
        "axs[0, 1].set_ylabel('$R^2$', fontsize=14)\n",
        "axs[0, 1].tick_params(axis='x', rotation=90, labelsize=12)\n",
        "axs[0, 1].tick_params(axis='y', rotation=90, labelsize=12)\n",
        "axs[0, 1].grid(True)\n",
        "\n",
        "# Plot MAE for each incremental feature set\n",
        "axs[1, 0].plot(selected_features, mae_scores, marker='o', linestyle='-', color='r')\n",
        "axs[1, 0].set_title('MAE for Incremental Feature Sets', fontsize=16)\n",
        "axs[1, 0].set_xlabel('Features', fontsize=14)\n",
        "axs[1, 0].set_ylabel('MAE mm day$^{-1}$', fontsize=14)\n",
        "axs[1, 0].tick_params(axis='x', rotation=90, labelsize=12)\n",
        "axs[1, 0].tick_params(axis='y', rotation=90, labelsize=12)\n",
        "axs[1, 0].grid(True)\n",
        "\n",
        "# Plot MAPE for each incremental feature set\n",
        "axs[1, 1].plot(selected_features, mse_scores, marker='o', linestyle='-', color='purple')\n",
        "axs[1, 1].set_title('MSE for Incremental Feature Sets', fontsize=16)\n",
        "axs[1, 1].set_xlabel('Features', fontsize=14)\n",
        "axs[1, 1].set_ylabel('MSE', fontsize=14)\n",
        "axs[1, 1].tick_params(axis='x', rotation=90, labelsize=12)\n",
        "axs[1, 1].tick_params(axis='y', rotation=90, labelsize=12)\n",
        "axs[1, 1].grid(True)\n",
        "\n",
        "# Adjust the layout to avoid overlapping titles\n",
        "plt.tight_layout()\n",
        "plt.savefig('correlation_plot_500dpi.png', dpi=500)\n",
        "\n",
        "# Download the saved figure from Colab\n",
        "files.download('correlation_plot_500dpi.png')\n",
        "# Show the plots\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 982
        },
        "id": "qt8pIK21QC6m",
        "outputId": "4cedf633-607c-4bed-d57d-199641e160c2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2ffddf4c-2dbe-49b4-a117-03308290ad76\", \"correlation_plot_500dpi.png\", 639399)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1300x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PCA analysis**"
      ],
      "metadata": {
        "id": "CPkAfXBPDZPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming you have a DataFrame 'X' with all your features\n",
        "# First, you should standardize the data (mean=0, std=1)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Initialize PCA with the number of components you want\n",
        "pca = PCA(n_components=len(X.columns))  # You can reduce this number based on your needs\n",
        "\n",
        "# Fit and transform the data\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Explained variance ratio\n",
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "\n",
        "# Cumulative explained variance\n",
        "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
        "\n",
        "# Increase font size of labels and ticks\n",
        "plt.rcParams.update({'font.size': 8})\n",
        "\n",
        "# Plot Explained Variance Ratio\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, alpha=0.5, align='center')\n",
        "plt.xlabel('Principal Components',fontsize=14)\n",
        "plt.ylabel('Explained Variance Ratio',fontsize=14)\n",
        "\n",
        "\n",
        "# Save the figure to your hard disk\n",
        "plt.savefig('explained_variance_ratio.png', bbox_inches='tight', dpi=300)\n",
        "\n",
        "# Plot Cumulative Explained Variance\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.step(range(1, len(explained_variance_ratio) + 1), cumulative_variance, where='mid')\n",
        "plt.xlabel('Principal Components',fontsize=14)\n",
        "plt.ylabel('Cumulative Explained Variance',fontsize=14)\n",
        "\n",
        "\n",
        "# Save the figure to your hard disk\n",
        "plt.savefig('cumulative_explained_variance.png', bbox_inches='tight', dpi=300)\n",
        "\n",
        "# Show the plots\n",
        "plt.show()\n",
        "\n",
        "# Optionally, you can also download the figures using Python code:\n",
        "from google.colab import files\n",
        "\n",
        "# Download the Explained Variance Ratio plot\n",
        "files.download('explained_variance_ratio.png')\n",
        "\n",
        "# Download the Cumulative Explained Variance plot\n",
        "files.download('cumulative_explained_variance.png')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "id": "2wByL2ZXW4u3",
        "outputId": "7f25231e-4c95-4bd4-897c-bc9b98a1bbcc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_36e8813a-1efc-41a8-b4b1-8791eb84152d\", \"explained_variance_ratio.png\", 76880)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d5b814e0-4f61-4129-b2c6-a9855fbad528\", \"cumulative_explained_variance.png\", 78223)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a PCA instance\n",
        "pca = PCA()\n",
        "\n",
        "# Fit the PCA model to your training data\n",
        "pca.fit(X_train)\n",
        "\n",
        "# Calculate the cumulative explained variance ratio\n",
        "cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
        "n_components_95 = np.argmax(cumulative_variance_ratio >= 1) + 1  # Add 1 because indexing starts from 0\n",
        "\n",
        "# Print the number of components required for 95% variance\n",
        "print(f'Number of components required for 100% variance: {n_components_95}')\n",
        "\n",
        "# Transform your data using the selected number of components\n",
        "X_train_pca_95 = pca.transform(X_train)[:, :n_components_95]\n",
        "X_test_pca_95 = pca.transform(X_test)[:, :n_components_95]\n",
        "\n",
        "# Determine the number of components needed for 95% variance\n",
        "n_components_95 = np.argmax(cumulative_variance_ratio >= 0.99) + 1  # Add 1 because indexing starts from 0\n",
        "\n",
        "# Print the number of components required for 95% variance\n",
        "print(f'Number of components required for 99% variance: {n_components_95}')\n",
        "\n",
        "# Transform your data using the selected number of components\n",
        "X_train_pca_95 = pca.transform(X_train)[:, :n_components_95]\n",
        "X_test_pca_95 = pca.transform(X_test)[:, :n_components_95]\n",
        "\n",
        "n_components_95 = np.argmax(cumulative_variance_ratio >= 0.95) + 1  # Add 1 because indexing starts from 0\n",
        "\n",
        "# Print the number of components required for 95% variance\n",
        "print(f'Number of components required for 95% variance: {n_components_95}')\n",
        "\n",
        "# Transform your data using the selected number of components\n",
        "X_train_pca_95 = pca.transform(X_train)[:, :n_components_95]\n",
        "X_test_pca_95 = pca.transform(X_test)[:, :n_components_95]\n",
        "\n",
        "n_components_95 = np.argmax(cumulative_variance_ratio >= 0.90) + 1  # Add 1 because indexing starts from 0\n",
        "\n",
        "# Print the number of components required for 95% variance\n",
        "print(f'Number of components required for 90% variance: {n_components_95}')\n",
        "\n",
        "# Transform your data using the selected number of components\n",
        "X_train_pca_95 = pca.transform(X_train)[:, :n_components_95]\n",
        "X_test_pca_95 = pca.transform(X_test)[:, :n_components_95]\n",
        "\n",
        "n_components_95 = np.argmax(cumulative_variance_ratio >= 0.80) + 1  # Add 1 because indexing starts from 0\n",
        "\n",
        "# Print the number of components required for 95% variance\n",
        "print(f'Number of components required for 85% variance: {n_components_95}')\n",
        "\n",
        "# Transform your data using the selected number of components\n",
        "X_train_pca_95 = pca.transform(X_train)[:, :n_components_95]\n",
        "X_test_pca_95 = pca.transform(X_test)[:, :n_components_95]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf4xDpRAegdG",
        "outputId": "0a3506af-8b4f-444d-a011-fd62519ef635"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of components required for 100% variance: 12\n",
            "Number of components required for 99% variance: 4\n",
            "Number of components required for 95% variance: 3\n",
            "Number of components required for 90% variance: 2\n",
            "Number of components required for 85% variance: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn import preprocessing\n",
        "import numpy\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you uploaded a CSV file named 'my_dataset.csv'\n",
        "file_name = 'ET_Riaz_5.csv'\n",
        "\n",
        "# Read the uploaded CSV file into a DataFrame\n",
        "df = pd.read_csv(file_name)\n",
        "\n",
        "# Now, you can work with the DataFrame 'df' as you would with any other pandas DataFrame.\n",
        "\n",
        "sns.set_theme(style=\"white\", font_scale=1.5)\n",
        "# Load the example planets dataset\n",
        "df1=df.drop(['Day','Month','Year'],axis=1)\n",
        "column_order = ['Tx', 'Tn', 'RH', 'u(x)', 'Rs', 'e(a)', 'e(s)', 'u2', 'Ra', 'n', 'N', 'Rnl', 'Rn', 'ETo']\n",
        "df1 = df1[column_order]\n",
        "df1\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.inspection import permutation_importance\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "df3=df1.drop(['Tx', 'Tn', 'RH', 'u(x)', 'Rs', 'e(a)', 'e(s)', 'u2', 'Ra', 'n', 'N', 'Rnl', 'Rn'],axis=1)\n",
        "y=df3\n",
        "y\n",
        "X=df1.drop(['ETo'],axis=1)\n",
        "X=df1.drop(['ETo'],axis=1)\n",
        "# Assuming X is your feature matrix with columns 'u(x)', 'Tx', 'RH', 'Rs', 'RA'\n",
        "selected_features = ['u(x)', 'Tx', 'RH', 'Rs', 'Ra']\n",
        "X_reduced = X[selected_features]\n",
        "\n",
        "# Split the reduced data into training and testing sets\n",
        "X_train_reduced, X_test_reduced, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Convert the y_train and y_test DataFrames to 1D arrays\n",
        "y_train = y_train.values.ravel()\n",
        "y_test = y_test.values.ravel()\n",
        "\n",
        "# Create models with default hyperparameters\n",
        "random_forest_model_reduced = RandomForestRegressor()\n",
        "xgb_model_reduced = XGBRegressor()\n",
        "lgbm_model_reduced = LGBMRegressor()\n",
        "decision_tree_model_reduced = DecisionTreeRegressor()\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "num_folds = 10\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=0)\n",
        "\n",
        "# Create a dictionary to store results and hyperparameters for each model\n",
        "results_reduced = {}\n",
        "\n",
        "# Convert X_train_reduced to a NumPy array to simplify indexing\n",
        "X_train_reduced_np = X_train_reduced.to_numpy()\n",
        "\n",
        "# Perform 10-fold cross-validation for each model\n",
        "for model_name, model in [('RFR-X$_5$', random_forest_model_reduced), ('XGBR-X$_5$', xgb_model_reduced), ('LGMR-X$_5$', lgbm_model_reduced), ('DTR-X$_5$', decision_tree_model_reduced)]:\n",
        "    mse_scores = []\n",
        "    r2_scores = []\n",
        "    rmse_scores = []\n",
        "    mae_scores = []\n",
        "\n",
        "    for train_index, val_index in kf.split(X_train_reduced):\n",
        "        X_train_fold, X_val_fold = X_train_reduced_np[train_index], X_train_reduced_np[val_index]\n",
        "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
        "\n",
        "        model.fit(X_train_fold, y_train_fold)\n",
        "        y_val_pred = model.predict(X_val_fold)\n",
        "\n",
        "        mse = mean_squared_error(y_val_fold, y_val_pred)\n",
        "        r2 = r2_score(y_val_fold, y_val_pred)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = mean_absolute_error(y_val_fold, y_val_pred)\n",
        "\n",
        "        mse_scores.append(mse)\n",
        "        r2_scores.append(r2)\n",
        "        rmse_scores.append(rmse)\n",
        "        mae_scores.append(mae)\n",
        "\n",
        "    # Store results and hyperparameters for the current model\n",
        "    results_reduced[model_name] = {\n",
        "        'Hyperparameters': model.get_params(),\n",
        "        'MSE': mse_scores,\n",
        "        'R2': r2_scores,\n",
        "        'RMSE': rmse_scores,\n",
        "        'MAE': mae_scores\n",
        "    }\n",
        "\n",
        "# Print results for reduced features\n",
        "for model_name, metrics in results_reduced.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"Hyperparameters: {metrics['Hyperparameters']}\")\n",
        "    print(f\"Mean MSE: {np.mean(metrics['MSE'])}\")\n",
        "    print(f\"Mean R2: {np.mean(metrics['R2'])}\")\n",
        "    print(f\"Mean RMSE: {np.mean(metrics['RMSE'])}\")\n",
        "    print(f\"Mean MAE: {np.mean(metrics['MAE'])}\")\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "9C7x-_0Kfmh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94f96004-c6d3-4d52-f2f9-9174edc91ddc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000320 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1249\n",
            "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 7.240462\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000324 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1246\n",
            "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 7.235094\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000364 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1249\n",
            "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 7.241299\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000314 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1250\n",
            "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 7.238393\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000365 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1245\n",
            "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 7.245744\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000330 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1250\n",
            "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 7.227983\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000532 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1250\n",
            "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 7.253128\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1247\n",
            "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 7.262667\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000359 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1244\n",
            "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 7.253983\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000312 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1250\n",
            "[LightGBM] [Info] Number of data points in the train set: 5850, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 7.246786\n",
            "Model: RFR-X$_5$\n",
            "Hyperparameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 1.0, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
            "Mean MSE: 0.02462711261538458\n",
            "Mean R2: 0.9967707209536142\n",
            "Mean RMSE: 0.15617111857583096\n",
            "Mean MAE: 0.10291876923076915\n",
            "\n",
            "\n",
            "Model: XGBR-X$_5$\n",
            "Hyperparameters: {'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': None, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n",
            "Mean MSE: 0.025797678243577177\n",
            "Mean R2: 0.9966140902970085\n",
            "Mean RMSE: 0.16051890685485426\n",
            "Mean MAE: 0.11668445060803341\n",
            "\n",
            "\n",
            "Model: LGMR-X$_5$\n",
            "Hyperparameters: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}\n",
            "Mean MSE: 0.016462258976825173\n",
            "Mean R2: 0.9978395470969467\n",
            "Mean RMSE: 0.1281168642655719\n",
            "Mean MAE: 0.09381307118999141\n",
            "\n",
            "\n",
            "Model: DTR-X$_5$\n",
            "Hyperparameters: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}\n",
            "Mean MSE: 0.09735230769230771\n",
            "Mean R2: 0.9872483822379563\n",
            "Mean RMSE: 0.31191440980732665\n",
            "Mean MAE: 0.2236769230769231\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Create a DataFrame from the results_reduced dictionary for easy plotting\n",
        "results_reduced_df = pd.DataFrame(results_reduced)\n",
        "\n",
        "# Transpose the DataFrame for a better structure\n",
        "results_reduced_df = results_reduced_df.T\n",
        "\n",
        "# Define the metrics to plot\n",
        "metrics_to_plot = ['MSE', 'R2', 'RMSE', 'MAE']\n",
        "\n",
        "# Create subplots in a 2x2 grid\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(16, 10))\n",
        "\n",
        "# Loop through each metric and create a bar plot in the corresponding subplot\n",
        "for i, metric in enumerate(metrics_to_plot):\n",
        "    row = i // 2\n",
        "    col = i % 2\n",
        "    if metric == 'R2':\n",
        "        # Use LaTeX formatting for RÂ²\n",
        "        sns.barplot(x=results_reduced_df.index, y=results_reduced_df[metric].apply(np.mean), ax=axes[row, col])\n",
        "        axes[row, col].set_title(f'Mean $R^2$ Comparison with X$_{5}$ Feature set', fontsize=18)\n",
        "        axes[row, col].set_ylabel(f'Mean $R^2$', fontsize=16)\n",
        "    else:\n",
        "        sns.barplot(x=results_reduced_df.index, y=results_reduced_df[metric].apply(np.mean), ax=axes[row, col])\n",
        "        axes[row, col].set_title(f'Mean {metric} Comparison with X$_{5}$ Feature set', fontsize=18)\n",
        "        axes[row, col].set_ylabel(f'Mean {metric}', fontsize=16)\n",
        "\n",
        "    axes[row, col].set_xlabel('Models', fontsize=18)\n",
        "\n",
        "    axes[row, col].tick_params(axis='x')\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the figure with 400 dpi\n",
        "plt.savefig('mean_comparison_plot.png', dpi=400)\n",
        "\n",
        "# Download the saved figure from Colab\n",
        "files.download('mean_comparison_plot.png')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vW4xrzPcNCk4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "outputId": "98c7db0c-6fb8-481c-b410-79d0e6bb163a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dc7e8f3c-8e60-490d-9160-2e049b8134c5\", \"mean_comparison_plot.png\", 428988)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7OcD1zEhlJiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LGBMR with Standard Value**"
      ],
      "metadata": {
        "id": "-iZ8u_d4YlAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from scipy.stats import spearmanr\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have already defined df, X, and y...\n",
        "\n",
        "# Split the data into training and testing sets (e.g., 80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Create an LGBMRegressor model\n",
        "lgbm_model = LGBMRegressor()\n",
        "\n",
        "# Train the LGBMRegressor model with all features\n",
        "lgbm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = lgbm_model.predict(X_test)\n",
        "\n",
        "# Calculate Spearman correlation coefficient\n",
        "spearman_corr, _ = spearmanr(y_test, y_pred)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "print(f'R-squared (R2): {r2}')\n",
        "print(f'Spearman Correlation: {spearman_corr:.2f}')\n",
        "\n",
        "# Create a correlation plot between predicted and actual values with the legend\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.scatterplot(x=y_test, y=y_pred, label=f'Spearman Correlation: {spearman_corr:.3f}')\n",
        "\n",
        "plt.xlabel('Standard ET$_0$ Values',fontsize=14)\n",
        "plt.ylabel('Forecasted ET$_0$ Values',fontsize=14)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.legend()\n",
        "plt.savefig('correlation_plot_500dpi.png', dpi=500)\n",
        "\n",
        "# Download the saved figure from Colab\n",
        "files.download('correlation_plot_500dpi.png')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "mMpE3hsTiYva",
        "outputId": "de3b36bf-95a2-4d63-df6f-4c3247c1d022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001078 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3196\n",
            "[LightGBM] [Info] Number of data points in the train set: 6500, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score 7.244554\n",
            "Mean Squared Error (MSE): 0.018215086334977235\n",
            "R-squared (R2): 0.997796943310868\n",
            "Spearman Correlation: 1.00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_00d427d3-1aa4-4be3-b18f-e4f4eae60d47\", \"correlation_plot_500dpi.png\", 361472)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from scipy.stats import spearmanr\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have already defined df, X, and y...\n",
        "X_subset = df[['u(x)', 'Tx', 'RH','Rs']]  # Subset of features: 'u(x)', 'Tx', 'RH'\n",
        "y = df['ETo']  # Target: 'ETo'\n",
        "# Split the data into training and testing sets (e.g., 80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_subset, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Create an LGBMRegressor model\n",
        "lgbm_model = LGBMRegressor()\n",
        "\n",
        "# Train the LGBMRegressor model with all features\n",
        "lgbm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = lgbm_model.predict(X_test)\n",
        "\n",
        "# Calculate Spearman correlation coefficient\n",
        "spearman_corr, _ = spearmanr(y_test, y_pred)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "print(f'R-squared (R2): {r2}')\n",
        "print(f'Spearman Correlation: {spearman_corr:.2f}')\n",
        "\n",
        "# Create a correlation plot between predicted and actual values with the legend\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.scatterplot(x=y_test, y=y_pred, label=f'Spearman Correlaton: {spearman_corr:.3f}')\n",
        "\n",
        "plt.xlabel('Standard ET$_0$ Values',fontsize=14)\n",
        "plt.ylabel('Forecasted ET$_0$ Values',fontsize=14)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.legend()\n",
        "plt.savefig('correlation_plot_500dpi.png', dpi=500)\n",
        "\n",
        "# Download the saved figure from Colab\n",
        "files.download('correlation_plot_500dpi.png')\n",
        "plt.show()\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "hC1hBdyzvO0u",
        "outputId": "0a38a56d-0074-4bb8-9c10-d8fac7aeea7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000294 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1009\n",
            "[LightGBM] [Info] Number of data points in the train set: 6500, number of used features: 4\n",
            "[LightGBM] [Info] Start training from score 7.244554\n",
            "Mean Squared Error (MSE): 0.03531861245584839\n",
            "R-squared (R2): 0.9957283262900432\n",
            "Spearman Correlation: 1.00\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cee8d169-99ca-4fdd-be83-26916be60176\", \"correlation_plot_500dpi.png\", 386002)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}